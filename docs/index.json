[
{
	"uri": "https://1414c.github.io/jiffy/overview/",
	"title": "Jiffy Overview",
	"tags": [],
	"description": "",
	"content": "Overview and Features Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting Started Initial Setup Before we get start generating services, there are few things to get out of the way. First we need to make sure that the Go environment is setup, then we need to get jiffy installed.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/installation/",
	"title": "Jiffy Installation",
	"tags": [],
	"description": "",
	"content": "Installation and Dependencies Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/execution/",
	"title": "Jiffy Execution",
	"tags": [],
	"description": "",
	"content": "Execution Options Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/models/",
	"title": "Jiffy Models",
	"tags": [],
	"description": "",
	"content": "Models Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/",
	"title": "Generation Reference",
	"tags": [],
	"description": "",
	"content": "Application Generation Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/extensionpoints/",
	"title": "Extension Points",
	"tags": [],
	"description": "",
	"content": "Extension Points Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/accesscontrol/",
	"title": "Access Control",
	"tags": [],
	"description": "",
	"content": "Access Control Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/interprocess/",
	"title": "Interprocess Communication",
	"tags": [],
	"description": "",
	"content": "Interprocess Communication Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/interprocess/ip-content-a/",
	"title": "Group Membership Overview",
	"tags": [],
	"description": "",
	"content": "Overview  Jiffy-generated applications can be deployed as single or multiple instances. When running multiple instances of a Jiffy-generated application, a group-membership service establishes connectivity between all running instances. An application instance always runs a group-membership service, even when running as a single instance. Each application instance running the group-membership service can be thought of as a process. At any point in time, the group has an elected leader. The group-leader information must be made available via an external persistent store, except in the case of single-instance operation. An interface is provided (gmcom.GMLeaderSetterGetter{}) in order to support the passing of implementation-specific persistent store accessors to a starting process. Default implementations to permit access to redis, memcached, stand-alone, and sluggo are provided and are directly supported via configuration in the .xxx.config.json file. The interface can also be used by the implementer to persist the current group-leader information in any other accessible medium (ie. db-of-your-choice). Faster is better here. Each process has a uint id (PID) that is assigned by the group-leader upon joining the group. Processes join the group by querying the well-known persistent store to obtain the current group-leader information. Once the group-leader is known, the joining instance contacts the leader\u0026rsquo;s address:port and sends a JOIN message. The leader will allocate a new PID for the joining process and send an ACK message in response. The joining process set it\u0026rsquo;s PID based on the PID contained in the ACK message. Processes can join and drop out of the group without any changes to the configuration. Group-membership is managed dynamically via inter-process messaging between group-members. Each process knows the PID of and maintains a local status of every other process in the group. Each process maintains a status-count for every other process in the group.  Notes I tried a number of different algorithms while writing the group membership / consensus subsystem. The current approach models the Bully algorithm and a little bit of what I remember of the way a large hardware vendor\u0026rsquo;s node-network operated in the early 2000\u0026rsquo;s.\nI like the approach I used, as every node is in contact with every other node and consensus tends to be reached quickly. However there are some drawbacks that become clear as the size of the node-network increases.\nLets start with a scenario where a jiffy application has been deployed with two nodes. In this scenario, each instance will ping the other instance with a frequency dictated by the ping_cycle attribute in the .prod.config.json file; each node will ping the other node every n seconds.\nNext, lets increase the number of deployed nodes from two to four. Each node will ping each of its colleague nodes once per ping-cycle, which means three pings per node, per ping-cycle with a net ping load of 12.\nWhat does the series of pings per ping-cycle look like as the number of nodes increases?\n 1 node = 0 pings / ping-cycle 2 nodes = 1 outbound ping / node / ping-cycle; 2 pings issued by the group 3 nodes = 2 outbound pings / node / ping-cycle; 6 pings issued by the group 4 nodes = 3 outbound pings / node / ping-cycle 12 pings issued by the group \u0026hellip;  This is a well-known series of numbers: $S=[0, 2 ,6, 12, 20, 30, 42, 56, 72 \u0026hellip; ]$\nSo where we have n nodes, the number of pings per ping-cycle can be determined by $a_n=(n-1)*n$ which does not look great when the number of nodes starts to grow. I didn\u0026rsquo;t have octal installed, so I created this quick graph at desmos.com to illustrate the problem (look at the positive-x side of the curve - hehe\u0026hellip; ). The diagram in the Multi-Instance Deployment section of the jiffy docs also highlights the large number of inter-nodal pings.\nNot pretty - quadratic?! However\u0026hellip;\nThe group sub-system is self-contained in the generated code-body, so in theory one could drop their own implementation into the codebase. It might be fun to experiment with making the group sub-system more modular and configurable. A good side-project would be to implement RAFT or a ring-propagation-style consensus protocol.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/",
	"title": "Testing and Deployment",
	"tags": [],
	"description": "",
	"content": "Testing and Deployment Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/using-docker/dr-content-a/",
	"title": "Jiffy with Docker and SQLite",
	"tags": [],
	"description": "",
	"content": "Overview We will create and deploy a sample application using the all-in-one approach inside a Docker container. To make things easy, we will use SQLite as the database, which means that the Dockerfile and entrypoint setup will be quite simple. Note that if you try to do the same thing with one of the other supported databases there will be some additional configuration. Docker containers are typically used to provide single services.\nSQLite lets us do all-in-one in Docker, as SQLite is a library facilitating access to a file rather than a database service available at an address:port. Our Dockerfile -\u0026gt; entrypoint only has to start one thing: our application.\nNote that this is a setup for testing and development only. When deploying a jiffy-application with Docker, you should use a container clustering/management solution (Docker Swarm, Kubernetes, Rancher \u0026hellip;). Doing will simplify application scaling and is also necessary in order to support the peer-to-peer networking requirement.\nSteps  Verify the Jiffy installation. Generate a new application using a sample model file from the Jiffy source-tree. Edit the application\u0026rsquo;s configuration file for SQLite and Docker use. Statically compile a binary for inclusion in the Docker image. Write a simple Dockerfile to create a runnable image. Write a small script to update the image\u0026rsquo;s .dev.config.json file with the container\u0026rsquo;s ipv4 address Create a container from the image and start the container. Test access to the application running in the container using Postman. Stop the container. Cleanup the Docker environment.  Verify Jiffy Installation Ensure that Jiffy has been installed on your workstation by following the instructions provided in the Jiffy Installation section.\nGenerate the Application We will generate a new application from a model file that contains a \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity. Two relationships are maintained in the model; a Library hasMany Books and a Book belongsTo a specific Library. An application generated from this model will allow many Jiffy application features to be tested.\nOpen a terminal window on your workstation and run jiffy using the Library-Book model file to generate the source-code for our test application as follows:\njiffy -m $GOPATH/src/github.com/1414C/jiffy/support/testing_models/hasManyBelongsTo.json -p /exp/libraryapp Remember that jiffys -p flag expects to be provided with an existing path underneath your $GOPATH/src folder. In the example invocation shown above, jiffy will create the libraryapp folder underneath $GOPATH/src/exp/ and then write the generated source-code to this location.\nExecution of the generator (jiffy) should result in output similar to:\n2018/06/15 14:44:11 generated: /Users/stevem/gowork/src/exp/libraryapp/models/librarym.go 2018/06/15 14:44:11 generated: /Users/stevem/gowork/src/exp/libraryapp/models/librarym_ext.go 2018/06/15 14:44:11 generated: /Users/stevem/gowork/src/exp/libraryapp/controllers/libraryc.go ... ... ... 2018/06/15 14:44:13 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/libraryapp/util/strings.go 2018/06/15 14:44:13 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/libraryapp/util/strings.go 2018/06/15 14:44:13 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/libraryapp/appobj/appconf.go 2018/06/15 14:44:13 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/libraryapp/appobj/appconf.go Your output may look slightly different, particularly the database connection test which will almost certainly fail. This is nothing to be concerned about, as the generator is attempting to connect to a local postgres instance using bad credentials. \nEdit the Application Configuration File Update Address Keys The next step is to edit the generated application\u0026rsquo;s configuration files. Docker allocates a static ip-address for each container by default, and we will use that address in our application\u0026rsquo;s configuration file. \u0026lsquo;external_address\u0026rsquo; refers to the address at which the application\u0026rsquo;s end-points will be available, while the \u0026lsquo;internal_address\u0026rsquo; is used for cache updates and interprocess communication over web-socket connections. Strictly speaking, in a single-instance Docker deployment we could get away with maintaining the address-keys as follows:\n.dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... } However, we will show how to obtain and insert the container\u0026rsquo;s real ip-address into the configuration file. This will be useful later if you deploy multiple application instances in Docker containers.\nOpen the generated .dev.config.json file in an editor and update the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; values with \u0026ldquo;xxx.xxx.xxx.xxx:8080\u0026rdquo; and \u0026ldquo;xxx.xxx.xxx.xxx:4444\u0026rdquo; respectively. Using an illegal ipv4 address as a placeholder/mask ensures that the container will not start in the event that the container\u0026rsquo;s address could not be assigned to the config keys. When you have finished, save the file after verifying that it looks like this:\n.dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... } Update the Application\u0026rsquo;s Database Config As we intend to use SQLite in our all-in-one Docker test deployment, the \u0026lsquo;database\u0026rsquo; block in .dev.config.json must be updated as follows:\n.dev.config.json { ... \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;sqlite\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;port\u0026#34;: 0, \u0026#34;usr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testdb.db\u0026#34; }, ... } Update the Application\u0026rsquo;s Group Leader KVS Config Jiffy generates configuration files supporting a stand-alone / local group-leadership KVS by default. Examine the \u0026lsquo;group_leader_kvs\u0026rsquo; block in *.config.json to ensure the \u0026lsquo;local_standalone\u0026rsquo; KVS option is active as shown below:\n.dev.config.json { ... \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, ... } Once the database block in .dev.config.json has been updated, save the file and close the editor.\n\n\nBuild a Static Application Binary for Alpine Linux Next, we need to build a static application binary for linux/amd64. To build the application, a number of dependencies are required as outlined in the Jiffy Dependencies section of the documentation. Check that your build environment contains the correct packages and import any that are missing.\nThis tutorial uses the popular Alpine Linux distribution as the basis for the new container image. Alpine Linux is a small and sparse distribution making it nice for use with containers. There are a few things to be aware of however\u0026hellip;\nAlpine Linux is based on lib-musl which means that binaries built by go build where the source makes use of cgo must target lib-musl rather than lib-gcc. The binary resulting from the typical \u0026lsquo;GOOS=linux GOARCH=amd64 go build -o main .\u0026rsquo; command would almost certainly not work on Alpine. The good news is that it is quite easy to build with musl-gcc, the bad news is that musl-gcc is available for Linux only. If you are working on a system in which lib-musl is not supported, you will need to run the go build command in a supported build environment. Most Linux distributions and architectures are supported.\nCheck if lib-musl has been installed in the build environment by running the which command:\nwhich musl-gcc If musl-gcc was found in the $PATH, which will return output similar to:\n/usr/bin/musl-gcc If musl-gcc was not found, follow the installation instructions below to download and install the required packages.\nInstall Musl-gcc We will go over how to install musl-gcc on a Debian system, but the steps are largely the same for any Linux distribution. Use your distribution\u0026rsquo;s package manager to install the musl lib, musl development files and musl development tools. Run the following commands (or their equivalents) in a terminal window on your Linux build system:\nsudo apt-get update sudo apt-get install musl sudo apt-get install musl-dev sudo apt-get install musl-tools Check to make sure that musl-gcc is now in the $PATH:\nwhich musl-gcc Build a Static Application Binary After ensuring that all of the required dependencies have been installed in the build environment, run the following command to build a statically-linked binary called main for the Alpine Linux target OS. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Adjust the GOARCH environment variable as necessary:\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build --ldflags \u0026#39;-w -linkmode external -extldflags \u0026#34;-static\u0026#34;\u0026#39; -a -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. Setting \u0026ndash;ldflags as shown instructs go build to produce a statically linked binary. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped Build a Dynamically-Linked Application Binary This is optional and will produce a marginally smaller binary. We will not use a dynamically-linked binary in our image, but have included a suitable go build command for reference purposes.\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build -a -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. go build produces dynamically-linked binaries by default, so no linker instructions have been provided. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-musl-x86_64.so.1, not stripped \n\nCreate a Dockerfile Verify that you have Docker installed in your build environment. The easiest way to do this is to run which docker in a terminal window to ensure the docker application is in the \\$PATH. If there is no response, check the $PATH or install Docker following the instructions at www.docker.com. Verify that the Docker daemon is running by opening a terminal window in your build environment and running the docker ps command. If Docker is not running, an error message will be displayed. Start the Docker daemon before continuing.\nIn order to deploy the compiled all-in-one application in a Docker container, we need to create a Dockerfile. The docker build command uses the Dockerfile as a set of instructions when building an image. As mentioned previously, we will use Alpine Linux as the foundation (base image) for the new Docker container image. Dockerhub has a number of pre-defined images that are available to be \u0026lsquo;pulled\u0026rsquo; into locally defined custom images.\nCreate a new file called Dockerfile in the root folder of the libraryapp source-tree and open it in your editor. Edit the content of the Dockerfile as shown below. An effort has been made to briefly describe what each line of the Dockerfile is used for.\n# use the official docker hub alpine:latest base imageFROMalpine:latest# set the maintainer information for the new imageLABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34;# add the compiled application binary to the root folder of the new imageADD main ./# copy the configuration file to the root folder of the new imageCOPY .dev.config.json .# add the entrypoint.sh shell script to the root folder of the new imageADD docker-entrypoint.sh .# set widely exectuable permission on the shell-scriptRUN /bin/chmod 777 docker-entrypoint.sh# create a directory in the root folder of the new image to hold the jwt signing keysRUN mkdir jwtkeys# copy the jwtkeys folder content into the image\u0026#39;s /jwtkeys folderCOPY jwtkeys ./jwtkeys# set container environment variable $PORT to 8080ENV PORT 8080# container will listen on port tcp/8080EXPOSE8080# install sqlite3 into the imageRUN apk update \\  \u0026amp;\u0026amp; apk add sqlite \\ \u0026amp;\u0026amp; apk add socat# add unix file command - this is not a requirementRUN apk add file# create a test.db file in the root folder (don\u0026#39;t really need to do this,# but it is a nice test when getting started)RUN /usr/bin/sqlite3 /test.db# set the container entrypoint - container executes this once it is up and runningENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;]# specify the flag(s) to be used with the ENTRYPOINTCMD [\u0026#34;-dev\u0026#34;]\n\nCreate the Entrypoint Script In a previous step .dev.config.json was updated with xxx.xxx.xxx.xxx ipv4 address masks. In order to replace the masks with the container\u0026rsquo;s ipv4 address, docker run and docker start will execute the docker-entrypoint.sh when creating a container instance based on the image definition. At the moment this is a problem however, as we have not written the script yet. Create a new file called docker-entrypoint.sh in the root folder of the libraryapp source-tree and open it in your editor. Copy the following content into the new docker-entrypoint.sh file:\n#!/bin/sh  # get the ipv4 address assigned to eth0 replace=$(ifconfig eth0 | grep \u0026#34;inet addr\u0026#34; | cut -d \u0026#39;:\u0026#39; -f 2 | cut -d \u0026#39; \u0026#39; -f 1) # set a variable with the value we are planning to replace search=\u0026#34;xxx.xxx.xxx.xxx\u0026#34; # check that variable replace has something in it if [ -z \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;Did not get an address value for eth0\u0026#34; elif [ -n \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;${replace}found\u0026#34; # replace all instances of \u0026#39;xxx.xxx.xxx.xxx\u0026#39; in .dev.config.json # with the ipv4 address in the ${replace} variable sed -i \u0026#34;s/${search}/${replace}/g\u0026#34; .dev.config.json exec /main \u0026#34;$@\u0026#34; fi  Note that the docker-entrypoint.sh script assumes the ipv4 address should be read from the eth0 interface. This may not be the case in more complex deployments.\n \n\nBuild the Image Assuming the previous steps have been successful, it is now time to build the new Docker image. Execute the following command from the libraryapp root folder:\ndocker build -t libraryapp . Running docker build as shown instructs Docker to construct an image called libraryapp using the Dockerfile in the current working directory. You should see output similar to:\nSending build context to Docker daemon 16.41MB Step 1/17 : FROM alpine:3.7 ---\u0026gt; 3fd9065eaf02 Step 2/17 : LABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34; ---\u0026gt; Using cache ---\u0026gt; 79c0d43a29f9 Step 3/17 : ADD main ./ ---\u0026gt; a7e7dce67f50 Step 4/17 : COPY .dev.config.json . ---\u0026gt; c5822b775472 Step 5/17 : ADD docker-entrypoint.sh . ---\u0026gt; dc5f95101182 Step 6/17 : RUN /bin/chmod 777 docker-entrypoint.sh ---\u0026gt; Running in 77137cc55a5c Removing intermediate container 77137cc55a5c ---\u0026gt; dbaf6e72994a Step 7/17 : RUN mkdir jwtkeys ---\u0026gt; Running in 14818b929ee8 Removing intermediate container 14818b929ee8 ---\u0026gt; f90bb5e8d516 Step 8/17 : COPY jwtkeys ./jwtkeys ---\u0026gt; b1f7dbcb7f99 Step 9/17 : ENV PORT 8080 ---\u0026gt; Running in b5f273f638f4 Removing intermediate container b5f273f638f4 ---\u0026gt; 48ad91d892a2 Step 10/17 : EXPOSE 8080 ---\u0026gt; Running in 16494e968402 Removing intermediate container 16494e968402 ---\u0026gt; 7b9ad3d367ad Step 11/17 : RUN apk update \u0026amp;\u0026amp; apk add sqlite \u0026amp;\u0026amp; apk add socat ---\u0026gt; Running in 52ca734359f8 fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz v3.7.0-215-g16971064c0 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main] v3.7.0-207-gac61833f9b [http://dl-cdn.alpinelinux.org/alpine/v3.7/community] OK: 9054 distinct packages available (1/5) Installing ncurses-terminfo-base (6.0_p20171125-r0) (2/5) Installing ncurses-terminfo (6.0_p20171125-r0) (3/5) Installing ncurses-libs (6.0_p20171125-r0) (4/5) Installing readline (7.0.003-r0) (5/5) Installing sqlite (3.21.0-r1) Executing busybox-1.27.2-r7.trigger OK: 13 MiB in 16 packages (1/1) Installing socat (1.7.3.2-r3) Executing busybox-1.27.2-r7.trigger OK: 13 MiB in 17 packages Removing intermediate container 52ca734359f8 ---\u0026gt; a67a51781543 Step 12/17 : RUN apk add file ---\u0026gt; Running in 51824f0e8666 (1/2) Installing libmagic (5.32-r0) (2/2) Installing file (5.32-r0) Executing busybox-1.27.2-r7.trigger OK: 18 MiB in 19 packages Removing intermediate container 51824f0e8666 ---\u0026gt; c529b1a51fbb Step 13/17 : RUN apk add busybox-extras ---\u0026gt; Running in ff07237bfbea (1/1) Installing busybox-extras (1.27.2-r11) Executing busybox-extras-1.27.2-r11.post-install Executing busybox-1.27.2-r7.trigger OK: 18 MiB in 20 packages Removing intermediate container ff07237bfbea ---\u0026gt; 93f5024f2a17 Step 14/17 : RUN apk add openssh-client ---\u0026gt; Running in 7ea7c5e2197a (1/2) Installing openssh-keygen (7.5_p1-r8) (2/2) Installing openssh-client (7.5_p1-r8) Executing busybox-1.27.2-r7.trigger OK: 21 MiB in 22 packages Removing intermediate container 7ea7c5e2197a ---\u0026gt; 63dfd0feacfc Step 15/17 : RUN /usr/bin/sqlite3 /test.db ---\u0026gt; Running in e1215daeac5c Removing intermediate container e1215daeac5c ---\u0026gt; e3339d8ca07e Step 16/17 : ENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;] ---\u0026gt; Running in cb7231e2f911 Removing intermediate container cb7231e2f911 ---\u0026gt; 43f23ae635c7 Step 17/17 : CMD [\u0026#34;-dev\u0026#34;] ---\u0026gt; Running in cd1245631529 Removing intermediate container cd1245631529 ---\u0026gt; 5ef02199fb7e Successfully built 5ef02199fb7e Successfully tagged libraryapp:latest Aardvark:libraryapp stevem$ View the Image You can run the docker image command to view some basic data regarding the new image:\ndocker image ls library* You should see output similar to:\nREPOSITORY TAG IMAGE ID CREATED SIZE libraryapp latest 5ef02199fb7e Less than a second ago 23.6MB Use the Image Once the image has been created, the next step is to use it to create a container. This can be done in a single step where Docker creates the container and then starts it. Run the following command to create and start a new container from the libraryapp image:\ndocker run --name libraryapp -p 8080:8080 -d libraryapp If all went well, docker created a container from the libraryapp image and then started it. The flags provided with the docker run command do the following:\n \u0026ndash;name - the image to use -p - used to bind the host\u0026rsquo;s tcp/8080 port to container port tcp/8080 -d - detach the container from the starting session  Check the Container Status Container status can be checked via the docker ps command:\ndocker ps -a You should see output similar to:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 532180e4716c libraryapp \u0026#34;/main -dev\u0026#34; About an hour ago Up About an hour 0.0.0.0:8080-\u0026gt;8080/tcp libraryapp The output of the command shows that the libraryapp container was started with entrypoint \u0026lsquo;/main -dev\u0026rsquo; and that container port :8080 is mapped to host port :8080. For a discussion of what to do if the container entrypoint fails, see the Troubleshooting section of this document.\nSSH into the Container We can ssh into the running container to see what is going on using the command shown in the following terminal session. The command logs in as root using the specified interactive shell (in this case /bin/sh). Check that \u0026lsquo;main -dev\u0026rsquo; is running as expected using the Linux ps command.\ndocker exec -it libraryapp /bin/sh / # ps -ef PID USER TIME COMMAND 1 root 0:13 /main -dev 25 root 0:00 /bin/sh 31 root 0:00 ps -ef / # Take a look around the in the container environment and verify that the content of .dev.config.json has been updated with the correct ip-address using the ifconfig/cat commands. Remember that the docker container is created with a static ipv4 address assigned to the eth0 interface. Verify that the eth0 ipv4 address has been added to the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; keys in .dev.config.json.\n/ # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:234 errors:0 dropped:0 overruns:0 frame:0 TX packets:214 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:14515 (14.1 KiB) TX bytes:13329 (13.0 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:55613 errors:0 dropped:0 overruns:0 frame:0 TX packets:55613 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:9736184 (9.2 MiB) TX bytes:9736184 (9.2 MiB) / # cat .dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;172.17.0.2:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;172.17.0.2:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... ... \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] }/ # \n\nLogin to the Application Launch Postman or your favorite RESTful service testing tool and specify a target URL of: http://172.17.0.2:8080/usr/login making sure to select the http POST method. Maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a jiffy application is an email address, but an exception is made for the default administration user definition.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.  If all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single 'token' tag containing a jumble of letters and numbers. This is the JWT that will be used to validate the 'admin' user's authorization to access the 'Library' and 'Book' entity service end-points. If you want to read more about JWT's, [jwt.io](https://jwt.io) is a good place to start, or you can refer to the [Access Control](/jiffy/accesscontrol/index.html) section of this document set. ![Login](../../images/login-b.jpg)  Create a Library We will create a new \u0026lsquo;Library\u0026rsquo; entity. Configure your test-tool to POST to the \u0026lsquo;library\u0026rsquo; service as shown in the following image:\nCopy the JWT from the login session and paste it into the new POST request\u0026rsquo;s Authorization header field as shown below and then submit the request to the application.\nFollowing submission, a new \u0026lsquo;Library\u0026rsquo; entity should have been created:\nCreate another \u0026lsquo;Library\u0026rsquo; entity using the \u0026lsquo;Create a Library\u0026rsquo; steps and then request a list of Library entities using the GET ../librarys end-point:\nCreate a Book Next, we will create a \u0026lsquo;Book\u0026rsquo; entity and allocate it to \u0026lsquo;Library\u0026rsquo; 1. Configure your test-tool to POST to the \u0026lsquo;book\u0026rsquo; service as shown in the following image:\nFollowing the submission, a new \u0026lsquo;Book\u0026rsquo; entity should have been created:\nCreate a few more \u0026lsquo;Book\u0026rsquo; entities using the \u0026lsquo;Create a Book\u0026rsquo; steps and allocate them to your \u0026lsquo;Library\u0026rsquo; entities. When you have finished, request a list of \u0026lsquo;Book\u0026rsquo; entities using the GET ../books end-point:\nLibrary toBooks Based on the \u0026lsquo;hasMany\u0026rsquo; relationship between the \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity\u0026rsquo;s, we can get the number of \u0026lsquo;Book\u0026rsquo; entities belonging to \u0026lsquo;Library\u0026rsquo; 1 as follows:\nRemove the $count suffix from the URL to get the complete list of Book entities belonging to \u0026lsquo;Library\u0026rsquo; 1:\nBook toLibrary A reciprocal \u0026lsquo;belongsTo\u0026rsquo; relationship exists between the \u0026lsquo;Book\u0026rsquo; and \u0026lsquo;Library\u0026rsquo; entity definitions. Select a \u0026lsquo;Book\u0026rsquo; entity and verify that the \u0026lsquo;belongsTo\u0026rsquo; relationship works as expected:\nCheck the list of filters and commands along with the Library and Book models to see what can be appended to the the service end-points. Try some things out.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/accesscontrol/ac-content-a/",
	"title": "Access Control Overview",
	"tags": [],
	"description": "",
	"content": "Overview Access to application resources (entities) is controlled in four ways:\n Configuration based service activation. Secure user authentication. Authorization checks via JWT token claim inspection embedded as middleware in the protected route declarations (end-points). Usr/Auth/Group/GroupAuth caches are maintained on each group-member and updated via an internal API and dissemination protocol in the group-membership service.  Configuration Based Service Activation An internal service is created for each of the the application\u0026rsquo;s entities. Services can be marked as active or inactive in the service configuration, thereby allowing a single application to be generated, while at the same time allowing selective service deployment. For example, there may be cases where it is desirable to route certain services to a particular application instance and another set of services to the rest of the pool. In such a case, a reverse-proxy could be configured to route the end-points appropriately, and the deployed service configurations would be adjusted accordingly. Service activations are controlled via entries in the \u0026lsquo;service_activations\u0026rsquo; block of each application instance\u0026rsquo;s configuration file.\nThe following configuration file excerpt shows that the selected instance of the application is servicing \u0026lsquo;Person\u0026rsquo; entity requests, but is not presently servicing \u0026lsquo;Car\u0026rsquo; entity requests. However, if a relationship exists between \u0026lsquo;Person\u0026rsquo; and \u0026lsquo;Car\u0026rsquo;, requests rooted on the \u0026lsquo;Person\u0026rsquo; entity but involving the \u0026lsquo;Car\u0026rsquo; entity will be accepted. For example, the selected instance would not honor a GET request for ../car/1234, but would accept and process a request for ../person/1234/toCar. In practice, the reverse-proxy/load-balancer should be configured to route requests to the correct end-point.\n... ..., \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;service_active\u0026#34;: false } ] } Secure User Authentication User authentication is conducted using bcrypt in such a manner that passwords are never stored in the application database. When a user is created, their user-id is stored in the database along with the salt/peppered bcrypt hash of their password. This ensures that in the event of a breach no plain-text passwords can be obtained.\nBcrypt was chosen for the following reasons:\n Bcrypt hashes are salt/peppered to mitigate rainbow table attacks. Bcrypt is slow by design, making brute force reversal a time-consuming and expensive proposition. As increased computing power becomes available, the bcrypt cost parameter can be increased (current = 14). The password hash itself is not used for authentication; it is the by-product of successful authentication.  When a user logs into the application the following steps occur:\n A lookup of the user-name and stored bcrypt hash is executed against the database. The user provided password is hashed in memory using the Go standard lib bcrypt functions and the protected salt/pepper values. The computed bcrypt hash is compared to the stored hash value for the user. If the hash values match, a JWT (token) is created and signed using ECDSA-256 (adjustable to ECDSA-384, ECDSA-521, RSA-256, RSA-384, RSA-512). The JWT is passed back to the caller and must henceforth be included in the http header of all requests using the Authorization field. The users access credentials are updated in the servicing group-member\u0026rsquo;s cache. The users access credentials are passed via the cache subsystem to all other group-members.  In addition to fulfilling the authorization requirements, the JWT is also used as a CSRF equivalent. By default the generated JWT has a validity of one-hour, but this may be adjusted via the application configuration file. See the following Authorization and End-Point Security section for more details regarding the content and use of the JWT content/claims.\nAuthorizations \u0026amp; End-Point Security In addition to password authentication, generated applications provide the ability to manage access to their end-points via an authorization scheme. At a high-level:\n An Authorization is generated and linked to each end-point. Authorizations are assigned to User Groups. User Groups are allocated to Users via a Groups field in the Usr master.  -\u0026gt; User | --\u0026gt; Group 1 | | | --\u0026gt; Auth_EndPoint_A | --\u0026gt; Auth_EndPoint_B | --\u0026gt; Auth_EndPoint_C | --\u0026gt; Group 2 | --\u0026gt; Auth_EndPoint_K --\u0026gt; Auth_EndPoint_M Authorizations Application access can be restricted at the end-point level. Each generated end-point is given a name based on its entity, http method and purpose. The gorilla mux provides an easy way to assign names to end-points in a route declaration, and these names are defined in the generated application as Authorizations or Auths.\nAuthorizations are created per end-point and are therefore known to the router, which in turn allows the route middleware of the generated application to determine which Authorization is needed in order to permit the request to proceed. Recall that an authenticated user is sent a signed base64-encoded JWT token that must be passed in the http header Authorization field of each request. The generated router middleware validates the signature, decodes the token, and then examines its Claims in order to determine whether the request should be allowed to proceed. This level of checking can be thought of as the Authentication verification; does the requesting party have a valid access token for the system in general?\nAssuming that the requesting user has a valid access token, the next step is to determine whether the user has permission to access the requested end-point. Each User is assigned to one or more User Groups and these are included as a Groups Claim in the JWT token when the User logs into the application. As a result, the route middleware is able to examine the content of the Groups Claim in order to determine whether the User is permitted to access the requested end-point. The route authorization check unfolds as follows:\n Verify the requesting user has a valid access token (JWT); can the signature be verified? Is the JWT still valid? Read the Groups Claim from the JWT token. Determine the \u0026lsquo;Name\u0026rsquo; (Authorization) of the current route. Examine the authorization cache for each Group the User has been assigned to. If the required Authorization is found in any of the User Groups that the User has been assigned to, the request is allowed to proceed.  The last bullet point is interesting, as it means that end-point access of protected routes is denied by default. Unless access is specifically granted via Authorization -\u0026gt; User Group -\u0026gt; User assignment, the protected end-point is not accessible.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-a/",
	"title": "Application Configuration Overview",
	"tags": [],
	"description": "",
	"content": "Overview The generated application code can be run unchanged for testing purposes, but some external setup is required.\n Edit the generated .prd.config.json file to define your production configuration. Edit the generated .dev.config.json file to define your development / testing configuration. When using SSL to test locally, SSL certs will be needed. See the SSL setup section below for instructions regarding the generation of certificates suitable for local testing via go test.  Configuration File Overview Sample Development Configuration File { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34;, \u0026#34;ormLogActive\u0026#34;: true, \u0026#34;ormDebugTraceActive\u0026#34;: false }, \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, \u0026#34;logging\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;callLocation\u0026#34;: true, \u0026#34;colorMsgTypes\u0026#34;: true, \u0026#34;infoMsgs\u0026#34;: false, \u0026#34;warningMsgs\u0026#34;: false, \u0026#34;errorMsgs\u0026#34;: true, \u0026#34;debugMsgs\u0026#34;: false, \u0026#34;traceMsgs\u0026#34;: false }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] }  Configuration File Fields    Field Name Optional Description     \u0026ldquo;external_address\u0026rdquo; mandatory \u0026lsquo;external_address\u0026rsquo; is used to instruct the service instance which tcp address:port to publish the service end-points on. Example: \u0026ldquo;external_address\u0026rdquo;: \u0026ldquo;192.168.1.66:8080\u0026rdquo;   \u0026ldquo;internal_address\u0026rdquo; mandatory \u0026lsquo;internal_address\u0026rsquo; is used to instruct the service instance which address:port to use when accepting inter-group-member web-sockets requests. This address:port should ideally be hosted on a separate interface, as the web-sockets communication is conducted without authentication or encryption. Example: \u0026ldquo;internal_address\u0026rdquo;: \u0026ldquo;192.168.1.66:4444\u0026rdquo;   \u0026ldquo;env\u0026rdquo; mandatory \u0026lsquo;env\u0026rsquo; is used to inform the generated server which mode to run in. The material difference between \u0026ldquo;dev\u0026rdquo;, \u0026ldquo;def\u0026rdquo; and \u0026ldquo;prod\u0026rdquo; is slight; the \u0026ldquo;dev\u0026rdquo; and \u0026ldquo;def\u0026rdquo; modes run the ORM in debugging mode, thereby causing the generated SQL statements to be written as a log to stdout.  Valid values: \u0026ldquo;dev\u0026rdquo; or \u0026ldquo;def\u0026rdquo; or \u0026ldquo;prod\u0026rdquo; Example: \u0026ldquo;env\u0026rdquo;: \u0026ldquo;dev\u0026rdquo;   \u0026ldquo;ping_cycle\u0026rdquo; mandatory \u0026lsquo;ping_cycle\u0026rsquo; is used to determine the frequency with which the group-members execute a round of pinging. The value must be a whole number \u0026gt; 0. See the Group Membership section of this file for details regarding the execution of a ping-cycle. Example: \u0026ldquo;ping_cycle\u0026rdquo;: 1   \u0026ldquo;failure_threshold\u0026rdquo; mandatory \u0026lsquo;failure_threshold\u0026rsquo; is used to set the limit for recorded ping failures against any process in the group. At the moment this number is used verbatim, but in the future the number of ping failures required to move a process-status from SUSPECT to FAILED will be dependent on the number of processes in the group. See the Group Membership section of this file for greater detail regarding the ALIVE -\u0026gt; SUSPECT -\u0026gt; FAILED chain of process statuses. Example: \u0026ldquo;failure_threshold\u0026rdquo;: 5   \u0026ldquo;pepper\u0026rdquo; mandatory \u0026lsquo;pepper\u0026rsquo; is used as a pepper seed to the bcrypt password hash. The generated server handles user login authentication via bcrypt hashing of the password the user entered, then comparing the resulting hash to the stored bcrypt password hash that was created when the user set their initial password. Passwords are not kept anywhere in the system. Example:\u0026ldquo;pepper\u0026rdquo;: \u0026ldquo;secret-pepper-key\u0026rdquo;   \u0026ldquo;hmac_key\u0026rdquo; N/A \u0026lsquo;hmac_key\u0026rsquo; is a legacy configuration option left over from the old CSRF implementation. This field has been deprecated. Example: \u0026ldquo;hmac_key\u0026rdquo;: \u0026ldquo;some_easily_shoulder_surfable_value\u0026rdquo;   \u0026ldquo;database\u0026rdquo; mandatory is a JSON block holding the access information for the database system. Fill in what is needed for the type of database you are connecting to. SQLite for example, does not have any user-access control etc.   \u0026ldquo;db_dialect\u0026rdquo; mandatory \u0026lsquo;dialect\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the database dialect to use to connect to the backend DBMS. Example: \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;postgres\u0026rdquo; The following values are permitted: {\u0026ldquo;postgres\u0026rdquo;, \u0026ldquo;mssql\u0026rdquo;, \u0026ldquo;hdb\u0026rdquo;, \u0026ldquo;sqlite3\u0026rdquo;, \u0026ldquo;mysql\u0026rdquo;}   \u0026ldquo;host\u0026rdquo; mandatory \u0026lsquo;host\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the ip-address or canonical name of the system hosting the database. Example: \u0026ldquo;host\u0026rdquo;: \u0026ldquo;localhost\u0026rdquo;   \u0026ldquo;port\u0026rdquo; mandatory \u0026lsquo;port\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the port that the database accepts client connections with. Example: \u0026ldquo;port\u0026rdquo;: 5432   \u0026ldquo;user\u0026rdquo; mandatory \u0026lsquo;user\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the username used by the application to login to the database. Example: \u0026ldquo;user\u0026rdquo;: \u0026ldquo;godev\u0026rdquo;   \u0026ldquo;password\u0026rdquo; mandatory \u0026lsquo;password\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the password required for the application to login to the database. Example: \u0026ldquo;password\u0026rdquo;: \u0026ldquo;gogogo123\u0026rdquo;   \u0026ldquo;name\u0026rdquo; mandatory \u0026lsquo;name\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and refers to the name of the database that the application client should connect to. Example: \u0026ldquo;name\u0026rdquo;: \u0026ldquo;testdb\u0026rdquo;   \u0026ldquo;ormLogActive\u0026rdquo; mandatory \u0026lsquo;ormLogActive\u0026rsquo; belongs to the \u0026lsquo;database\u0026rsquo; structure and is used to activate log output from the sqac ORM. Example: \u0026ldquo;ormLogActive\u0026rdquo;: false   \u0026ldquo;group_leader_kvs\u0026rdquo; mandatory \u0026lsquo;group_leader_kvs\u0026rsquo; is a configuration block used to declare the active group-leadership KVS details.   \u0026ldquo;local_standalone\u0026rdquo; mandatory \u0026lsquo;local_standalone\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and contains a configuration block that can be used to instruct the jiffy application instance to run the group-membership KVS lookup in standalone mode. This is the default mode for a generated jiffy application.   \u0026ldquo;local_standalone -\u0026gt; \u0026ldquo;active\u0026rdquo; mandatory \u0026lsquo;local_standalone -\u0026gt; active\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a boolean value (true/false) indicating whether or not the jiffy application is running the group-membership KVS lookup in standalone mode.   \u0026ldquo;local_standalone -\u0026gt; internal_address\u0026rdquo; conditional \u0026lsquo;local_standalone -\u0026gt; internal_address\u0026rsquo; holds the address:port of the standalone jiffy application server. The address:port provided here should be locally ping-able.   \u0026ldquo;redis\u0026rdquo; mandatory \u0026lsquo;redis\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and contains a configuration block that can be used to instruct the jiffy application instance to access a redis system when performing group-leadership KVS reads and updates.   \u0026ldquo;redis -\u0026gt; active\u0026rdquo; mandatory \u0026lsquo;redis -\u0026gt; active\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a boolean value (true/false) indicating whether or not the jiffy application is accessing a redis system to perform group-leadership KVS reads and updates.   \u0026ldquo;redis -\u0026gt; \u0026ldquo;max_idle\u0026rdquo; mandatory \u0026lsquo;redis -\u0026gt; max_idle\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a uint value specifying a maximum number of idle redis client connections can remain active at any point in time.   \u0026ldquo;redis -\u0026gt; max_active\u0026rdquo; mandatory \u0026lsquo;redis -\u0026gt; max_active\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a uint value specifying a maximum number of active redis client connections a jiffy application instance is permitted to hold at any point in time.   \u0026ldquo;redis -\u0026gt; max_protocol\u0026rdquo; mandatory \u0026lsquo;redis -\u0026gt; max_protocol\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a string value specifying which transport should be used to communicate with the redis group-leadership KVS system. tcp is the default value.   \u0026ldquo;redis -\u0026gt; max_address\u0026rdquo; mandatory \u0026lsquo;redis -\u0026gt; max_address\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a string value specifying the address:port at which the redis group-leadership KVS can be accessed.   \u0026ldquo;memcached\u0026rdquo; mandatory \u0026lsquo;memcached\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and contains a configuration block that can be used to instruct the jiffy application instance to access a memcached system/cluster when performing group-leadership KVS reads and updates.   \u0026ldquo;memcached -\u0026gt; active\u0026rdquo; mandatory \u0026lsquo;memcached -\u0026gt; active\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a boolean value (true/false) indicating whether or not the jiffy application is accessing a memcached system/cluster to perform group-leadership KVS reads and updates.   \u0026ldquo;memcached -\u0026gt; addresses\u0026rdquo; mandatory \u0026lsquo;memcached -\u0026gt; addresses\u0026rsquo; belongs to the \u0026lsquo;group_leader_kvs\u0026rsquo; structure and holds a json array of string values specifying the address:port(s) at which the memcached group-leadership KVS cluster can be accessed.   \u0026ldquo;logging\u0026rdquo; mandatory is a JSON block holding the application logging configuration.   \u0026ldquo;active\u0026rdquo; mandatory \u0026lsquo;active\u0026rsquo; is a flag that generally activates or deactivates the application logging. When set to false, application logging is deactivated and only Console-type messages will be displayed. When set to true, logs for each activated logging-type (Info, Warning, Error etc.) will be output.   \u0026ldquo;callLocation\u0026rdquo; mandatory Setting the \u0026lsquo;callLocation\u0026rsquo; flag to true instructs the logging package to append the source-file name and line-location of the previous statement to the log output for all logging-types.   \u0026ldquo;colorMsgTypes\u0026rdquo; mandatory Setting the \u0026lsquo;colorMsgTypes\u0026rsquo; flag to true instructs the logging package to color the message-type (INFO:, WARNING:, ERROR:, etc.) in the log output. In general log entries observe the following format: \u0026lt;MESSAGE_TYPE:\u0026gt;\u0026lt;LOCAL_DATETIME\u0026gt;\u0026lt;MESSAGE_TEXT\u0026gt;\u0026lt;SOURCE_FILE\u0026gt;\u0026lt;SOURCE_LINE_NUMBER\u0026gt;   \u0026ldquo;infoMsgs\u0026rdquo; mandatory When set to true, the application will write informational messages to stdout. This is verbose. Defaulted to false.   \u0026ldquo;warningMsgs\u0026rdquo; mandatory When set to true, the application will write warning messages to stdout. Defaulted to true.   \u0026ldquo;errorMsgs\u0026rdquo; mandatory When set to true, the application will write error messages to stdout. Defaulted to true.   \u0026ldquo;debugMsgs\u0026rdquo; mandatory When set to true, the application will write debugging messages to stdout. Defaulted to false.   \u0026ldquo;traceMsgs\u0026rdquo; mandatory When set to true, the application will write error messages to stdout. Defaulted to false.   \u0026ldquo;cert_file\u0026rdquo; optional \u0026lsquo;cert_file\u0026rsquo; should point to the location of a self-signed or purchased certificate file and is used to support https. Maintaining a \u0026lsquo;cert_file\u0026rsquo; and \u0026lsquo;key_file\u0026rsquo; in the configuration informs the generated server to publish via https. Example: \u0026ldquo;cert_file\u0026rdquo;: \u0026ldquo;myCert.cer\u0026rdquo;   \u0026ldquo;key_file\u0026rdquo; optional \u0026lsquo;key_file\u0026rsquo; should point to the location of the key-file for the self-signed or purchased certificate file referenced in the \u0026lsquo;key_file\u0026rsquo; configuration key. Maintaining a \u0026lsquo;cert_file\u0026rsquo; and \u0026lsquo;key_file\u0026rsquo; in the configuration informs the generated server to publish via https. Example: \u0026ldquo;key_file\u0026rdquo;: \u0026ldquo;myKeyFile.key\u0026rdquo;   \u0026ldquo;rsa256_priv_key_file\u0026rdquo; optional Private key file for rsa256 JWT verification. Application access is handled via claims embedded in JWT tokens. The JWT header and payload contain the claims and are encoded as base64. In order to ensure the JWT content has not been tampered with, a verification signature based on the JWT content and a set of public-private keys is included in the JWT. Jiffy generates a set of public-private keys for each supported signing algorithm, but only populates the key configuration files with the set corresponding the value set in the \u0026lsquo;jwt_sign_method\u0026rsquo;. Look in the /jwtkeys folder to see the public-private keys generated by Jiffy.If you have an external system that signs JWT\u0026rsquo;s with RSA256, it is possible to provide the Jiffy-generated application with the public-private key-pair by setting their locations and names in the \u0026lsquo;rsa256_priv_key_file\u0026rsquo; and \u0026lsquo;rsa256_pub_key_file\u0026rsquo;. This would allow the external authentication system to create access tokens for the Jiffy-generated application, provided that the correct claims were embedded in the JWT header and payload. This effectively enables a very simple single-sign-on facsimile. The following pub/priv keys can be used for this purpose.   \u0026ldquo;rsa256_pub_key_file\u0026rdquo; optional Public key file for rsa256 JWT verification.   \u0026ldquo;rsa384_priv_key_file\u0026rdquo; optional Private key file for rsa384 JWT verification.   \u0026ldquo;rsa384_pub_key_file\u0026rdquo; optional Public key file for rsa384 JWT verification.   \u0026ldquo;rsa512_priv_key_file\u0026rdquo; optional Private key file for rsa512 JWT verification.   \u0026ldquo;rsa512_pub_key_file\u0026rdquo; optional Public key file for rsa512 JWT verification.   \u0026ldquo;ecdsa256_priv_key_file\u0026rdquo; optional Private key file for ecdsa256 JWT verification.   \u0026ldquo;ecdsa256_pub_key_file\u0026rdquo; optional Public key file for ecdsa256 JWT verification.   \u0026ldquo;ecdsa384_priv_key_file\u0026rdquo; optional Private key file for ecdsa384 JWT verification.   \u0026ldquo;ecdsa384_pub_key_file\u0026rdquo; optional Public key file for ecdsa384 JWT verification.   \u0026ldquo;ecdsa521_priv_key_file\u0026rdquo; optional Private key file for ecdsa521 JWT verification.   \u0026ldquo;ecdsa521_pub_key_file\u0026rdquo; optional Public key file for ecdsa521 JWT verification.   \u0026ldquo;jwt_sign_method\u0026rdquo; mandatory \u0026lsquo;jwt_sign_method\u0026rsquo; informs the application which algorithm should be used to sign the JWT created during the login process. In this example, the ecdsa384_pub_key_file \u0026amp; ecdsa384_priv_key_file key files will be used to sign the JWT. Note that this only applies to JWTs that are created via a direct login into the application via the https://appurl:port/login end-point. It is possible that a user will access the application using a JWT generated somewhere with a set of keys that are also known to the application. Example: \u0026ldquo;jwt_sign_method\u0026rdquo;: \u0026ldquo;ES384\u0026rdquo;   \u0026ldquo;jwt_lifetime\u0026rdquo; mandatory \u0026lsquo;jwt_lifetime\u0026rsquo; informs the application how long generated JWT\u0026rsquo;s are valid for in minutes. The \u0026lsquo;jwt_lifetime\u0026rsquo; value is used to determine the value of the JWT\u0026rsquo;s \u0026lsquo;exp\u0026rsquo; claim. Example:\u0026ldquo;jwt_lifetime\u0026rdquo;: 120   \u0026ldquo;service_activations\u0026rdquo; mandatory When an application is generated based on the model file(s), all service aspects of the complete set of entities will be created. There may be scenarios where it is appropriate to limit the set of activated services on a running instance of an application server. This can be achieved by maintaining the activation status of each modeled entity in the service_activations list.  \u0026lsquo;service_activations is an array containing sets of \u0026lsquo;service_name and \u0026lsquo;service_activation\u0026rsquo;.   \u0026ldquo;service_name\u0026rdquo; mandatory Service name is simply the entity name in CamelCase matching that of the entity\u0026rsquo;s definition in its respective model file.   \u0026ldquo;service_activation\u0026rdquo; mandatory A boolean value (true\\false) describing whether the entity\u0026rsquo;s services are active on the application server. Care must be taken with service activations, as relationships between entities must be considered. Disabling an entity that has a \u0026lsquo;belongsTo\u0026rsquo; relation with an active entity can lead to problems. In such a case, the expectation is that another instance of the application server is running with the required services active. While the generated application server does not handle the rerouting or request forwarding in such a case, it should be possible to direct requests to the correct server based on NGinx config (for example).    Database Dialects and Sample Database Configurations Currently, the following db_dialects are supported by the sqac ORM runtime:\n   Database JSON Value for db_dialect field     Postgres \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;postgres\u0026rdquo;   MSSQL (2008+) \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;mssql\u0026rdquo;   SAP Hana \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;hdb\u0026rdquo;   SQLite3 \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;sqlite3\u0026rdquo;   MySQL / MariaDB \u0026ldquo;db_dialect\u0026rdquo;: \u0026ldquo;mysql\u0026rdquo;    SAP Hana { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;hdb\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;clkhana01.lab.clockwork.ca\u0026#34;, \u0026#34;port\u0026#34;: 30047, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } \nMSSQL { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;mssql\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 1401, \u0026#34;usr\u0026#34;: \u0026#34;SA\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;sqactst\u0026#34; }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } \nMySQL / MariaDB { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;192.168.1.50\u0026#34;, \u0026#34;port\u0026#34;: 3306, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;sqactst\u0026#34; }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } \nPostgreSQL { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;sqactst\u0026#34; }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } \nSQLite { \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;sqlite\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 0, \u0026#34;usr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testdb.sqlite\u0026#34; }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } "
},
{
	"uri": "https://1414c.github.io/jiffy/extensionpoints/ep-content-a/",
	"title": "Extension Point Overview",
	"tags": [],
	"description": "",
	"content": "Extension-Points (ext folders) The Jiffy application generates a working services application based on the provided model files. While the generated application should be runnable immediately following generation, there is often a need to perform validation and normalization of the incoming data. This is best coded in the model-layer within the generated validation methods, but sometimes this is not sufficient.\nThere may be a need to inspect the request details immediately once the request has been passed to the controller. There may be a need to perform crucial validations of the request-body in the controller layer prior to calling the model-layer (i.e. in advance of the validator). There may be a need to influence the value of an entity\u0026rsquo;s fields prior to returning the read or created entity back to the caller. For reasons such as these, so-called \u0026lsquo;extension-points\u0026rsquo; have been embedded in the model and controller layers of the code.\nEach extension-point offers the developer the ability to code their own method in a regeneration protected code-body in order to perform checks or data manipulations. Consider that regeneration of an application will overwrite the current controller and model files if the same target destination is used. If an application developer were to extend the controller or model directly in the generated code, their additions would be lost if the application were to be regenerated. By introducing the extension-point concept and separating the related code from the generated code the application developers enhancements are protected from being over-written by an inadvertent application regeneration.\nFirstApp  appobj   appconf.go   appobj.go  controllers   authc.go   controllerfuncs.go   groupauthc.go   person_relationsc.go   personc.go   usrc.go   usr_groupc.go   ext   extc_interfaces.go   personc_ext.go . . .  models   authm.go   errors.go   group_authm.go   modelfuncs.go   personm_ext.go   personm.go   servicesm.go   usr_groupm.go   usrm.go   ext   model_ext_interfaces.go  util   strings.go  .dev.config.json  .prd.config.json  main_test.go  main.go Extension-points are declared in the generated codebase as a specific set of controller and model interfaces. The interface declarations are contained in the ext sub-folders of the model and controller folders. The ext sub-folders also contain sample (empty) implementations of the interfaces are provided for each modeled entity.\nThe extension-point interfaces rely on the use of the empty interface{} in order to facilitate the passing of a pointer to the data structure being inspected/updated. Use of interface{} allows us to embrace the concept of a general extension-point API at the cost of strict typing. Additionally, the implementer must make use of reflection in order to assign a type to the value of the interface{} underlying data structure. As of this writing, the use of interface{} and reflection is the best way to implement a general extension-point API with Go. If generics and algebraic types are added to Go, all empty interface{} code will be unceremoniously dumped and replaced with something nicer.\nExtension-points are generated on a per-entity-basis controlled by the inclusion of the \u0026lsquo;ext_points\u0026rsquo; block in the entity\u0026rsquo;s model declaration. See the Annotated Simple Single Entity Model for an overview of the extension-point model elements.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-a/",
	"title": "Generation Overview",
	"tags": [],
	"description": "",
	"content": "Jiffy Application File Structure Running the Jiffy generator creates a set of files that comprise a working backend services application. Jiffy generates the following source code tree when provided with a model-file describing a simple \u0026lsquo;Person\u0026rsquo; entity.\nFirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go  controllers   authc.go   controllerfuncs.go   groupauthc.go   person_relationsc.go   personc.go   usrc.go   usr_groupc.go   ext   extc_interfaces.go   personc_ext.go  group   gmcl    gmclient.go   gmcom    gmcache.go    gmclsrv.go    gmerrors.go    gmomap.go   gmsrv   gmprocessors.go   gmprotocol_senders.go   gmserver.go   gmtxrx.go  jwtkeys   ecdsa256    ecdsa.priv.pem    ecdsa.pub.pem   ecdsa384    ecdsa384.priv.pem    ecdsa384.pub.pem   ecdsa521    ecdsa521.priv.pem    ecdsa521.pub.pem   rsa256    rsa.priv.pem    rsa.pub.pem   rsa384    rsa384.priv.pem    rsa384.pub.pem   rsa512   rsa512.priv.pem   rsa512.pub.pem  middleware   requireuser.go  models   authm.go   errors.go   group_authm.go   modelfuncs.go   personm_ext.go   personm.go   servicesm.go   usr_groupm.go   usrm.go   ext   model_ext_interfaces.go  util   strings.go  .dev.config.json  .prd.config.json  main_test.go  main.go Basic Application Flow Incoming service requests are handled by a mux, which validates / authenticates the request, and then matches it to a route. The selected route passes the request to a controller specific to the entity-type, where the incoming information is mapped into a go struct matching the entity declaration. The controller then calls the appropriate model method for the http operation and entity-type combination, passing it the entity structure. The model handler passes the entity struct through a member-field validation layer, and then to the model\u0026rsquo;s interface to the underlying sqac ORM. The database request is handled by the ORM, and then the response is passed from the model back to the controller where it is marshaled into a JSON payload and sent back to the caller in the response-writer\u0026rsquo;s body.\nJiffy applications contain an embedded leader-based group-membership sub-system that is used for interprocess communication when the generated jiffy application is deployed as multiple processes.\n When a jiffy-application is deployed as more than one process (node), there is a need for changes to users, auths, groups and group/auth associations to be communicated to all running instances. These common application entities are cached locally on each running instance in order to avoid accessing a database unnecessarily. An internal cache subsystem was chosen in order to avoid dependencies on external solutions like redis/memcached/etcd etc. (see footnote). Changes to these objects are performed via standard jiffy-admin services that are present in every jiffy-application. When one of the standard admin objects is updated via an admin service, the object\u0026rsquo;s data is updated in the database. Following a successful database update, the jiffy-application will disseminate the updated object data to the local cache of the application server that processed the change, as well as every other application server (node) in the group. Given that there is interprocess / inter-nodal communication for the cache updates, the status of the group members must be tracked. The subsystem uses a SWIM (Scalable Weakly-Consistent Infection-Style Process-Membership) protocol to check and disseminate the statues of the group\u0026rsquo;s processes. A ping is sent from each process to every other known process in the group in random order once per ping-cycle. The ping message contains a piggybacked process-map containing the pinging process\u0026rsquo;s (node\u0026rsquo;s) view of the world in terms of process status. Processes (nodes) may have one of the following five statuses (ALIVE, SUSPECT, FAILED, DEPARTING, DEPARTED), as well as a status count indicating how many times the pinging process has noted that a process is in a particular state.  See the Group Membership section of this document for a detailed overview of the group-membership subsystem.\nThere are more elegant ways to express certain aspects of the generated application. The coding style has been deliberately kept as simple and straight-forward as possible in order to facilitate easier understanding and adjustment of the generated code.\n** Using something like etcd to replace the group-membership and app-server-level caching may make sense in Kubernetes-style deployments. In the future, jiffy may move to the etcd model for all deployments.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/tt-content-a/",
	"title": "Hand Coding a Custom Join",
	"tags": [],
	"description": "",
	"content": "Manual Join Creation TODO "
},
{
	"uri": "https://1414c.github.io/jiffy/models/mo-content-a/",
	"title": "Model Overview",
	"tags": [],
	"description": "",
	"content": "Model Files Model files contain the Entity, Index and Relation definitions that you wish to generate services and database artifacts for. Jiffy determines the location of the model file(s) via the -m or -mf flags provided at the time of execution. See the Execution Options section of the documentation for details regarding the use of the -m and -mf flags.\nIt is possible to use more than one model-file, as long as there is no duplication of entity definitions across the files. Model files may be loaded in any order via the -mf flag, but the complete set of files must be loaded at the same time. As an example, it would be fine to create three model files; Library.json, Book.json, LibraryCard.json, but all three files should be complete and processed at the same time via the -mf flag in order to allow the correct generation of relationships etc.\nSample models.json files are installed with the application and can be found in the support/testing_models folder of the Jiffy source tree. The sample models are used as the basis for the following sections.\nMaking Changes to a Model Each time the Jiffy-generated application is started, a check is performed to see if it\u0026rsquo;s models match any database artifacts. For example, if the generated application contains a model called \u0026lsquo;Widget\u0026rsquo;, a check is performed to see if table \u0026lsquo;widget\u0026rsquo; exists in the database. If a table matching the model name is detected in the database, the application will attempt to process the model definition as an ALTER TABLE-type operation rather than CREATE TABLE. The application will add new model elements to the existing database table schema, but will not delete database artifacts if model elements are removed. During the development-cycle it is recommended to drop and recreate the database artifacts when making changes to the model. This can be done using the -dr flag option when executing your generated application. See the application startup sequence section of this document for details regarding database artifact creation and updates.\nSimple Single Entity Model The following JSON illustrates the definition of a simple single-entity model file. In this case, a model entity called \u0026lsquo;Person\u0026rsquo; will be created in the generated application, along with corresponding database table \u0026lsquo;person\u0026rsquo;. Table \u0026lsquo;person\u0026rsquo; will be created (if it does not already exist) when the application is started for the first time.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;id_properties\u0026#34;: { \u0026#34;start\u0026#34;: 10000000 }, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,le,gt,ge\u0026#34; }, \u0026#34;validLicense\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,ne\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: simpleSingleEntityModel.json. \nAnnotated Simple Single Entity Model The following block outlines and describes the fields contained in the simple model file above.\n{ \u0026#34;entities\u0026#34;: [ // The \u0026#39;entities\u0026#39; block contains an array of entities belonging to the application  // model. Each entity relates directly to a database table (or view). Entities  // contain information that the application generator uses to create and update  // database artifacts such as tables, indexes, sequences and foreign-keys, as well  // as information informing the application runtime of the member field properties.  // This is a mandatory model element.  { \u0026#34;typeName\u0026#34;: \u0026#34;Person\u0026#34; // Field \u0026#39;typeName\u0026#39; refers to the name of an entity. It should be capitalized  // and written in CamelCase.  // An Entity given a typeName of \u0026#34;Person\u0026#34; will result in an internal model  // object of type Person and a database table called \u0026#39;person\u0026#39;.  // This is a mandatory model element.  \u0026#34;id_properties\u0026#34;: { // The \u0026#39;id_properties\u0026#39; block contains a single entry for now, and is used to  // provide guidance to the application generator regarding the setup of the  // entity\u0026#39;s ID field.  // This is an optional model element.  \u0026#34;start\u0026#34;: 10000000, // Field \u0026#39;start\u0026#39; can be used to provide a starting point for an entity\u0026#39;s  // ID field.  // This is a mandatory model element if the \u0026#39;id_properties\u0026#39; block has  // been included in the model.  }, \u0026#34;properties\u0026#34;: { // The \u0026#39;properties\u0026#39; block contains 1:n entity member field definitions.  // Member fields should be defined in camelCase and can start with a lower  // or upper-case character. In the context of the \u0026#34;entity\u0026#34; with a \u0026#39;typeName\u0026#39;  // of \u0026#39;Person\u0026#39;, \u0026#39;properties\u0026#39; refer to the data fields of the generated  // \u0026#39;Person\u0026#39; model structure. \u0026#39;properties\u0026#39; are a collection of free-form  // name-tags, each with a child-block containing the \u0026#39;property\u0026#39; attributes.  // This is a mandatory model element.  The \u0026#34;name\u0026#34; property block is described below: \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, // Field \u0026#39;type\u0026#39; in a \u0026#39;properties\u0026#39;-\u0026gt;\u0026#39;name\u0026#39; JSON-block refers to the go  // data-type associated with the current \u0026#39;property\u0026#39;.  // \u0026#39;type\u0026#39; is a mandatory field in an \u0026#34;entity\u0026#34; \u0026#39;property\u0026#39; block.  \u0026#34;dbtype\u0026#34;: \u0026#34;varchar(100)\u0026#34;, // Field \u0026#39;dbtype\u0026#39; can be used to specify a native db-field-type for  // the property. This feature can be useful if for example, the  // developer is confident that a string will never exceed 100  // characters in length. Care should be taken to ensure that the  // specified DB-Type is consistent with the go-type that will be  // generated in the application\u0026#39;s model.\u0026lt;Entity\u0026gt; defintion. Consider  // also that making use of this field potentially limits the backend  // portability of the generated code. For example, not all database  // systems have a TINYINT data-type, so specifying a \u0026#39;db_type\u0026#39; of  // TINYINT could be problematic if multiple database systems are  // being used for testing.  // This is an optional field.  \u0026#34;no_db\u0026#34;: // Field \u0026#39;no_db\u0026#39; can be used to instruct the generator to create the  // field as a member in the enitity struture, but to prevent the  // field from being persisted in the backend database. Non-persistent  // fields are not created in the database table schemas, and values  // passed into the application are wiped from their respective  // internal structures following use. \u0026#39;no_db\u0026#39; fields can also be used  // to pass calculated values back to the caller.  // This is an optional field.  \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, // Field \u0026#39;format\u0026#39; is not currently used, but is intended to deal with  // field conversion from strings / floats to timestamp formats etc.  // This is an optional field.  \u0026#34;required\u0026#34;: false, // Field \u0026#39;required\u0026#39; is used to instruct the generator to set a  // \u0026#39;NOT NULL\u0026#39; database constraint on the column related to the  // property.  // Allowed values include {true, false}.  // This is a mandatory field.  \u0026#34;unique\u0026#34;: false, // Field \u0026#39;unique\u0026#39; is used to instruct the database not to accept  // duplicate values in the database column related to the property.  // Setting this field to true will cause a \u0026#39;UNIQUE\u0026#39; constraint to  // be applied to the related database column.  // Allowed values include {true, false}.  // This is a mandatory field.  \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, // Field \u0026#39;index\u0026#39; is used to instruct the database to create an index  // on the db table-column related to the property. See the \u0026#39;indexes\u0026#39;  // element in the type definition for the creation of compound  // indices.  // Allowed values include {\u0026#34;unique\u0026#34;, \u0026#34;nonUnique\u0026#34;, \u0026#34;\u0026#34;}.  // This is an optional field.  \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; // Field \u0026#39;selectable\u0026#39; can be used to instruct the code-generator to  // create simple REST query accessor routes for the current \u0026#39;property\u0026#39;.  // The generator creates routes to permit GET operations that can be  // called based on the entity \u0026#39;typeName\u0026#39; and \u0026#39;property\u0026#39; values.  // Allowed values include:  // {\u0026#34;EQ\u0026#34;, \u0026#34;eq\u0026#34;, \u0026#34;LT\u0026#34;, \u0026#34;lt\u0026#34;, \u0026#34;GT\u0026#34;, \u0026#34;gt\u0026#34;, \u0026#34;GE\u0026#34;, \u0026#34;ge\u0026#34;, \u0026#34;LIKE\u0026#34;, \u0026#34;like\u0026#34;, \u0026#34;NE\u0026#34;, \u0026#34;ne\u0026#34;, \u0026#34;\u0026#34;}  // Additional restrictions are imposed based on the \u0026#39;type\u0026#39; field value.  // For example, a bool type need not support LT or GT operators.  // Sample URLs for Person-\u0026gt;Name selection with \u0026#34;eq,like\u0026#34; are shown:  // https://localhost:\u0026lt;port\u0026gt;/persons/name(EQ \u0026#39;\u0026lt;sel_string\u0026gt;\u0026#39;)  // https://localhost:\u0026lt;port\u0026gt;/persons/name(LIKE \u0026#39;\u0026lt;sel_string\u0026gt;\u0026#39;)  // Note that this is not the same as filtering insofar as setting the  // selectable options results in the creation of parameterized static  // routes in the application mux.  }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,le,gt,ge,ne\u0026#34; }, ... ... }, \u0026#34;ext_points\u0026#34;: { // The \u0026#39;ext_points\u0026#39; block contains two elements which Jiffy uses to determine  // whether or not to create extension-points in the entity.  // This is an optional block.  \u0026#34;gen_controller\u0026#34;: true, // Element \u0026#39;gen_controller\u0026#39; is used by Jiffy to determine whether or not  // to insert extension-points into the entity\u0026#39;s controller. Setting the  // value of this element to \u0026#39;true\u0026#39; will cause Jiffy to insert extension-  // points into the entity\u0026#39;s controller and generate an empty implementation  // of the extension-point interface for the entity in the ./controllers/ext  // folder. A generated controller extension-point implementation for  // entity \u0026#39;Person\u0026#39; would take the form of: \u0026#39;personc_ext.go\u0026#39;.  // This is an optional element.  \u0026#34;gen_model\u0026#34;: true // Element \u0026#39;gen_model\u0026#39; is used by Jiffy to determine whether or not to  // insert extension-points into the entity\u0026#39;s model file. Setting the  // value of this element to \u0026#39;true\u0026#39; will cause Jiffy to insert extension-  // points into the entity\u0026#39;s model file and generate an empty implementation  // of the extension-point interface for the entity in the ./models folder.  // A generated model extension-point implementation for entity \u0026#39;Person\u0026#39;  // would take the form of: \u0026#39;personm_ext.go\u0026#39;.  // This is an optional element.  } }, { ... next entity definition } ] } Entity ID The ID field is visibly absent from the preceding entity declarations. The original intent was to support any name for the primary key / resource identifier of an entity. While it is possible to do this, ID uint values are the universal \u0026lsquo;standard non-standard\u0026rsquo; way of representing object identifiers in systems. As a result, ID is injected into the model definition of every entity as a uint64 field and is marked as the primary-key in the database table. By default, ID is created as an auto-incrementing column in the DBMS, but this functionality can be suppressed (future - the ORM supports this, but Jiffy has yet to be updated). The ability to allow a specific starting point for the ID key range is supported via the entity header-level \u0026ldquo;start\u0026rdquo; value.\nIf the ID field really needs to be known as something else - CustomerNumber for example, the generated code can be edited in a few locations to support the change. It is worth mentioning that the number of edits required to rename ID increases in direct relation to the number and complexity of entity relations (both to and from).\nAs an alternative to renaming ID, it is also conceivable that it can be ignored. Ignoring ID means that the generated CRUD controller/model/routes are not as useful as they could be, but they offer a great starting point for your own coding. Entities can be defined with column constraints that mimic those of DBMS primary / complex keys, then the generated CRUD artifacts based on ID can be ignored, copied then ignored, or modified to accommodate the modeled entities.\nIt is also possible to go completely custom and write your own models and controllers from scratch using a generated model as a reference template. In addition to exposing a generic internal CRUD interface to the backend, the more interesting go/sql calls are exposed internally along with some lightly wrapped and super useful calls from jmoirons widely used sqlx package. Although Jiffy eschews non-standard lib packages wherever possible, sqlx is really great.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/execution/ex-content-a/",
	"title": "Running Jiffy",
	"tags": [],
	"description": "",
	"content": "Execution In order to run the Jiffy application generator, ensure the following:\n  Make sure Go has been installed in the test environment. See http://www.golang.org for installation files and instructions.\n  Make sure that the Jiffy source code and dependencies have been installed.\n  One of the supported databases is available, either locally or over the network.\n  Jiffy can be started in two ways:\n Using the binary installed by following the instructions located in the Jiffy Installation section of this documentation. This is the preferred method of execution.  jiffy -m \u0026#34;/tmp/simpleSingleEntityModel.json\u0026#34; -p \u0026#34;/github.com/footle.com/mynewsvcs\u0026#34;  You may also execute the application directly from the Jiffy source code as follows.  cd $GOPATH/src/github.com/1414C/jiffy go run main.go -m \u0026#34;/tmp/simpleSingleEntityModel.json\u0026#34; -p \u0026#34;/github.com/footle.com/mynewsvcs\u0026#34; We will discuss the flags and parameters in the following sections.\n  "
},
{
	"uri": "https://1414c.github.io/jiffy/installation/in-content-a/",
	"title": "Jiffy Dependencies",
	"tags": [],
	"description": "",
	"content": "What does Jiffy need to run? Wherever possible and reasonable, Jiffy relies on packages found in the Go standard library. As of this writing, Go version 1.14.3 is recommended in order to build the Jiffy binary. Jiffy requires a running database from the following list of supported databases:\nSupported Databases  PostgreSQL tested with version 10+ SAP HanaDB tested with HDB 2.0 MSSQL tested with MSSQL 2017 MySQL SQLite3 Firebird (future) DB2 (future)  Database Drivers The following Go database drivers are required, even if you are only planning to make use of one of the DBMS\u0026rsquo;s in the supported list. This is due to the fact that Jiffy attempts to connect to your test database during the code generation process and there is no guarantee what that database may be. It is possible that a developer tests with SQLite locally when generating the code and performing initial tests, but intends to ultimately connect to Postgres.\n   Driver Name Driver Location     SAP Hana Database Driver github.com/SAP/go-hdb/driver   MSSQL Database Driver github.com/denisenkom/go-mssqldb   MySQL Database Driver github.com/go-sql-driver/mysql   PostgreSQL Database Driver github.com/lib/pq   SQLite3 Database Driver github.com/mattn/go-sqlite3    The database drivers can be pulled down from their respective repositories via the go get -u command. However, correct versions of the database drivers will be pulled from their respective repositories based on the go.mod file in the project codebase during the build process.\ngo get -u github.com/lib/pq \n\nOther Dependencies    Library Name Library Location     sqac ORM github.com/1414C/sqac   sluggo Key-Value-Store github.com/1414C/sluggo   jwt-go package github.com/dgrijalva/jwt-go   gorilla mux package github.com/gorilla/mux   web-sockets package golang.org/x/net/websocket   log-writer package github.com/1414C/lw   redis client github.com/garyburd/redigo/redis   memcached client github.com/bradfitz/gomemcache/memcache    If you wish to be certain that you have everything, copy and execute the following script in your development and build environments. go get should pull the libraries based on the content of jiffy\u0026rsquo;s go.mod file.\n#!/usr/bin/bash  go get -u github.com/1414C/sqac go get -u github.com/1414C/sluggo/wscl go get -u github.com/dgrijalva/jwt-go go get -u github.com/dgrijalva/jwt-go/request go get -u github.com/gorilla/mux go get -u golang.org/x/net/websocket go get -u github.com/SAP/go-hdb/driver go get -u github.com/denisenkom/go-mssqldb go get -u github.com/go-sql-driver/mysql go get -u github.com/lib/pq go get -u github.com/mattn/go-sqlite3 go get -u github.com/garyburd/redigo/redis go get -u github.com/bradfitz/gomemcache/memcache "
},
{
	"uri": "https://1414c.github.io/jiffy/overview/ov-content-a/",
	"title": "What is Jiffy?",
	"tags": [],
	"description": "",
	"content": "What does Jiffy do? Jiffy is a model-based RESTful application services generator written in Go. Think of Jiffy as an accelerator: Jiffy generates a complete backend services application, and that generated application is what will be compiled and then run in production.\nJiffy generates a robust go-based application that treats the data persistence layer in a generic manner. This allows the generated application to connect to number of different database systems (outlined below), without any code changes. Generated applications can be targeted at SAP Hana; Postgres, MySQL, MSSQL or SQLite simply by updating one configuration file.\nWhat does a Jiffy application provide? Jiffy consumes simple JSON model-files and uses them to generate a working, secure and extensible application server codebase. Generated applications need no additional coding to run, although in most situations custom checks should be added via extension-points present in the generated codebase.\nJiffy applications provide the following features:\n Generated applications can be connected to Postgres, MSSQL, SAP Hana, SQLite or MariaDB No database specific code is compiled into the binary; an app can be pointed from SQLite to SAP Hana with no code changes Login / authorization management via JWT Built-in support for the creation of signing-keys for JWT (RS256, RS384, RS512, ES256, ES384, ES512) Support for JWT\u0026rsquo;s created by other IDP\u0026rsquo;s (RS256, RS384, RS512, ES256, ES384, ES512) Bcrypt salt/pepper based authentication scheme (passwords are never stored in the db) JSON configuration (model) file(s) for Entity, Index, Foreign-Key and Relationship definitions Models support persistent and non-persistent fields Generated apps create and alter database artifacts based on the model file (tables, indices, sequences etc.) Support for single and composite index declarations via the model file Built-in support for https Built-in normalization and validation in the model-layer Each entity\u0026rsquo;s corresponding service can be enabled and disabled on a per-app-server (process) basis based on config Generates a working set of CRUD-type RESTful services for each entity in the model file Get/set type end-points support \\$count, \\$limit=n, \\$offset=n, \\$orderby=field_name (\\$asc|\\$desc) Supports and generates working end-points for hasOne, hasMany and belongsTo entity relationships Generates static query end-points End-points are secured by way of scope inspection (JWT claims) in the route handler middleware End-point security is generated by default via a auths -\u0026gt; auth-groups -\u0026gt; user arrangement Generates a comprehensive set of working tests (go test) Generated code is easily extended either via direct editing, or through an extension-point concept in the model and controller-layers A leader-election-based group-membership service exists between running instances of the application to facilitate internal caching of user ACL and session information across nodes Jiffy applications are designed for bare-metal, VM, containerized and managed container deployment (Kubernetes)  How does Jiffy interface to the underlying database? Jiffy sits on top of a thin ORM that was written to talk to the SAP Hana in-memory db and then extended to the other supported DBMS systems. The ORM code is very simple and can easily be extended to support other databases. Bear in mind that the generated queries are designed to accommodate the lowest-common-denominator-type CRUD access. It is expected that a serious deployment will involve extending the generated codebase to optimize access in certain scenarios.\nORM\u0026rsquo;s sound like a bad idea to a lot of people. That being said, as soon as one wishes to support more than one type of backend DBMS, a level of abstraction (like a thin ORM) starts to look a bit more appealing. However\u0026hellip;\nIf you look at the generated code and don\u0026rsquo;t like what you see, the ORM handle exposes the standard go/sql and the awesome jmoiron/sqlx libraries to the developer. The generated ORM code can simply be replaced with hand-coded SQL.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/",
	"title": "Jiffy Tutorials",
	"tags": [],
	"description": "",
	"content": "Tutorials Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/interprocess/ip-content-b/",
	"title": "Failure Detector",
	"tags": [],
	"description": "",
	"content": "Group Membership Failure Detector   When discussing deployment of a Jiffy-generated application, each instance of the application is referred to as a process, application instance or node.\n  Processes may fail.\n  Processes exist with one of five publicly disseminated and well-known statuses: {ACTIVE; SUSPECT; FAILED; DEPARTING; DEPARTED}\n  Processes exist with a publicly (within the group) disseminated incarnation number.\n  Process viability is checked at selectable intervals (ping-cycle time) via a configurable ping-ack mechanism.\n  Each process pings all other processes in the group in random order once per ping-cycle. Each process is guaranteed to ping every other process in the group in (2n-1) pings, where n is the number of non-failed processes in the process-list.\n  Processes failing a ping-ack exchange are not immediately failed but are moved into the SUSPECT state.\n  The failure-threshold outlining the number of permissible ping-ack failures for a SUSPECT process is configurable via the \u0026lsquo;failure_threshold\u0026rsquo; key in the application configuration file. At the moment, the configuration value is used directly, but in large groups or groups where the number of active members varies greatly it would make sense to use the configuration value in combination with the number of active processes in the group to determine an appropriate SUSPECT to FAILURE threshold value.\n  The local status-count of the SUSPECT process is incremented once for each failed ping or notification of a failed Ping from another process in the group.\n  Process status is disseminated across all processes by way of a gossip-based infection-style piggybacking of process information on top of a process\u0026rsquo;s outgoing Ping messages. For example:\n Pinging process (Pi) sends a Ping containing it\u0026rsquo;s local group-membership list to a target process (Pj). Process Pj receives the Ping, takes note of the included group-membership list from Pi, updates its own group-membership list based on the received process status information, then sends an Ack message back to \u0026gt; Pi. Ping status scenarios are broken out in a subsequent section.\n   Once a SUSPECT process (Pj) reaches the failure-threshold in any pinging process (Pi), process Pi moves process Pj from the SUSPECT state to the FAILED state in its local group-membership list. A FAILED status is immutable, and the failed process will be removed from the group via the ping-based status dissemination.\n  If a process (Pi) receives a Ping message from another process (Pj) indicating that Pi is in a SUSPECT state, process Pi increments it\u0026rsquo;s incarnation number and continues to participate in the ping-cycle. Processes receiving pings from process Pi take note of Pi\u0026rsquo;s new incarnation number and set their internal record of Pi back to an ACTIVE status. However, if any process in the group has already set Pi\u0026rsquo;s status to FAILED this will override Pi\u0026rsquo;s incarnation number-based signal of liveness and all members will set their Pi status to FAILED after which Pi will be removed from the group.\n  It may be desirable to enhance the application slightly in this area to cause process-failures to trigger some sort of notification.\n  Typically the implementer should not have to worry about the failure detector beyond establishing reasonable limits for SUSPECT status Ping failures and setting a reasonable ping-cycle time in the configuration file.\nProcess Status Scenarios Consider a group-membership of {P1; P2; P3} where failure-threshold == 3:\nP1 Ping-Cycle\n (P1-Ping) -\u0026gt; (P2) (P2-Ack) -\u0026gt; (P1) (P1-Ping) -\u0026gt; (P3) (P3-Ack) -\u0026gt; (P1) (P1-Ping) -\u0026gt; (P1) (P1-Ack) -\u0026gt; (P1)  P2 Ping-Cycle\n (P2-Ping) -\u0026gt; (P1\u0026gt; (P1-Ack) -\u0026gt; (P2) (P2-Ping) -\u0026gt; (P3) (P3-Ack) -\u0026gt; (P2) (P2-Ping) -\u0026gt; (P2) (P2-Ack) -\u0026gt; (P2)  P3 Ping-Cycle\n (P3-Ping) -\u0026gt; (P1) (P1-Ack) -\u0026gt; (P3) (P3-Ping) -\u0026gt; (P2) (P2-Ack) -\u0026gt; (P3) (P3-Ping) -\u0026gt; (P3) (P3-Ack) -\u0026gt; (P3)  Example 1 (P1-Ping-1) -\u0026gt; (P2)\n(P2-NoAck)\nP1 moves P2\u0026rsquo;s status to SUSPECT in the local P1 group-membership list and sets the P2 status-count back to 1.\n\u0026hellip; ping-cycle completes\n (P1-Ping-2) -\u0026gt; (P2)\n(P2-NoAck)\nP1 leaves P2\u0026rsquo;s status as SUSPECT in the local P1 group-membership list and increments the P2 status-count by 1 (==2).\n\u0026hellip; ping-cycle completes\n (P1-Ping-3) -\u0026gt; (P2)\n(P2-NoAck)\nP1 moves P2\u0026rsquo;s status to FAILED in the local P1 group-membership list and increments the P2 status-count by 1 (==3).\n\u0026hellip; ping-cycle completes\nAs P1\u0026rsquo;s group-membership list is being updated with the P2 ping failures, P1 is disseminating that information to the other processes in the group. It is likely that other processes in the group have also noticed that P2 is not responding, so these processes are also disseminating the P2 SUSPECT status to all other processes in the group - including P1. As a result, failing processes will accrue SUSPECT status counts rapidly in each process\u0026rsquo;s group-membership list; the failure threshold value should be computed as a product of the number of running processes in the group (TODO).\nExample 2 (P1-Ping-1) -\u0026gt; (P2)\n(P2-NoAck)\nP1 moves P2\u0026rsquo;s status to SUSPECT in the local P1 group-membership list and sets the P2 status-count back to 1.\n\u0026hellip; ping -cycle completes\n (P1-Ping-2) -\u0026gt; (P2)\n(P2-NoAck)\nP1 leaves P2\u0026rsquo;s status as SUSPECT in the local P1 group-membership list and increments the P2 status-count by 1 (==2).\n\u0026hellip; ping-cycle completes\n (P1-Ping-3) -\u0026gt; (P2)\n(P2-Ack) -\u0026gt; (P1)\nP1 may set P2\u0026rsquo;s status back to ALIVE in the local P1 group-membership list and reset the P2 status-count back to 1).\n\u0026hellip; ping-cycle completes\n Why would P1 not guarantee the reset of P2\u0026rsquo;s status to the ALIVE state after receiving an Ack for last Ping message?\nAs the ping-cycles run, the possibility exists that if P2 were to come back online it may receive a Ping message containing a group-membership list where it (P2) is in a SUSPECT state. If P2 sees that it is SUSPECT, it reacts by incrementing it\u0026rsquo;s incarnation-number which is then relayed to the group-members via P2\u0026rsquo;s ping messages. When a process (let\u0026rsquo;s say P1), sees that SUSPECT process P2 has sent a Ping, it checks the embedded incarnation-number to see if it is greater than the P2 incarnation-number presently stored in P1\u0026rsquo;s local group-membership list. If the incarnation-number contained in the Ping is greater, P1 updates it\u0026rsquo;s group-membership list to indicate that P2 is ALIVE with a new incarnation number. If the incarnation-number in the (P2-Ping) is lower or the same as that of the P2 record in the local P1 group-membership list, the Ping is discarded.\nP2 can still send the Ack\u0026rsquo;s in response to Pings coming from other processes, and due to the concurrent nature of the service, it may well send a Ping to the other group-members (P1 for example) in time to prevent itself from being failed, but this is an unavoidable edge-case. When a SUSPECT process recovers to the extent that it is reachable again, and one or more group-members are very close to reaching the failure-threshold for the process in question, there is a chance that the recovered process will be failed anyway.\nThere is a lot more to write here in order to completely describe the mechanics of how the failure detector works. Additionally, the failure detector operates using a bully-type algorithm that has been abridged slightly to favor the highest known process as the new leader is a current-leader failure scenario. Highest known process is determined locally through inspection of each application instance\u0026rsquo;s group-membership map. This is in contrast to the typical bully implementation where ELECT-OK messages are used alongside local introspection. The codebase contains a full bully algorithm implementation, but the ELECT-OK message pair have been commented out for now. There is a tentative plan to do one or both of the following:\n Reimplement the failure detector using the Raft algorithm. Retool the jiffy application to create applications tightly integrated into the Kubernetes / CoreOS ecosystems.  "
},
{
	"uri": "https://1414c.github.io/jiffy/accesscontrol/ac-content-b/",
	"title": "Authorizations",
	"tags": [],
	"description": "",
	"content": "Standard CRUD Authorizations As discussed in the Access Control Overview, each of the generated services end-points is assigned a name which is used as an Authorization object by the router middleware.\nStandard CRUD end-points for entity Library are generated as follows:\n// ====================== Library protected routes for standard CRUD access ====================== a.router.HandleFunc(\u0026#34;/librarys\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibrarys)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.GET_SET\u0026#34;) a.router.HandleFunc(\u0026#34;/library\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Create)).Methods(\u0026#34;POST\u0026#34;).Name(\u0026#34;library.CREATE\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Get)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.GET_ID\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Update)).Methods(\u0026#34;PUT\u0026#34;).Name(\u0026#34;library.UPDATE\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Delete)).Methods(\u0026#34;DELETE\u0026#34;).Name(\u0026#34;library.DELETE\u0026#34;) Notice that each end-point handler is assigned a name via the gorilla.mux.Route.Name(\u0026ldquo;string\u0026rdquo;) method. The generated end-point names follow the standard shown here, but in practice it is safe to change them to whatever works best for your implementation. Duplicate names in the same router will cause the existing name-route combination to be overwritten by the latest name-route addition as per the gorilla API docs. Avoid the use of duplicate names. The set of generated Authorizations for the Library entitys CRUD end-points are:\n library.GET_SET library.CREATE library.GET_ID library.UPDATE library.DELETE  Static Filter Authorizations Static Filter end-points for entity Library follow the same rules as mentioned above and are generated as follows:\n//=================================== Library Static Filters =================================== // http://127.0.0.1:\u0026lt;port\u0026gt;/librarys/name(EQ \u0026#39;\u0026lt;sel_string\u0026gt;\u0026#39;) a.router.HandleFunc(\u0026#34;/librarys/name{name:[(]+(?:EQ|eq|LIKE|like)+[ \u0026#39;]+[a-zA-Z0-9_]+[\u0026#39;)]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibrarysByName)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.STATICFLTR_ByName\u0026#34;) // http://127.0.0.1:\u0026lt;port\u0026gt;/librarys/city(EQ \u0026#39;\u0026lt;sel_string\u0026gt;\u0026#39;) a.router.HandleFunc(\u0026#34;/librarys/city{city:[(]+(?:EQ|eq)+[ \u0026#39;]+[a-zA-Z0-9_]+[\u0026#39;)]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibrarysByCity)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.STATICFLTR_ByCity\u0026#34;) The set of generated Authorizations for the Library entity\u0026rsquo;s static filter end-points are:\n library.STATICFLTR_ByName library.STATICFLTR_ByCity  Relation Authorizations Relation end-points for entity Library follow the same rules as mentioned above and are generated as follows:\n//====================================== Library Relations ======================================  // hasMany relation ToBooks for Library  a.router.HandleFunc(\u0026#34;/library/{library_id:[0-9]+}/tobooks\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibraryToBooks)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.REL_tobooks\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{library_id:[0-9]+}/tobooks/{book_id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibraryToBooks)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.REL_tobooks_id\u0026#34;) The set of generated Authorizations for the Library entity\u0026rsquo;s relation end-points are:\n library.REL_tobooks library.REL_tobooks_id  Authorization Generation Authorizations are assigned to end-points in the route declarations as described in the preceding sections. They are also added to a table (auth) in the backing database, as are the User Groups (table usrgroup) and the assignment of Authorizations to the same (via table groupauth).\nAt application start-up, a walk of the router is performed in order to obtain a complete list of Authorizations. This is necessary, as changes may have been made to the application since the last time it was run. For example, a new entity may have been added; the Authorizations for the corresponding end-points need to be made available via the creation of new entries in the auth table. The creation of the new Authorizations in the auth table does not add them to any User Groups, but simply makes them available for use.\nAuthorization Maintenance The end-points related to Authorization, User Group and User maintenance are protected by default. This means that in order to perform any activities (such as create Users) in the generated application, an initial User belonging to a User Group with sufficient Authorizations is required. To this end, a User called \u0026lsquo;admin\u0026rsquo; and a User Group called \u0026lsquo;Super\u0026rsquo; are created by default the first time the application is run. This unfolds as follows:\n A complete list of the route Authorizations is obtained by walking the router as described above in the Authorization Generation section. Table usrgroup is checked for the existence of the \u0026lsquo;Super\u0026rsquo; group. If the \u0026lsquo;Super\u0026rsquo; User Group is not found, it is created. All existing Authorization allocations to the \u0026lsquo;Super\u0026rsquo; User Group are deleted. The list of route Authorizations is then used to allocate Authorization for each end-point to the \u0026lsquo;Super\u0026rsquo; User Group. A check for the existence of the \u0026lsquo;admin\u0026rsquo; user is executed against the usr table. If the \u0026lsquo;admin\u0026rsquo; user does not exist, it is created as a member of the \u0026lsquo;Super\u0026rsquo; User Group, with an initial password of \u0026lsquo;initpass\u0026rsquo;. As the User Group Authorizations are cached on all application instances in the pool, the cache is re-initialized locally and then distributed to the other pool members so that the \u0026lsquo;Super\u0026rsquo; group is generally available.  It is possible to force a rebuild of the \u0026lsquo;Super\u0026rsquo; User Group\u0026rsquo;s Authorization allocations by starting the generated application with the -rs (rebuild super) flag. This will force the application to run through the preceding list of steps, resulting in a \u0026lsquo;Super\u0026rsquo; User Group that contains a complete list of the Authorizations needed to access all end-points, as well as removing any end-point Authorizations that may no longer exist. Only the \u0026lsquo;Super\u0026rsquo; User Group may be updated in this manner. Changes to existing User Groups must be carried out manually by an authorized user via the end-points related to User, User Group and Authorization maintenance.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-b/",
	"title": "Default Configuration",
	"tags": [],
	"description": "",
	"content": "Default Config The following command strings may be used to run the program using a set of default configuration that has been hard-coded into the source files. The default configuration may be edited in the generated appobj/appconf.go file to suit local requirements. The default application settings are shown in the server configuration file format. The default configuration publishes the end-points on port 3000 over http due to the absence of the cert_file and key_file values.\ngo run main.go or\ngo run main.go -def Default Configuration Settings The default configuration settings are shown below:\n{ \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;def\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;user\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34;, \u0026#34;ormLogActive\u0026#34;: true }, \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, \u0026#34;logging\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;callLocation\u0026#34;: false, \u0026#34;colorMsgTypes\u0026#34;: true, \u0026#34;infoMsgs\u0026#34;: true, \u0026#34;warningMsgs\u0026#34;: true, \u0026#34;errorMsgs\u0026#34;: true, \u0026#34;debugMsgs\u0026#34;: false, \u0026#34;traceMsgs\u0026#34;: false }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } "
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/using-docker/dr-content-b/",
	"title": "Jiffy with Docker and External PostgreSQL",
	"tags": [],
	"description": "",
	"content": "Overview We will create and deploy a sample application inside a Docker container. The containerized application will run as a single-instance and communicate with a Postgres database on the container-host\u0026rsquo;s network. In this example the Postgres database will not be running in a container.\nAs in the Jiffy with Docker and SQLite tutorial, our Dockerfile will be quite simple and we will go with some of the docker build defaults. These include allowing docker build to determine the ipv4 address to assign to the image, and also using the default Docker networking setup (\u0026ndash;network-bridge).\nNote that this is a setup for testing and development only. When deploying a jiffy-application with Docker, you should use a container clustering/management solution (Docker Swarm, Kubernetes, Rancher \u0026hellip;). Doing will simplify application scaling and is also necessary in order to support the peer-to-peer networking requirement.\nSteps  Verify the Jiffy installation. Generate a new application using a sample model file from the Jiffy source-tree. Edit the application\u0026rsquo;s configuration file for Postgres and Docker use. Statically compile a binary for inclusion in the Docker image. Write a simple Dockerfile to create a runnable image. Write a small script to update the image\u0026rsquo;s .dev.config.json file with the container\u0026rsquo;s ipv4 address Create a container from the image and start the container. Test access to the application running in the container using Postman. Stop the container. Cleanup the Docker environment.  Verify Jiffy Installation Ensure that Jiffy has been installed on your workstation by following the instructions provided in the Jiffy Installation section.\nGenerate the Application We will generate a new application called pgelibraryapp from a model file that contains a \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity. Two relationships are maintained in the model; a Library hasMany Books and a Book belongsTo a specific Library. An application generated from this model will allow many Jiffy application features to be tested.\nOpen a terminal window on your workstation and run jiffy using the Library-Book model file to generate the source-code for our test application as follows:\njiffy -m $GOPATH/src/github.com/1414C/jiffy/support/testing_models/hasManyBelongsTo.json -p /exp/pgelibraryapp Remember that jiffys -p flag expects to be provided with an existing path underneath your $GOPATH/src folder. In the example invocation shown above, jiffy will create the pgelibraryapp folder underneath $GOPATH/src/exp/ and then write the generated source-code to this location.\nExecution of the generator (jiffy) should result in output similar to:\n2018/06/22 12:26:57 generated: /Users/stevem/gowork/src/exp/pgelibraryapp/models/librarym.go 2018/06/22 12:26:57 generated: /Users/stevem/gowork/src/exp/pgelibraryapp/models/librarym_ext.go 2018/06/22 12:26:57 generated: /Users/stevem/gowork/src/exp/pgelibraryapp/controllers/libraryc.go ... ... ... 2018/06/22 12:26:59 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/pgelibraryapp/util/strings.go 2018/06/22 12:26:59 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/pgelibraryapp/util/strings.go 2018/06/22 12:26:59 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/pgelibraryapp/appobj/appconf.go 2018/06/22 12:26:59 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/pgelibraryapp/appobj/appconf.go Your output may look slightly different, particularly the database connection test which will almost certainly fail. This is nothing to be concerned about, as the generator is attempting to connect to a local Postgres instance using bad credentials. \nEdit the Application Configuration File Update Address Keys The next step is to edit the generated application\u0026rsquo;s configuration files. Docker allocates a static ip-address for each container by default, and we will use that address in our application\u0026rsquo;s configuration file. \u0026lsquo;external_address\u0026rsquo; refers to the address at which the application\u0026rsquo;s end-points will be available, while the \u0026lsquo;internal_address\u0026rsquo; is used for cache updates and interprocess communication over web-socket connections. Strictly speaking, in a single-instance Docker deployment we could get away with maintaining the address-keys as follows:\n.dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... } However, we will show how to obtain and insert the container\u0026rsquo;s real ip-address into the configuration file. This will be useful later if you deploy multiple application instances in Docker containers.\nOpen the generated .dev.config.json file in an editor and update the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; values with \u0026ldquo;xxx.xxx.xxx.xxx:8080\u0026rdquo; and \u0026ldquo;xxx.xxx.xxx.xxx:4444\u0026rdquo; respectively. Using an illegal ipv4 address as a placeholder/mask ensures that the container will not start in the event that the container\u0026rsquo;s address could not be assigned to the config keys. When you have finished, save the file after verifying that it looks like this:\n.dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... } Update the Application\u0026rsquo;s Database Config Jiffy generates configuration files targeting a Postgres database by default. Maintain the values in the \u0026lsquo;database\u0026rsquo; block of the *.dev.config.json; file as necessary in order to gain access to your testing database:\n.dev.config.json { ... \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;192.168.1.65\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34; }, ... } Once the database block in .dev.config.json has been updated, save the file and close the editor.\nEnsure PostgreSQL is Available By default, Postgres only allows connections from the localhost (127.0.0.1). If your Postgres database is running on another machine, you will need to ensure that it allows connections from remote hosts. A quick web-search will reveal how to maintain Postgres\u0026rsquo;s postgresql.conf and pg_hba.conf files to allow remote connections to the database. Make sure that you are able to connect to your Postgres database from the Docker host environment before continuing.\nUpdate the Application\u0026rsquo;s Group Leader KVS Config Jiffy generates configuration files supporting a stand-alone / local group-leadership KVS by default. Examine the \u0026lsquo;group_leader_kvs\u0026rsquo; block in *.config.json to ensure the \u0026lsquo;local_standalone\u0026rsquo; KVS option is active as shown below:\n.dev.config.json { ... \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, ... } \n\nBuild a Static Application Binary for Alpine Linux Next, we need to build a static application binary for linux/amd64. To build the application, a number of dependencies are required as outlined in the Jiffy Dependencies section of the documentation. Check that your build environment contains the correct packages and import any that are missing.\nThis tutorial uses the popular Alpine Linux distribution as the basis for the new container image. Alpine Linux is a small and sparse distribution making it nice for use with containers. There are a few things to be aware of however\u0026hellip;\nAlpine Linux is based on lib-musl which means that binaries built by go build where the source makes use of cgo must target lib-musl rather than lib-gcc. The binary resulting from the typical \u0026lsquo;GOOS=linux GOARCH=amd64 go build -o main .\u0026rsquo; command would almost certainly not work on Alpine. The good news is that it is quite easy to build with musl-gcc, the bad news is that musl-gcc is available for Linux only. If you are working on a system in which lib-musl is not supported, you will need to run the go build command in a supported build environment. Most Linux distributions and architectures are supported.\nCheck if lib-musl has been installed in the build environment by running the which command:\nwhich musl-gcc If musl-gcc was found in the $PATH, which will return output similar to:\n/usr/bin/musl-gcc If musl-gcc was not found, follow the installation instructions below to download and install the required packages.\nInstall Musl-gcc We will go over how to install musl-gcc on a Debian system, but the steps are largely the same for any Linux distribution. Use your distribution\u0026rsquo;s package manager to install the musl lib, musl development files and musl development tools. Run the following commands (or their equivalents) in a terminal window on your Linux build system:\nsudo apt-get update sudo apt-get install musl sudo apt-get install musl-dev sudo apt-get install musl-tools Check to make sure that musl-gcc is now in the $PATH:\nwhich musl-gcc Build a Static Application Binary After ensuring that all of the required dependencies have been installed in the build environment, run the following command to build a statically-linked binary called main for the Alpine Linux target OS. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Adjust the GOARCH environment variable as necessary:\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build --ldflags \u0026#39;-w -linkmode external -extldflags \u0026#34;-static\u0026#34;\u0026#39; -a -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. Setting \u0026ndash;ldflags as shown instructs go build to produce a statically linked binary. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped Build a Dynamically-Linked Application Binary This is optional and will produce a marginally smaller binary. We will not use a dynamically-linked binary in our image, but have included a suitable go build command for reference purposes.\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build -a -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. go build produces dynamically-linked binaries by default, so no linker instructions have been provided. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-musl-x86_64.so.1, not stripped \n\nCreate a Dockerfile Verify that you have Docker installed in your build environment. The easiest way to do this is to run which docker in a terminal window to ensure the docker application is in the $PATH. If there is no response, check the $PATH or install Docker following the instructions at www.docker.com. Verify that the Docker daemon is running by opening a terminal window in your build environment and running the docker ps command. If Docker is not running, an error message will be displayed. Start the Docker daemon before continuing.\nIn order to deploy the compiled application in a Docker container, we need to create a Dockerfile. The docker build command uses the Dockerfile as a set of instructions when building an image. As mentioned previously, we will use Alpine Linux as the foundation (base image) for the new Docker container image. Dockerhub has a number of pre-defined images that are available to be \u0026lsquo;pulled\u0026rsquo; into locally defined custom images.\nCreate a new file called Dockerfile in the root folder of the libappmulti source-tree and open it in your editor. Copy the following content into the new Dockerfile. An effort has been made to briefly describe what each line of the Dockerfile is used for.\n# use the official docker hub alpine:latest base imageFROMalpine:latest# set the maintainer information for the new imageLABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34;# add the compiled application binary to the root folder of the new imageADD main ./# copy the configuration file to the root folder of the new imageCOPY .dev.config.json .# add the entrypoint.sh shell script to the root folder of the new imageADD docker-entrypoint.sh .# set widely exectuable permission on the shell-scriptRUN /bin/chmod 777 docker-entrypoint.sh# create a directory in the root folder of the new image to hold the jwt signing keysRUN mkdir jwtkeys# copy the jwtkeys folder content into the image\u0026#39;s /jwtkeys folderCOPY jwtkeys ./jwtkeys# set container environment variable $PORT to 8080ENV PORT 8080# container will listen on port tcp/8080EXPOSE8080# install sqlite3 into the imageRUN apk update \\  \u0026amp;\u0026amp; apk add sqlite \\ \u0026amp;\u0026amp; apk add socat# add unix file commandRUN apk add file# create a test.db file in the root folder (don\u0026#39;t really need to do this,# but it is a nice test when getting started)RUN /usr/bin/sqlite3 /test.db# set the container entrypoint - container executes this once it is up and runningENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;]# specify the flag(s) to be used with the ENTRYPOINTCMD [\u0026#34;-dev\u0026#34;]\n\nCreate the Entrypoint Script In a previous step .dev.config.json was updated with xxx.xxx.xxx.xxx ipv4 address masks. In order to replace the masks with the container\u0026rsquo;s ipv4 address, docker run and docker start will execute the docker-entrypoint.sh when running a container instance based on the image definition. At the moment this is a problem however, as we have not written the script yet. Create a new file called docker-entrypoint.sh in the root folder of the pgelibraryapp source-tree and open it in your editor. Copy the following content into the new docker-entrypoint.sh file:\n#!/bin/sh  # get the ipv4 address assigned to eth0 replace=$(ifconfig eth0 | grep \u0026#34;inet addr\u0026#34; | cut -d \u0026#39;:\u0026#39; -f 2 | cut -d \u0026#39; \u0026#39; -f 1) # set a variable with the value we are planning to replace search=\u0026#34;xxx.xxx.xxx.xxx\u0026#34; # check that variable replace has something in it if [ -z \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;Did not get an address value for eth0\u0026#34; elif [ -n \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;${replace}found\u0026#34; # replace all instances of \u0026#39;xxx.xxx.xxx.xxx\u0026#39; in .dev.config.json # with the ipv4 address in the ${replace} variable sed -i \u0026#34;s/${search}/${replace}/g\u0026#34; .dev.config.json exec /main \u0026#34;$@\u0026#34; fi  Note that the docker-entrypoint.sh script assumes the ipv4 address should be read from the eth0 interface. This may not be the case in more complex deployments.\n \n\nBuild the Image Assuming the previous steps have been successful, it is now time to build the new Docker image. Execute the following command from the pgelibraryapp root folder:\ndocker build -t pgelibraryapp . Running docker build as shown instructs Docker to construct an image called pgelibraryapp using the Dockerfile in the current working directory. You should see output similar to:\nSending build context to Docker daemon 14.4MB Step 1/17 : FROM alpine:3.7 ---\u0026gt; 3fd9065eaf02 Step 2/17 : LABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34; ---\u0026gt; Running in bf4ee48b2816 Removing intermediate container bf4ee48b2816 ---\u0026gt; f6450f88abb9 Step 3/17 : ADD main ./ ---\u0026gt; 0339472c223a Step 4/17 : COPY .dev.config.json . ---\u0026gt; ea4d0e22dda8 Step 5/17 : ADD docker-entrypoint.sh . ---\u0026gt; 3a091afcc4e6 Step 6/17 : RUN /bin/chmod 777 docker-entrypoint.sh ---\u0026gt; Running in 02bc2611f675 Removing intermediate container 02bc2611f675 ---\u0026gt; 82b131becf0a Step 7/17 : RUN mkdir jwtkeys ---\u0026gt; Running in 5dc37bbb6d90 Removing intermediate container 5dc37bbb6d90 ---\u0026gt; ce27be862527 Step 8/17 : COPY jwtkeys ./jwtkeys ---\u0026gt; fad638ee093f Step 9/17 : ENV PORT 8080 ---\u0026gt; Running in ebf5a4645a24 Removing intermediate container ebf5a4645a24 ---\u0026gt; f73fa9102cca Step 10/17 : EXPOSE 8080 ---\u0026gt; Running in 8ec67da3a90f Removing intermediate container 8ec67da3a90f ---\u0026gt; d943968d2257 Step 11/17 : RUN apk update ---\u0026gt; Running in 4f036d66ca8e fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz v3.7.0-215-g16971064c0 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main] v3.7.0-207-gac61833f9b [http://dl-cdn.alpinelinux.org/alpine/v3.7/community] OK: 9054 distinct packages available Removing intermediate container 4f036d66ca8e ---\u0026gt; 15aef1a3a835 Step 12/17 : RUN apk add file ---\u0026gt; Running in 7444e203db73 (1/2) Installing libmagic (5.32-r0) (2/2) Installing file (5.32-r0) Executing busybox-1.27.2-r7.trigger OK: 9 MiB in 13 packages Removing intermediate container 7444e203db73 ---\u0026gt; 92bf177f86b7 Step 13/17 : RUN apk add busybox-extras ---\u0026gt; Running in 662591e9e2bd (1/1) Installing busybox-extras (1.27.2-r11) Executing busybox-extras-1.27.2-r11.post-install Executing busybox-1.27.2-r7.trigger OK: 9 MiB in 14 packages Removing intermediate container 662591e9e2bd ---\u0026gt; 80ab4f590c82 Step 14/17 : RUN apk add openssh-client ---\u0026gt; Running in 5baaa52529ab (1/2) Installing openssh-keygen (7.5_p1-r8) (2/2) Installing openssh-client (7.5_p1-r8) Executing busybox-1.27.2-r7.trigger OK: 12 MiB in 16 packages Removing intermediate container 5baaa52529ab ---\u0026gt; 8d1b14444e72 Step 15/17 : RUN apk add postgresql-client ---\u0026gt; Running in 2a3edc09549a (1/9) Installing ncurses-terminfo-base (6.0_p20171125-r0) (2/9) Installing ncurses-terminfo (6.0_p20171125-r0) (3/9) Installing ncurses-libs (6.0_p20171125-r0) (4/9) Installing libedit (20170329.3.1-r3) (5/9) Installing db (5.3.28-r0) (6/9) Installing libsasl (2.1.26-r11) (7/9) Installing libldap (2.4.45-r3) (8/9) Installing libpq (10.4-r0) (9/9) Installing postgresql-client (10.4-r0) Executing busybox-1.27.2-r7.trigger OK: 24 MiB in 25 packages Removing intermediate container 2a3edc09549a ---\u0026gt; 9d5c92cc037f Step 16/17 : ENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;] ---\u0026gt; Running in 499c637488e1 Removing intermediate container 499c637488e1 ---\u0026gt; 6b4c3914a599 Step 17/17 : CMD [\u0026#34;-dev\u0026#34;] ---\u0026gt; Running in 401321fde538 Removing intermediate container 401321fde538 ---\u0026gt; 32045cc2b080 Successfully built 32045cc2b080 Successfully tagged pgelibraryapp:latest Aardvark:pgelibraryapp stevem$ View the Image You can run the docker image command to view some basic data regarding the new image:\ndocker image ls pgelib* You should see output similar to:\nREPOSITORY TAG IMAGE ID CREATED SIZE pgelibraryapp latest 32045cc2b080 About a minute ago 35MB Use the Image Once the image has been created, the next step is to use it to create a container. This can be done in a single step where Docker creates the container and then starts it. Run the following command to create and start a new container from the pgelibraryapp image:\ndocker run --name pgelibraryapp -p 8080:8080 -d pgelibraryapp If all went well, docker created a container from the pgelibraryapp image and then started it. The flags provided with the docker run command do the following:\n \u0026ndash;name - the image to use -p - used to bind the host\u0026rsquo;s tcp/8080 port to container port tcp/8080 -d - detach the container from the terminal session  Check the Container Status Container status can be checked via the docker ps command:\ndocker ps -a You should see output similar to:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e04bbd64dfba pgelibraryapp \u0026#34;/main -dev\u0026#34; 3 seconds ago Up 3 seconds 0.0.0.0:8080-\u0026gt;8080/tcp pgelibraryapp The output of the command shows that the pgelibraryapp container was started with entrypoint \u0026lsquo;/main -dev\u0026rsquo; and that container port :8080 is mapped to host port :8080.\nSSH into the Container We can ssh into the running container to see what is going on using the command shown in the following terminal session. The command logs in as root using the specified interactive shell (in this case /bin/sh). Check that \u0026lsquo;main -dev\u0026rsquo; is running as expected using the Linux ps command.\ndocker exec -it pgelibraryapp /bin/sh / # ps -ef PID USER TIME COMMAND 1 root 0:00 /main -dev 12 root 0:00 /bin/sh 19 root 0:00 ps -ef / # Take a look around the in the container environment and verify that the content of .dev.config.json has been updated with the correct ip-address using the ifconfig/cat commands. Remember that the docker container is created with a static ipv4 address assigned to the eth0 interface. Verify that the eth0 ipv4 address has been added to the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; keys in .dev.config.json.\n/ # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:401 errors:0 dropped:0 overruns:0 frame:0 TX packets:275 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:61539 (60.0 KiB) TX bytes:26368 (25.7 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:401 errors:0 dropped:0 overruns:0 frame:0 TX packets:401 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:70197 (68.5 KiB) TX bytes:70197 (68.5 KiB) / # cat .dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;172.17.0.2:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;172.17.0.2:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... ... \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] }/ # \n\nUse the psql Client to Connect to Postgres We installed the Postgres client package into the pgelibraryapp image by including it in our Dockerfile. Make sure that the pgelibraryapp container is running and that you have logged in via the docker exec -it pgelibraryapp /bin/sh command. Try to connect to your Postgres database as follows:\n/ # psql -h 192.168.1.65 -d postgres -U postgres Password for user postgres: ******************* psql (10.4, server 9.5.3) Type \u0026#34;help\u0026#34; for help. postgres=# Connecting to the database using psql is just for demonstration purposes. If the database was not reachable the container would not have started. For a discussion of what to do if the container entrypoint fails, see the Troubleshooting section of this document. \nLogin to the Application Launch Postman or your favorite RESTful service testing tool and specify a target URL of: http://172.17.0.2:8080/usr/login making sure to select the http POST method. Maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a jiffy application is an email address, but an exception is made for the default administration user definition.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.  If all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single 'token' tag containing a jumble of letters and numbers. This is the JWT that will be used to validate the 'admin' user's authorization to access the 'Library' and 'Book' entity service end-points. If you want to read more about JWT's, [jwt.io](https://jwt.io) is a good place to start, or you can refer to the [Access Control](/jiffy/accesscontrol/index.html) section of this document set. ![Login](../../images/login-b.jpg)  Create a Library We will create a new \u0026lsquo;Library\u0026rsquo; entity. Configure your test-tool to POST to the \u0026lsquo;library\u0026rsquo; service as shown in the following image:\nCopy the JWT from the login session and paste it into the new POST request\u0026rsquo;s Authorization header field as shown below and then submit the request to the application.\nFollowing submission, a new \u0026lsquo;Library\u0026rsquo; entity should have been created:\nCreate another \u0026lsquo;Library\u0026rsquo; entity using the \u0026lsquo;Create a Library\u0026rsquo; steps and then request a list of Library entities using the GET ../librarys end-point:\nCreate a Book Next, we will create a \u0026lsquo;Book\u0026rsquo; entity and allocate it to \u0026lsquo;Library\u0026rsquo; 1. Configure your test-tool to POST to the \u0026lsquo;book\u0026rsquo; service as shown in the following image:\nFollowing the submission, a new \u0026lsquo;Book\u0026rsquo; entity should have been created:\nCreate a few more \u0026lsquo;Book\u0026rsquo; entities using the \u0026lsquo;Create a Book\u0026rsquo; steps and allocate them to your \u0026lsquo;Library\u0026rsquo; entities. When you have finished, request a list of \u0026lsquo;Book\u0026rsquo; entities using the GET ../books end-point:\nLibrary toBooks Based on the \u0026lsquo;hasMany\u0026rsquo; relationship between the \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity\u0026rsquo;s, we can get the number of \u0026lsquo;Book\u0026rsquo; entities belonging to \u0026lsquo;Library\u0026rsquo; 1 as follows:\nRemove the $count suffix from the URL to get the complete list of Book entities belonging to \u0026lsquo;Library\u0026rsquo; 1:\nBook toLibrary A reciprocal \u0026lsquo;belongsTo\u0026rsquo; relationship exists between the \u0026lsquo;Book\u0026rsquo; and \u0026lsquo;Library\u0026rsquo; entity definitions. Select a \u0026lsquo;Book\u0026rsquo; entity and verify that the \u0026lsquo;belongsTo\u0026rsquo; relationship works as expected:\nCheck the list of filters and commands along with the Library and Book models to see what can be appended to the the service end-points. Try some things out.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/extensionpoints/ep-content-b/",
	"title": "Controller Extension Points",
	"tags": [],
	"description": "",
	"content": "Overview Controller extension-points exist for the Create, Update and Get CRUD operations. Each operation has a related extension-point interface, for which an empty implementation may be created when the application is generated. If the generator sees that the extension-point implementation file for an entity has already been created, it will not over-write or create a new version.\nFile myapp/controllers/ext/extc_interfaces.go contains the generated entity controller extension-point interface declarations. Each interface and interface method is documented in this file.\nFile myapp/controllers/ext/\u0026lt;entity_name\u0026gt;c_ext.go is generated for each entity with empty extension-point interface implementations. This file may be edited by the application developer to add custom application logic.\nController Extension-Point Interfaces  Interface ControllerCreateExt   BeforeFirst(w http.ResponseWriter, r *http.Request) error BeforeFirst is a controller extension-point that can be implemented in order to examine and potentially reject a Create entity request. This extension-point is the first code executed in the controller's Create method. Authentication and Authorization checks should be performed upstream in the route middleware-layer and detailed checks of a request.Body should be carried out by the validator in the model-layer.    AfterBodyDecode(ent interface{}) error AfterBodyDecode is a controller extension-point that can be implemented to perform preliminary checks and changes to the unmarshalled content of the request.Body. Detailed checks of the unmarshalled data from the request.Body should be carried out by the validator in the model-layer. This extension-point should only be used to carry out deal-breaker checks and perhaps to default data in the entity struct prior to calling the validator/normalization methods in the model-layer.    BeforeResponse(ent interface{}) error BeforeResponse is an extension-point that can be implemented to perform checks following the return of the call to the model-layer. At this point, changes to the db will have been made, so failing the call should take this into consideration.     Interface ControllerUpdateExt   BeforeFirst(w http.ResponseWriter, r *http.Request) error BeforeFirst is a controller extension-point that can be implemented in order to examine and potentially reject an Update entity request. This extension-point is the first code executed in the controller's Update method. Authentication and Authorization checks should be performed upstream in the route middleware-layer and detailed checks of a request.Body should be carried out by the validator in the model-layer.    AfterBodyDecode(ent interface{}) error AfterBodyDecode is a controller extension-point that can be implemented to perform preliminary checks and changes to the unmarshalled content of the request.Body. Detailed checks of the unmarshalled data from the request.Body should be carried out by the validator in the model-layer. This extension-point should only be used to carry out deal-breaker checks and perhaps to default data in the entity struct prior to calling the validator/normalization methods in the model-layer.    BeforeResponse(ent interface{}) error BeforeResponse is a controller extension-point that can be implemented to perform checks following the return of the call to the model-layer. At this point, changes to the db will have been made, so failing the call should take this into consideration.     Interface ControllerGetExt   BeforeFirst(w http.ResponseWriter, r *http.Request) error BeforeFirst is a controller extension-point that can be implemented in order to examine and potentially reject a Get entity request. This extension-point is the first code executed in the controller's Create method. Authentication and Authorization checks should be performed upstream in the route middleware-layer.    BeforeModelCall(ent interface{}) error BeforeModelCall is a controller extension-point that can be implemented in order to make changes to the content of the entity structure prior to calling the model-layer. By default the controller's Get method will populate the ID field of the entity structure using the :id value provided in the request URL. The use of this extension-point would be seemingly rare and any values added to the struct would be over-written in the model-layer when the call to the DBMS is made. The added values would however be available for use in the validation/normalization and DBMS access methods prior to the call to the ORM.    BeforeResponse(ent interface{}) error BeforeResponse is a controller extension-point that can be implemented to perform checks / changes following the return of the call to the model-layer. At this point, the db has been read and the populated entity structure is about to be marshaled into JSON and passed back to the router/mux.    "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-b/",
	"title": "Generated &#39;application&#39; Folder",
	"tags": [],
	"description": "",
	"content": "Following the execution of the application generator, a folder containing the generated app\u0026rsquo;s files is created as shown. The application folder follows the name provided via the -p Jiffy execution flag. In this case, the name of the application folder is \u0026lsquo;FirstApp\u0026rsquo;.\nFirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go  controllers   ...   ... . . .  .dev.config.json  .prd.config.json  main_test.go  main.go "
},
{
	"uri": "https://1414c.github.io/jiffy/models/mo-content-b/",
	"title": "Simple Two Entity Model",
	"tags": [],
	"description": "",
	"content": "Two Entity Model The following JSON illustrates the definition of a simple two-entity model file. In this case, model entities \u0026lsquo;Person\u0026rsquo; and \u0026lsquo;Country\u0026rsquo; will be created in the generated application, along with corresponding database tables \u0026lsquo;person\u0026rsquo; and \u0026lsquo;country\u0026rsquo;. No relationships have been defined between the two entities; this example simply illustrates how to add multiple entity definitions to a model file.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,le,gt,ge\u0026#34; }, \u0026#34;validLicense\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,ne\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } }, { \u0026#34;typeName\u0026#34;: \u0026#34;Country\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;isoCode\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;unique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: simpleTwoEntityModel.json.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/tt-content-b/",
	"title": "Dealing with mixed/multipart",
	"tags": [],
	"description": "",
	"content": "Supporting mixed/multipart TODO "
},
{
	"uri": "https://1414c.github.io/jiffy/execution/ex-content-b/",
	"title": "Jiffy Execution Flags",
	"tags": [],
	"description": "",
	"content": "Execution Flags Jiffy requires a small number of flags to be specified at runtime.\n -m Inclusion of the -m flag instructs jiffy to build a new application using the specified model file. Jiffy expects a fully-qualified path to a model file to follow the -m flag. The -m and -mf flags are mutually exclusive. -mf Inclusion of the -mf flag instructs jiffy to read and process all model files contained in the specified folder. Jiffy expects a fully-qualified path to a model folder to follow the -mf flag. The model folder must contain one or more jiffy model files. Jiffy will read all of the model files from the specified location and use them to generate a single application. Entities and entity relationships may span model files as long as they are coherent. The -mf and -m flags are mutually exclusive. -p Inclusion of the -p flag is used to specify the target directory for the generated application source-code relative to $GOPATH/src. This is a throwback to the pre-module days of Go, where it was necessary to place all code under the $GOPATH/src folder. There are no plans to change this at the moment. Specification of the application target location and project name with the -p flag will result in the creation of a new project directory in the designated location under $GOPATH/src. See the examples below for more details. -rb Inclusion of the -rb flag instructs jiffy to use the specified number of bits when generating RSA keys. This flag is optional and defaults to 2048 if not specified.  Execution Examples Application based on a single model file This example Illustrates the use of the -m flag to instruct jiffy to generate a new application based on a single model file located in /tmp. The -p flag instructs jiffy to name the new application \u0026lsquo;mynewserviceapp\u0026rsquo; and create it in the $GOPATH/src/github.com/footle.com/mynewserviceapp. Note that $GOPATH/src/github.com/footle.com must already exist in order for the generation to succeed.\njiffy -m /tmp/MyModel.json -p /github.com/footle.com/mynewserviceapp Application based on several model files This example Illustrates the use of the -mf flag to instruct jiffy to generate a new application based on a set of model files located in /tmp/MyModelFolder. The -p flag instructs jiffy to name the new application \u0026lsquo;mynewserviceapp\u0026rsquo; and create it in the $GOPATH/src/github.com/footle.com/mynewserviceapp. Note that $GOPATH/src/github.com/footle.com must already exist in order for the generation to succeed.\njiffy -mf /tmp/MyModelFolder -p /github.com/footle.com/mynewserviceapp "
},
{
	"uri": "https://1414c.github.io/jiffy/installation/in-content-b/",
	"title": "Jiffy Installation",
	"tags": [],
	"description": "",
	"content": "Install from Binary Distribution At the moment, the easiest way to install Jiffy is to pull down the binary distribution matching your build environment from the latest release area in the jiffy repository. There you will find builds of the jiffy executable for the following GOOS and GOARCH combinations.\n   GOOS GOARCH FILE     darwin amd64 jiffy-darwin-amd64.tar.gz   linux amd64 jiffy-linux-amd64.tar.gz   linux arm jiffy-linux-arm.tar.gz   linux arm64 jiffy-linux-arm64.tar.gz   linux mips64 jiffy-linux-mips64.tar.gz   linux ppc64 jiffy-linux-ppc64.tar.gz   linux s390x jiffy-linux-s390x.tar.gz   freebsd amd64 jiffy-freebsd-amd64.tar.gz   freebsd arm jiffy-freebsd-arm.tar.gz   openbsd amd64 jiffy-openbsd-amd64.tar.gz   openbsd arm jiffy-openbsd-arm.tar.gz    This list is not exhaustive. If your GOOS/GOARCH are not found in this list, you may build jiffy from source by following the instructions in the next section.\nOnce downloaded, you may extract the \u0026lsquo;jiffy\u0026rsquo; binary to a location anywhere in your $PATH, (/usr/local/bin is typical). Once the \u0026lsquo;jiffy\u0026rsquo; binary has been moved to its new home, open a new terminal window and use the which command to ensure that the binary is in the $PATH.\ntar -xvf jiffy-linux-amd64.tar.gz mv jiffy /usr/local/bin which jiffy -a If which cannot find the jiffy binary (or finds the wrong one!), make sure that your $PATH environment variable is set correctly, and maybe remove versions that were previously installed.\nInstall From Source Code To install Jiffy from source use go get on the command-line to pull the latest version from github as shown below:\ngo get -u github.com/1414C/jiffy The go get command will pull the master branch of the Jiffy github repository into your $GOPATH/src/github.com folder, as well as any dependencies referenced by the Jiffy source code. The -u flag is included to instruct go get to check for and pull updates to Jiffy packages and their dependencies based on the content of the project\u0026rsquo;s go.mod file.\nOnce the Jiffy source code and dependencies have been installed into the $GOPATH, make can be used to compile a binary from the Jiffy sources and install it in /usr/local/bin. Open a terminal window, switch to $GOPATH/src/github.com/1414C/jiffy and run make install-mac or make install-linux as shown below. make install-mac and make install-linux both build for a GOARCH=amd64. If you need to build for another architecture, edit the Makefile accordingly. Check the all section of the Makefile; you can probably just copy one of the existing entries as these are used to generate the binary_distributions tree.\nmake install-mac or make install-linux This will result in the creation of a binary file named \u0026lsquo;jiffy\u0026rsquo; and its subsequent installation in /usr/local/bin. You may move the \u0026lsquo;jiffy\u0026rsquo; binary anywhere in your $PATH, but for now /usr/local/bin will be fine. Once the \u0026lsquo;jiffy\u0026rsquo; binary has been moved to its new home, open a new terminal window and use the which command to ensure that the binary is in the $PATH.\nwhich jiffy -a If which cannot find the jiffy binary (or finds the wrong one!), make sure that your $PATH environment variable is set correctly, and maybe remove versions that were previously installed. Alternatively, Jiffy can be run directly from the source via \u0026lsquo;go run main.go \u0026hellip; \u0026hellip;'.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/gs-content-a/",
	"title": "Go Environment",
	"tags": [],
	"description": "",
	"content": "If you already have Go installed and know that your installation is working, you should skip to the next section. If you need to get Go installed on your machine, keep reading.\nGo is easy to setup and can be installed from source or binary package, both which are available at golang.org. Jiffy is presently built and tested using golang version 1.14.3, and jiffy expects at least version 1.13. Jiffy uses go modules.\n Go binary installation instructions Go build-from-source installation instructions  "
},
{
	"uri": "https://1414c.github.io/jiffy/overview/ov-content-b/",
	"title": "Jiffy Application Overview",
	"tags": [],
	"description": "",
	"content": "What does a generated Jiffy application look like? Generated Jiffy applications can be pointed at the DBMS of your choice without the need to recompile the binary (architecture differences not withstanding). This means that a developer can build a model, fully test it locally using SQLite and then redirect the application to a formal testing environment running SAP Hana, or any of the other supported database systems.\nApplications are generated based on model files which are encoded as simple JSON. The concepts of entity and resource-id form the cornerstones upon which the model, application and RESTful end-points are built.\nEntities can be thought of anything that needs to be modeled; Order, Customer, Invoice, Truck, \u0026hellip;, \u0026hellip; Each entity is mandated to have an ID field, which is analogous to a primary-key or row-id in the backend database. ID is used as the primary resource identifier for an entity, and is setup by default as an auto-incrementing column in the database. ID is implemented as go-type uint64 and is inserted into the model entity definition during application generation.\nSimple CRUD Access Accessing an entity via the generated CRUD interface is very simple. For example, a customer entity could be defined in the model and then accessed via the application as follows:\n  Create a customer entity:\n https://servername:port/customer + {JSON body} + POST    Update a customer entity:\n https://servername:port/customer/:id + {JSON body} + PUT    Read a customer entity:\n https://servername:port/customer/:id + GET    Delete a customer entity:\n https://servername:port/customer/:id + DELETE    Read all customer entities:\n https://servername:port/customers + GET    Filters and Relationships Additional routes can also be generated based on the model file, including custom filters for GET operations, static end-points for common GET operations, HasOne, HasMany and BelongsTo relationships:\n  Use a filter to Get customers where the last name is \u0026lsquo;Smith\u0026rsquo;:\n https://servername:port/customers/?last_name=Smith + GET    Use a generated static end-point to Get customers where credit score is less than 4:\n https://servername:port/customers/credit_score(LT 4) + GET    Use a generated relationship to retrieve all orders for a specific customer (10023):\n https://servername:port/customer/10023/orders + GET    Use a generated relationship to retrieve a specific order (99000022) for the specified customer (10023):\n https://servername:port/customer/10023/order/99000022 + GET    Use a generated belongsTo relationship to retrieve the customer for a specific order (990000222):\n https://servername:port/order/99000022/customer + GET    Commands A set of commands can be appended to an operation\u0026rsquo;s URL to perform some common activities. The commands can be appended to the URL in any order.\n  Get a count of all customer entities:\n https://servername:port/customer/$count + GET    Limit the number of returned customer entities to 3. The default ordering for this example would be ascending based on the entity ID field.\n https://servername:port/customer/$limit=3 + GET    Offset the database selection by 2 records, top-down, using the default order; (ascending based on the entity ID field):\n https://servername:port/customer/$offset=2 + GET    Select records in descending order based on the entity ID field:\n https://servername:port/customer/$desc + GET    Select records in descending order using the customer name field as the order-by criteria:\n https://servername:port/customer/\\$orderby=name$desc + GET    Limit the number of selected records to 3 and select in descending order based on the entity ID field:\n https://servername:port/customer/\\$limit=3/$desc + GET    Limit the number of selected records to 3 and select in ascending order using the customer name field as the order-by criteria:\n https://servername:port/customer/\\$limit=3;\\$orderby=name$asc + GET    Limit the number of selected records to 3 with an offset of 2 and select the records in ascending order using the customer name field as the sort criteria:\n https://servername:port/customer/\\$limit=3\\$offset=2\\$orderby=name$asc + GET    Limit the return of a static filter end-point to 3 records:\n https://servername:port/customers/credit_score(LT4)/$limit=3 + GET    More details regarding application modeling are contained in later sections of this documentation.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/using-docker/",
	"title": "Using Docker",
	"tags": [],
	"description": "",
	"content": "Using Docker with Jiffy Applications Jiffy "
},
{
	"uri": "https://1414c.github.io/jiffy/interprocess/ip-content-c/",
	"title": "Process Startup / Join",
	"tags": [],
	"description": "",
	"content": "Process Startup When an application instance (process) starts, the group-membership subsystem is started as a go-routine within the application.\nMember Communication The group-membership service communicates between processes via web-sockets connections. Each process accepts group-membership messages on the address:port specified by the \u0026lsquo;internal_address\u0026rsquo; key in the application configuration file. This port is not secured, and the group-membership messages are not encrypted in any way. It is advisable that the address:port used here is not accessible to the outside world.\nDue to the round-robin-every-process-pings-every-other-process model used by the failure detector, the group-membership service can be rather busy. Group Leadership Overview Election Overview In order to participate in a group, each starting process needs to know who the current group-leader is. Group-leadership is determined internally via the failure-detector and a bully-type leader-election. Each process knows who the current group-leader is at any given time. If a failure of the group-leader is detected, an election is held whereby the process with the highest process-id (PID) assumes leadership of the group.\nAssertion of leadership is disseminated to all group-members by the new leader via the COORDINATOR message. This takes care of the current group-members, but processes wishing to join the group must have a way to determine who the current group-leader is.\nJoining Overview Joining processes must access a well-known persistent store that holds the current group-leader information. This means that each joining process must know the location of, and the manner in which the persistent store can be queried. The persistent store exists outside of the group-membership and is typically some sort of name-value key-store like redis or memcached.\nTo this end, the .xxx.config.json file offers the option of running the application in stand-alone mode (self==leader), or with redis, memcached or sluggo as KVS repositories for the group-leader information.\nA general interface is provided by Jiffy to allow the implementing developer to add support for the persistent store of their choice. Enhancement points have not been added for the \u0026ldquo;custom_kvs_impl\u0026rdquo; key yet, but it should be quite easy to insert the required code. The rationale here is that many implementers will have a preference in terms of the key-value store they use, and may already have a suitable KVS in their productive landscape. The interface provided by Jiffy for this purpose is gmcom.GMLeaderSetterGetter and it must be implemented in the appobj/lead_set_get.go file. \nInterface gmcom.GMGetterSetter Interface gmcom.GMGetterSetter contains methods to facilitate read/write access to the one-and-only persisted leader record in any key-value-store. Applications implementing the interface may choose to store the persisted current leader in a number of mediums; flat-file, db table record, redis, memcached etc.\n Interface gmcom.GMGetterSetter   GetDBLeader() (*GMLeader, error) GetDBLeader is provided in order to allow the implementer to retrieve the current group-leader information from the persistent store. The implementation of this method is intended to be self-contained. For example, if the implementation calls for the current leader information to be persisted in redis, the implementer should code a self-contained method to connect to redis, retrieve the leader information and return it in the GMLeader pointer. Failure to read a current leader from the persistent store should result in the return of a nil in place of the *GMLeader pointer and a non-nil error value.    SetDBLeader(l GMLeader) error SetDBLeader is provided in order to allow the implementer to persist a newly elected leader's information in the persistent store. The implementation of this method is intended to be self-contained. For example, if the implementation calls for the current leader information to be persisted in redis, the implementer should code a self-contained method to connect to redis and store the leader information provided by input parameter *l*. Failure to persist the provided leader information should result in the implementer returning a non-nil value in the *error* return parameter.    Cleanup() error Cleanup is provided in order to allow the implementer to cleanup connection pools, open and/or busy connections before the hosting application shuts down in response to a SIGKILL, os.Interrupt or SIGINT event. If the implementation does not require any cleanup, this method can be implemented to simply return nil.    Interface gmcom.GMSetterGetter Sample Implementation // LeadSetGet provides a sample implementation of the GMLeaderSetterGetter // interface in order to support persistence of the current group-leader // information. re-implement these methods as you see fit to facilitate // storage and retrieval of the leader information to and from the persistent // storage. This example uses a quick and dirty web-socket-based cache to // handle the persistence. It works well enough for testing, but you should // use something more robust like a database, redis etc. The methods in the // GMLeaderSetterGetter interface are called when a new process is attempting // to join the group and also when a new leader is selected via the coordinator // process. // // To test with the delivered interface implementation, install and run sluggo: // go get -u github.com/1414C/sluggo // // Execute sluggo from the command-line as follows: // go run main.go -a \u0026lt;ipaddress:port\u0026gt; // For example: // $ go run main.go -a 192.168.1.40:7070 // type LeadSetGet struct { gmcom.GMLeaderSetterGetter } // GetDBLeader retrieves the current leader information from // the persistence layer. func (sg *LeadSetGet) GetDBLeader() (*gmcom.GMLeader, error) { // access the database here to read the current leader  l := \u0026amp;gmcom.GMLeader{} wscl.GetCacheEntry(\u0026#34;LEADER\u0026#34;, l, \u0026#34;192.168.1.40:7070\u0026#34;) return l, nil } // SetDBLeader stores the current leader information in the // persistence layer. func (sg *LeadSetGet) SetDBLeader(l gmcom.GMLeader) error { // access the database here to set a new current leader  wscl.AddUpdCacheEntry(\u0026#34;LEADER\u0026#34;, \u0026amp;l, \u0026#34;192.168.1.40:7070\u0026#34;) return nil } // Cleanup closes connections to group-leadership KVS when // prior to application shutdown. func (sg *LeadSetGet) Cleanup() error { // perform cleanup(s)  return nil } Startup \u0026amp; Group Leader Identification When the application starts in group-membership mode, the process must determine who the group-leader is as described in the preceding sections. The process tries to join an existing group four times before giving up, and within each join attempt the process tries to read the current leader PID from the persistent store three times.\nGroup Leader Identification When the starting process is able to read the PID and IP Address:port of the current group-leader from the persistent store, it proceeds to the next step where an attempt to contact the leader is made.\nIf the starting process is unable to read the leader information from the persistent store, the process waits for a randomized period of between 1 and 1000 ms. Once the wait is over, the process tries to read the current leader from the persistent store again. This loop will be repeated up to four times before the process gives up and attempts to assume the role of group-leader itself.\nA distinction is not currently made between being unable to contact the persistent store and not finding a current leader after reading the persistent store.\nGroup Leader is Found Once a starting process has obtained a set of group-leader information from the persistent store that looks valid, it uses the information to send a Join message to the group-leader. There are a few possible outcomes to the sending of the Join message:\n  The group-leader accepts the Join message. When the group-leader accepts the Join message from the starting process it checks for problems as outlined below. If all goes well, the group-leader will return an Ack message containing a PID for use by the starting process. At this point, the starting process will initialize it\u0026rsquo;s failure detector loop and start participating in the group.\n  The group-leader could not be contacted. In this case, the starting process waits for a randomized period of time between 1 and 1000ms, then loops back to read the group-leader information from the persistent store again in hope that it has been updated. This can occur up to four times, after which the starting process will attempt to become the group-leader.\n  The group-leader information read from the persistent store was not correct. It is possible that the leader information in the persistent store is stale during a cold-startup. In this case, although a process was reachable at the group-leader\u0026rsquo;s ip-address:port, the so-called group-leader process was not in fact the leader. The starting process will wait for a randomized period of time between 1 and 1000ms, then loop back to read the group-leader information from the persistent store again in hope that it has been updated. This can occur up to four times, after which the starting process will report an error and gracefully exit.\n  A group-leader was found but has the current PID\u0026rsquo;s ip-address. It is possible that the starting PID\u0026rsquo;s address matches that of the group-leader that was read from the persistent store. This can happen in scenarios where the group-leader is the last process standing and then terminates without warning.\nThe persistent store retains the last group-leader information (Pi) resulting in a successful leader-ping if the first process to restart in the group happens to hold the same ip-address as that of the old group-leader. A successful ping (Pi-\u0026gt;Pi) looks like there is a functioning group-leader.\nIf the joining process sees it\u0026rsquo;s own ip-address in the group-leader slot within the persistent store, it is best to act like there is no current group-leader and wipe the read (leader) information clean. This will repeat four times as described above, then the current PID will attempt to assert itself as group-leader. The randomized time is used to offset potentially simultaneous multiple group-leadership assertions in mass cold-start situations.\nIt is important to remember/know that a starting process does not start participating in the group failure-detector until it has either joined an existing group, or has become the leader thereby starting a new group.\n  The leader reports that the ip-address:port of the starting process is already in use within the group.\nThis can occur due to a misconfigured failure threshold value (too high), or when a process is killed and restarted immediately. In this case, the starting process waits 5 seconds and then loops back to read the group-leader information and make another attempt to join the group. This can occur up to four times, after which the starting process will report an error and gracefully exit.\n  An unknown error occurs. This is a catch-all for failed join attempts. In this case, the starting process waits 5 seconds and then loops back to read the group-leader information and make another attempt to join the group. This can occur up to four times, after which the starting process will report an error and gracefully exit.\n  A group-leader is not found If a valid group-leader has not been found after four attempts, the starting process attempts to become the group-leader. The starting process will:\n Set it\u0026rsquo;s PID to 1. Add itself to the local process member map. Call gm.SendSetDBLeader to set itself as group-leader in the persistent store. Start it\u0026rsquo;s failure-detector loop in a go-routine.  "
},
{
	"uri": "https://1414c.github.io/jiffy/accesscontrol/ac-content-c/",
	"title": "Access Revocation and Renewal",
	"tags": [],
	"description": "",
	"content": "JWT Tokens and Access Revocation Jiffy applications do not direct support the revocation or automatic renewal of JWT tokens. Instead, a cross-process cache of User information is maintained via a group-membership service. The service ensures that changes to User information (create/update/delete) are disseminated to all running instances of the Jiffy generated application. Consequently, in Jiffy-based applications it makes sense to discuss User access revocation from the perspective of an administrator making a call to the user-API to perform general User deletion or deactivation. Such changes are affected in the backend database, and then updated in the application server caches by way of the web-sockets-based group-membership service.\nUser Access Revocation Example Conditions\n User \u0026lsquo;tester@test.com\u0026rsquo; has access to a number of services in a Jiffy-generated application. We now wish to remove access from this user. The JWT lifetime in our test system is set to 12 hours. tester@test.com has a current and valid JWT that will expire in 8 hours.  Revocation Steps\n A user with administrative privileges in the Jiffy-generated application makes a call to the Usr service of the Jiffy-generated application to deactivate the \u0026lsquo;tester@test.com\u0026rsquo; account. This call can be made to any running instance (node) of the application. The call updates the Usr record in the backend database. On confirmation of the successful update to the Usr record, the Usr controller of the node that made the deactivation request will disseminate the new status of the Usr record to the other group-members (nodes). Each group-member will update their Usr cache with the new information. The user will no longer be able to login to the application.  Revocation Results\n If the user attempts to login to any of the application instances, the middleware will see that the Usr has been deactivated when it checks the Usr cache and the login will be rejected. If the user has a valid JWT, but their access has been revoked as described in the previous steps, all attempts to access application services will be denied.   The JWT remains valid. The JWT contains the user\u0026rsquo;s ID. The route middleware examines the JWT Claims for every call made to the application services. The UID claim in the JWT is used by the middleware to read the Usr cache. In this example, the middleware cache will indicate that the user is no longer active. This approach allows us to focus on the maintenance and buffering of the persistent object (Usr) rather than trying to maintain/cache the transient JWT.  These steps are the same whether a user is being disabled, being granted more access, or having access to certain services revoked.\nJWT Token Expiration Jiffy application JWTs contain a standard set of registered claims as outlined in RFC7519 . Login to a jiffy generated application results in the creation of a new JWT where the standard \u0026lsquo;exp\u0026rsquo; claim is set based on the value of the \u0026lsquo;jwt_lifetime\u0026rsquo; key in the application\u0026rsquo;s configuration file. When the current (server) date-time exceeds the value contained in a JWT\u0026rsquo;s \u0026lsquo;exp\u0026rsquo; claim, the token is no longer accepted by the application. After JWT expiration, the used is forced to login again.\nJWT Token Renewal It would be possible to alter the Jiffy application to create self-renewing JWT\u0026rsquo;s. Doing so would mandate that the client developer compare the Authorization field in the response header to the one that was sent in the request. For now, the strategy is to have the application configuration set a JWT validity of ~12 hours, and then force the user to login again once the time limit expires.\nOn one hand, this approach to (not supporting) JWT renewal means that the client/consumer of the RESTful services need not worry about checking the JWT content at the end of each exchange. On the other hand, the current strategy may be a concern in system-to-system interfaces especially where it is not acceptable to set a very long JWT expiry limit in the configuration.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-c/",
	"title": "Development Configuration",
	"tags": [],
	"description": "",
	"content": "Development Config The following command string may be used to run the program using the values defined in the ./.dev.config.json file.\ngo run main.go -dev The generated sample dev configuration file should be edited to match the local environment. Jiffy will generate a sample .dev.config.json file similar to the one shown below:\n{ \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34;, \u0026#34;ormLogActive\u0026#34;: true, \u0026#34;ormDebugTraceActive\u0026#34;: false }, \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, \u0026#34;logging\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;callLocation\u0026#34;: true, \u0026#34;colorMsgTypes\u0026#34;: true, \u0026#34;infoMsgs\u0026#34;: false, \u0026#34;warningMsgs\u0026#34;: false, \u0026#34;errorMsgs\u0026#34;: true, \u0026#34;debugMsgs\u0026#34;: false, \u0026#34;traceMsgs\u0026#34;: false }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } "
},
{
	"uri": "https://1414c.github.io/jiffy/overview/ov-content-c/",
	"title": "Jiffy Application Structure",
	"tags": [],
	"description": "",
	"content": "Jiffy Application File Structure Jiffy generates the following structure when provided with a model-file describing a simple \u0026lsquo;Person\u0026rsquo; entity. Explanations of each folder and its content are discussed throughout the documentation.\nFirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go  controllers   authc.go   controllerfuncs.go   groupauthc.go   person_relationsc.go   personc.go   usrc.go   usr_groupc.go   ext   extc_interfaces.go   personc_ext.go  group   gmcl    gmclient.go   gmcom    gmcache.go    gmclsrv.go    gmerrors.go    gmomap.go   gmsrv   gmprocessors.go   gmprotocol_senders.go   gmserver.go   gmtxrx.go  jwtkeys   ecdsa256    ecdsa.priv.pem    ecdsa.pub.pem   ecdsa384    ecdsa384.prive.pem    ecdsa384.pub.pem   ecdsa521    ecdsa521.priv.pem    ecdsa521.pub.pem   rsa256    rsa.priv.pem    rsa.pub.pem   rsa384    rsa384.prive.pem    rsa384.pub.pem   rsa512   rsa512.priv.pem   rsa512.pub.pem  middleware   requireuser.go  models   authm.go   errors.go   group_authm.go   modelfuncs.go   personm_ext.go   personm.go   servicesm.go   usr_groupm.go   usrm.go   ext   model_ext_interfaces.go  util   strings.go  .dev.config.json  .prd.config.json  main_test.go  main.go "
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/gs-content-b/",
	"title": "Installing Jiffy",
	"tags": [],
	"description": "",
	"content": "Skip the Details and Try an Application If you want to try a small jiffy generated application without installing jiffy thats fine! Check out the libraryapp showcase to pull a docker image of a compiled jiffy application and follow the tutorial to test it out. If you want to install Jiffy and generate a services application yourself, keep reading!\nInstall from Binary Distribution At the moment, the easiest way to install Jiffy is to pull down the binary distribution matching your build environment from the latest release area in the jiffy repository. There you will find builds of the jiffy executable for the following GOOS and GOARCH combinations.\n   GOOS GOARCH FILE     darwin amd64 jiffy-darwin-amd64.tar.gz   linux amd64 jiffy-linux-amd64.tar.gz   linux arm jiffy-linux-arm.tar.gz   linux arm64 jiffy-linux-arm64.tar.gz   linux mips64 jiffy-linux-mips64.tar.gz   linux ppc64 jiffy-linux-ppc64.tar.gz   linux s390x jiffy-linux-s390x.tar.gz   freebsd amd64 jiffy-freebsd-amd64.tar.gz   freebsd arm jiffy-freebsd-arm.tar.gz   openbsd amd64 jiffy-openbsd-amd64.tar.gz   openbsd arm jiffy-openbsd-arm.tar.gz    This list is not exhaustive. If your GOOS/GOARCH are not found in this list, you may build jiffy from source by following the instructions in the next section.\nOnce downloaded, you may extract the \u0026lsquo;jiffy\u0026rsquo; binary to a location anywhere in your $PATH, (/usr/local/bin is typical). Once the \u0026lsquo;jiffy\u0026rsquo; binary has been moved to its new home, open a new terminal window and use the which command to ensure that the binary is in the $PATH.\ntar -xvf jiffy-linux-amd64.tar.gz mv jiffy /usr/local/bin which jiffy -a If which cannot find the jiffy binary (or finds the wrong one!), make sure that your $PATH environment variable is set correctly, and maybe remove versions that were previously installed.\nInstall From Source Code To install Jiffy from source use go get on the command-line to pull the latest version from github as shown below:\ngo get -u github.com/1414C/jiffy The go get command will pull the master branch of the Jiffy github repository into your $GOPATH/src/github.com folder, as well as any dependencies referenced by the Jiffy source code. The -u flag is included to instruct go get to check for and pull updates to Jiffy packages and their dependencies based on the content of the project\u0026rsquo;s go.mod file.\nOnce the Jiffy source code and dependencies have been installed into the $GOPATH, make can be used to compile a binary from the Jiffy sources and install it in /usr/local/bin. Open a terminal window, switch to $GOPATH/src/github.com/1414C/jiffy and run make install-mac or make install-linux as shown below. make install-mac and make install-linux both build for a GOARCH=amd64. If you need to build for another architecture, edit the Makefile accordingly. Check the all section of the Makefile; you can probably just copy one of the existing entries as these are used to generate the binary_distributions tree.\nmake install-mac or make install-linux This will result in the creation of a binary file named \u0026lsquo;jiffy\u0026rsquo; and its subsequent installation in /usr/local/bin. You may move the \u0026lsquo;jiffy\u0026rsquo; binary anywhere in your $PATH, but for now /usr/local/bin will be fine. Once the \u0026lsquo;jiffy\u0026rsquo; binary has been moved to its new home, open a new terminal window and use the which command to ensure that the binary is in the $PATH.\nwhich jiffy -a If which cannot find the jiffy binary (or finds the wrong one!), make sure that your $PATH environment variable is set correctly, and maybe remove versions that were previously installed. Alternatively, Jiffy can be run directly from the source via \u0026lsquo;go run main.go \u0026hellip; \u0026hellip;'.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/extensionpoints/ep-content-c/",
	"title": "Model Extension Points",
	"tags": [],
	"description": "",
	"content": "Overview Model extension-points exist for the Create, Update and Get CRUD operations. Each operation has a related extension-point interface, for which an empty implementation is created when the application is generated. If the generator sees that the extension-point implementation file for an entity has already been created, it will not over-write or create a new version.\nFile ./myapp/models/ext/extm_interfaces.go contains the generated entity model extension-point interface declarations. Each interface and interface method is documented in this file.\nFile ./myapp/controllers/\u0026lt;entity_name\u0026gt;m_ext.go is generated for each entity with empty extension-point interface implementations. This file may be edited by the application developer to add custom application logic.\nModel Extension-Point Interfaces  Interface ModelCreateExt   BeforeDB(ent interface{}) error BeforeDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately before the insertion request is made to the ORM. This extension-point is the first code executed in the model's Create method. Authentication and Authorization checks should be performed upstream in the route middleware-layer and detailed checks of an entity's data should be carried out in the validator-layer.    AfterDB(ent interface{}) error CreateAfterDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately following the return of the ORM insertion request. This extension-point is the last code executed in the model's Create method. As the insertion will have already occurred at this point, care should be taken when deciding whether to issue an error in this extension-point. Augmentation of the of the Create result may be carried out in this method in order to calculate non-persistent entity values for example.     Interface ModelUpdateExt   BeforeDB(ent interface{}) error BeforeDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately before the update request is made to the ORM. This extension-point is the first code executed in the model's Update method. Authentication and Authorization checks should be performed upstream in the route middleware-layer and detailed checks and normalization of the entity's data should be carried out in the validator-layer.    AfterDB(ent interface{}) error AfterDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately following the return of the ORM update request. This extension-point is the last code executed in the model's Update method. As the update will have already occurred at this point, care should be taken when deciding whether to issue an error in this extension-point. Augmentation of the of the Update result may be carried out in this method in order to calculate non-persistent entity values for example.     Interface ModelGetExt   BeforeDB(ent interface{}) error BeforeDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately before the read-entity request is made to the ORM. This extension-point is the first code executed in the model's Get method. Authentication and Authorization checks should be performed upstream in the route middleware-layer and detailed checks of an entity's data should be carried out in the validator-layer.    AfterDB(ent interface{}) error AfterDB is a model extension-point that can be implemented in order to examine and potentially make changes to the values in the entity structure immediately following the return of the ORM read-entity request. This extension-point is the last code executed in the model's Get method. As the read will have already occurred at this point, care should be taken when deciding whether to issue an error in this extension-point. Augmentation of the of the Get result may be carried out in this method in order to calculate non-persistent entity values for example. Note that the AfterDB(ent interface{}) method is called after the single and set Get CRUD operations for an entity.   "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-c/",
	"title": "Generated &#39;appobj&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;appobj\u0026rsquo; Folder  The appobj folder contains the generated application's configuration loader and the main application object.  FirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go  controllers   ...   ... . . .  .dev.config.json  .prd.config.json  main_test.go  main.go appobj.go The entry point for go applications is always the main() function, but we seldom write the so-called \u0026lsquo;main\u0026rsquo; part of the application in this monolithic function. To that end, an AppObj struct is declared and the main thread of the application runs against it. The content of main.go simply creates an instance of an AppObj struct, parses the flags and then calls the AppObj.Run() method.\nWhen the generated application is started, AppObj.Run() is responsible for:\n loading the specified configuration file creating the runtime services performing auto-migration of database artifacts initializing (loading) the keys for JWT/ECDSA support instantiating controllers initializing routes starting the mux reading the group-leader information from the group persistent store joining (or creating) the group starting the inter-process group-membership failure detector  The creation of the runtime services bears closer inspection before moving on. Generated applications contain an internal \u0026lsquo;service\u0026rsquo; for each entity declared in the source model files. The AppObj is responsible for the instantiation of these services when the application is started via the AppObj.createServices() method.\nA Services object containing each of the entity runtime services is created on the one-and-only instance of the AppObj. A runtime service is first created to support access to the backend DBMS via the sqac ORM, then a service is started for each entity. Entity services contain a reference to the ORM access handle, as well as an instance of the entity\u0026rsquo;s validator class which is contained in the model-layer.\nappconf.go The code in appconf.go contains the functions used to load application configuration files, as well as functions containing so-called \u0026lsquo;default\u0026rsquo; configuration. It is possible to edit the DefaultConfig() function so that it holds values specific to the local test/development environment. This prevents the need for maintaining a set of configuration files that the development staff need to keep in sync.\nlead_set_get.go The code in lead_set_get.go contains implementation of interface gmcom.GMLeaderSetterGetter. As explained in section Deployment Overview jiffy applications can be deployed as standalone servers, or as a group utilizing a group-leadership model and synchronized access and authorization caching. Default implementations of the Group Leader KVS accessors include support for redis, memcached, stand-alone operation and the dime-store cache server sluggo. The interface is simple to understand and utilizes well-known and well-supported client implementations to access redis and memcached. Although no extension points have been declared in the code to support other KVS servers, it would be a simple matter to do so. See section Interprocess Communication and Multi-Instance Deployment for a detailed overview of interface gmcom.GMLeaderSetterGetter.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/models/mo-content-c/",
	"title": "Model with Composite Index",
	"tags": [],
	"description": "",
	"content": "Two Entity Model with Composite Index The following JSON illustrates the addition of a composite-index to an entity definition. An index composed of the \u0026lsquo;name\u0026rsquo; and \u0026lsquo;province\u0026rsquo; fields has been declared in the \u0026lsquo;Owner\u0026rsquo; entity. This declaration will result in the creation of a non-unique btree index for columns \u0026lsquo;name\u0026rsquo; and \u0026lsquo;province\u0026rsquo; in the database. Any number of composite indices may be declared for an entity. No relationships have been defined between the two entities; this example simply illustrates how to declare a composite-index for an entity.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Owner\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;LicenseNumber\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;Province\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true }, \u0026#34;compositeIndexes\u0026#34;: [ {\u0026#34;index\u0026#34;: \u0026#34;name, province\u0026#34;} ] }, { \u0026#34;typeName\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Model\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Make\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: twoEntityWithCompositeIndex.json.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/interprocess/ip-content-d/",
	"title": "Process Shutdown",
	"tags": [],
	"description": "",
	"content": "Planned Shutdown  Application instances can be stopped deliberately. For example, application instances running in a cluster may be started and stopped based on auto-scaling behaviors. Application shutdowns consider the need to complete work in progress by listening for SIGTERM, SIGKILL and os.Interrupt \u0026lsquo;events\u0026rsquo; in a dedicated goroutine which we will refer to here as the \u0026lsquo;shutdown detector goroutine\u0026rsquo;. When a signal of interest is detected, the shutdown detector goroutine passes a value through a channel being listened to in the main services loop.  Upon receiving the channel value indicating a shutdown, the application instance sends a DEPARTING message to all group-members. Each group-member updates the process status of the departing application instance to DEPARTED upon receiving the DEPARTING message. DEPARTING messages contain a double-incremented (+=2) incarnation number and override ALIVE and SUSPECT statuses in the receiving application instance\u0026rsquo;s local group-membership list. The departing instance calls a Server.Shutdown(\u0026hellip;) method with a timeout context of 5 seconds to permit work in progress to complete. The departing instance then shuts down.   While the departing instance sends a DEPARTING message to all application instances that it knows about, this may not constitute the complete group-membership. Processes disseminate DEPARTED statuses of departed peers for a few ping cycles in order to ensure that the information is made available as widely as possible. After a short period of dissemination, each running application instance purges the DEPARTED application instance information from its local group-membership list.  "
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-d/",
	"title": "Production Configuration",
	"tags": [],
	"description": "",
	"content": "Production Config The following command string may be used to run the program using the values defined in the ./.prd.config.json file.\ngo run main.go -prod The generated sample production configuration file should be edited to match the local environment. Jiffy will generate a sample .prod.config.json file similar to the one shown below:\n{ \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;prod\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;user\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34;, \u0026#34;ormLogActive\u0026#34;: true }, \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, \u0026#34;logging\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;callLocation\u0026#34;: false, \u0026#34;colorMsgTypes\u0026#34;: true, \u0026#34;infoMsgs\u0026#34;: false, \u0026#34;warningMsgs\u0026#34;: true, \u0026#34;errorMsgs\u0026#34;: true, \u0026#34;debugMsgs\u0026#34;: false, \u0026#34;traceMsgs\u0026#34;: false }, \u0026#34;cert_file\u0026#34;: \u0026#34;srvcert.cer\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;srvcert.key\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;service_active\u0026#34;: true }, { \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } "
},
{
	"uri": "https://1414c.github.io/jiffy/accesscontrol/ac-content-d/",
	"title": "Using External Identity Providers",
	"tags": [],
	"description": "",
	"content": "Using External Identity Providers It is possible to use an external Identity Provider to supply JWT tokens capable of accessing jiffy-applications. In order for an external IDP to provide usable JWT\u0026rsquo;s to jiffy the following criteria must be met:\n The IDP must sign the JWT\u0026rsquo;s with an algorithm that jiffy supports (RSA / ECDSA). The IDP must provide the jiffy application with a public-key for signature verification. A valid user-id must exist in the jiffy application. The IDP must contain a mapping of user IDP ID\u0026rsquo;s to jiffy-application internal user id\u0026rsquo;s. The IDP must contain a record of the Authorization-Groups that the user should have access to. The IDP must include the jiffy-specific claims in the JWT payload. The IDP must supply the \u0026lsquo;alg\u0026rsquo; and \u0026lsquo;typ\u0026rsquo; elements in the JWT header.  Sample JWT for Jiffy Application Access  A user with an existing jiffy-application userID has been configured in an external IDP. The user\u0026rsquo;s internal jiffy-application ID is 12, and the user has been granted access to end-points encompassed by Authorization-Groups \u0026lsquo;GroupA\u0026rsquo; and \u0026lsquo;GroupC\u0026rsquo;. The IDP is signing JWT\u0026rsquo;s with ECDSA-SHA384.  The user logs into the IDP, then attempts to access a jiffy-application resource through some means by which a jiffy-compliant JWT generated by the IDP is included in the http request-header \u0026lsquo;Authorization\u0026rsquo; field:\nBase64 Encoded JWT in the Authorization (compliments of jwt.io) Decoded JWT Header (Red Section) { \u0026#34;alg\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } \nDecoded JWT Payload (Purple Section) { \u0026#34;Groups\u0026#34;: \u0026#34;GroupA; GroupC\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;billthecat@1414c.io\u0026#34;, \u0026#34;exp\u0026#34;: 1528500904, \u0026#34;iat\u0026#34;: 1528493704, \u0026#34;id\u0026#34;: 12, \u0026#34;uid\u0026#34;: 12 } When this JWT is included in the http header of a jiffy-application request, the jiffy-application will decode the JWT header to determine the algorithm used to sign the token. Next, the application will use the appropriate public-key to verify the JWTs signature (blue section). If the application is not able to verify the signature, the request will be rejected.\nOnce the JWT integrity has been verified, the middleware performs the following checks before allowing the request to proceed to the entity controller method:\n Verify that the JWT has not expired by examining the unix epoch timestamp in the \u0026lsquo;exp\u0026rsquo; claim. If the system time exceeds the value contained in the \u0026lsquo;exp\u0026rsquo; claim, the request will be rejected. Ensure that the user-id contained in the custom \u0026lsquo;uid\u0026rsquo; claim is valid by performing a lookup in the application server cache. If the user is not valid, or is not found in the cache the request is rejected. A custom claim is used here rather than the standard \u0026lsquo;id\u0026rsquo; claim, as the \u0026lsquo;id\u0026rsquo; claim may be expected to hold a global ID for the user. Each authorization-group in the custom \u0026lsquo;Groups\u0026rsquo; claim is then checked to see if it contains authorization for the requested end-point. The middleware performs this check by examining the cached values of the Authorizations assigned to each Group in the \u0026lsquo;Groups\u0026rsquo; claim. If a match is found, the user is authorized to proceed and the request is allowed to enter the controller method.  Token Renewal with an External Identity Provider Most renewal schemes employed by an external IDP can be used to renew tokens. The Jiffy application itself is not able to participate in the request for a renewal token, but the consuming application is free to interact with the IDP to renew / acquire a valid JWT when the current token is nearing expiry.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/using-docker/dr-content-d/",
	"title": "Jiffy with Kubernetes",
	"tags": [],
	"description": "",
	"content": "Overview We will create and deploy a sample jiffy application in Kubernetes using the preconfigured minikube cluster. The containerized jiffy application will be deployed in the Kubernetes cluster and will communicate with a Postgres database and KVS running on the cluster-host\u0026rsquo;s network. In this example the Postgres database and KVS will not be running in containers.\nThe goal of this example is to get a feel for Kubernetes deployment of a jiffy-application. This tutorial should not be considered as a roadmap for productive Kubernetes deployments, but as a starting point for getting a jiffy application running in Kubernetes.\nWe will see how to deploy the containerized application into a Kubernetes Node, how to view the Pod logs, how to scale the deployment up/down and how to log into a Pod. For the most part, we will use the Kubernetes minikube default cluster values.\nSteps  Verify the Jiffy installation. Generate a new application using a sample model file from the Jiffy source-tree. Edit the application\u0026rsquo;s configuration file for Postgres and Docker use. Statically compile a binary for inclusion in the Docker image. Write a simple Dockerfile to create a runnable image. Write a small script to update the image\u0026rsquo;s .dev.config.json file with the container\u0026rsquo;s ipv4 address. Create a container from the image and start the container. Test access to the application running in the container using Postman. Install the minikube Kubernetes cluster. Create a Kubernetes deployment of the containerized jiffy application. Expose the jiffy application deployment as a Kubernetes Service. Detect the IP/port that minikube is using to expose the new Kubernetes Service. Run some tests against the Kubernetes Deployment of the jiffy application using Postman. Scale the deployment up and down. View the logs of the Pods running in the minikube cluster. Login to a Pod running an instance of the jiffy application and take a look around. Shutdown the Kubernetes Service. Remove the Kubernetes Deployment of the jiffy application. Cleanup the Docker environment.  Verify Jiffy Installation Ensure that Jiffy has been installed on your workstation by following the instructions provided in the Jiffy Installation section.\nGenerate the Application We will generate a new application called libappK8 from a model file that contains a \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity. Two relationships are maintained in the model; a Library hasMany Books and a Book belongsTo a specific Library. An application generated from this model will allow many Jiffy application features to be tested.\nOpen a terminal window on your workstation and run jiffy using the Library-Book model file to generate the source-code for our test application as follows:\njiffy -m $GOPATH/src/github.com/1414C/jiffy/support/testing_models/hasManyBelongsTo.json -p /exp/libappk8 Remember that jiffys -p flag expects to be provided with an existing path underneath your $GOPATH/src folder. In the example invocation shown above, jiffy will create the libappk8 folder underneath $GOPATH/src/exp/ and then write the generated source-code to this location.\nExecution of the generator (jiffy) should result in output similar to:\n2018/07/03 21:34:47 generated: /Users/stevem/gowork/src/exp/libappk8/models/librarym.go 2018/07/03 21:34:47 generated: /Users/stevem/gowork/src/exp/libappk8/models/librarym_ext.go 2018/07/03 21:34:47 generated: /Users/stevem/gowork/src/exp/libappk8/controllers/libraryc.go ... ... ... 2018/07/03 21:34:49 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/libappk8/util/strings.go 2018/07/03 21:34:49 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/libappk8/util/strings.go 2018/07/03 21:34:49 executing /usr/local/go/bin/goimports -w /Users/stevem/gowork/src/exp/libappk8/appobj/appconf.go 2018/07/03 21:34:49 executing /usr/local/go/bin/gofmt -w /Users/stevem/gowork/src/exp/libappk8/appobj/appconf.go Your output may look slightly different, particularly the database connection test which will almost certainly fail. This is nothing to be concerned about, as the generator is attempting to connect to a local Postgres instance using bad credentials. \nEdit the Application Configuration File Update Address Keys The next step is to edit the generated application\u0026rsquo;s configuration files. Docker allocates a static ip-address for each container by default, and we will use that address in our application\u0026rsquo;s configuration file. \u0026lsquo;external_address\u0026rsquo; refers to the address at which the application\u0026rsquo;s end-points will be available, while the \u0026lsquo;internal_address\u0026rsquo; is used for cache updates and interprocess communication over web-socket connections.\nOpen the generated .dev.config.json file in an editor and update the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; values with \u0026ldquo;xxx.xxx.xxx.xxx:8080\u0026rdquo; and \u0026ldquo;xxx.xxx.xxx.xxx:4444\u0026rdquo; respectively. Using an illegal ipv4 address as a placeholder/mask ensures that the container will not start in the event that the container\u0026rsquo;s address could not be assigned to the config keys. When you have finished, save the file after verifying that it looks like this:\n.dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;xxx.xxx.xxx.xxx:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... } Update Application\u0026rsquo;s Database Config Jiffy generates configuration files targeting a Postgres database by default. Maintain the values in the \u0026lsquo;database\u0026rsquo; block of the *.dev.config.json; file as necessary in order to gain access to your testing database:\n.dev.config.json { ... \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;192.168.1.65\u0026#34;, \u0026#34;port\u0026#34;: 5432, \u0026#34;usr\u0026#34;: \u0026#34;godev\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;gogogo123\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;glrestgen\u0026#34; }, ... } Once the database block in .dev.config.json has been updated, save the file and close the editor.\nEnsure PostgreSQL is Available By default, Postgres only allows connections from the localhost (127.0.0.1). If your Postgres database is running on another machine, you will need to ensure that it allows connections from remote hosts. A quick web-search will reveal how to maintain Postgres\u0026rsquo;s postgresql.conf and pg_hba.conf files to allow remote connections to the database. Make sure that you are able to connect to your Postgres database (use psql) from the Docker host environment before continuing.\nUpdate the Application\u0026rsquo;s Group Leader KVS Config Jiffy generates configuration files supporting a stand-alone / local group-leadership KVS by default. When running more than one application instance, a group-leadership KVS is required in order for each group-member to obtain the group-leader information on start-up. This example will make use of the sluggo KVS. Examine the \u0026lsquo;group_leader_kvs\u0026rsquo; block in *.config.json to ensure the \u0026lsquo;sluggo\u0026rsquo; KVS option is active as shown below:\n.dev.config.json { ... \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;sluggo_address\u0026#34;: \u0026#34;192.168.111.24:7070\u0026#34; } }, ... } Ensure that a single instance of sluggo is running on a system accessible to the deployed containers.\n\n\nBuild a Static Application Binary for Alpine Linux Next, we need to build a static application binary for linux/amd64. To build the application, a number of dependencies are required as outlined in the Jiffy Dependencies section of the documentation. Check that your build environment contains the correct packages and import any that are missing.\nThis tutorial uses the popular Alpine Linux distribution as the basis for the new container image. Alpine Linux is a small and sparse distribution making it nice for use with containers. There are a few things to be aware of however\u0026hellip;\nAlpine Linux is based on lib-musl which means that binaries built by go build where the source makes use of cgo must target lib-musl rather than lib-gcc. The binary resulting from the typical \u0026lsquo;GOOS=linux GOARCH=amd64 go build -o main .\u0026rsquo; command would almost certainly not work on Alpine. The good news it is quite easy to build with musl-gcc, the bad news is that musl-gcc is available for Linux only. If you are working on a system in which lib-musl is not supported, you will need to run the go build command in a supported build environment. Most Linux distributions and architectures are supported.\nCheck if lib-musl has been installed in the build environment by running the which command:\nwhich musl-gcc If musl-gcc was found in the $PATH, which will return output similar to:\n/usr/bin/musl-gcc If musl-gcc was not found, follow the installation instructions below to download and install the required packages.\nInstall Musl-gcc We will go over how to install musl-gcc on a Debian system, but the steps are largely the same for any Linux distribution. Use your distribution\u0026rsquo;s package manager to install the musl lib, musl development files and musl development tools. Run the following commands (or their equivalents) in a terminal window on your Linux build system:\nsudo apt-get update sudo apt-get install musl sudo apt-get install musl-dev sudo apt-get install musl-tools Check to make sure that musl-gcc is now in the $PATH:\nwhich musl-gcc Build a Static Application Binary After ensuring that all of the required dependencies have been installed in the build environment, run the following command to build a statically-linked binary called main for the Alpine Linux target OS. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Adjust the GOARCH environment variable as necessary:\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build --ldflags \u0026#39;-w -linkmode external -extldflags \u0026#34;-static\u0026#34;\u0026#39; -a -v -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. Setting \u0026ndash;ldflags as shown instructs go build to produce a statically linked binary. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped Build a Dynamically-Linked Application Binary This is optional and will produce a marginally smaller binary. We will not use a dynamically-linked binary in our image, but have included a suitable go build command for reference purposes.\nCGO=0 GOOS=linux GOARCH=amd64 CC=$(which musl-gcc) go build -a -tags netgo -installsuffix cgo -o main . Running go build with CGO=0 and setting the -a flag forces a rebuild without cross-compilation dependencies. go build produces dynamically-linked binaries by default, so no linker instructions have been provided. Setting the CC environment variable to point at musl-gcc ensures that the target (executable) will run in the Alpine Linux environment. Once the build has completed, a new \u0026lsquo;main\u0026rsquo; file will have been created. Check the file via the file command:\nfile main You should see output similar to:\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-musl-x86_64.so.1, not stripped \n\nCreate a Dockerfile Verify that you have Docker installed in your build environment. The easiest way to do this is to run which docker in a terminal window to ensure the docker application is in the \\$PATH. If there is no response, check the $PATH or install Docker following the instructions at www.docker.com. Verify that the Docker daemon is running by opening a terminal window in your build environment and running the docker ps command. If Docker is not running, an error message will be displayed. Start the Docker daemon before continuing.\nIn order to deploy the compiled application in a Docker container, we need to create a Dockerfile. The docker build command uses the Dockerfile as a set of instructions when building an image. As mentioned previously, we will use Alpine Linux as the foundation (base image) for the new Docker container image. Dockerhub has a number of pre-defined images that are available to be \u0026lsquo;pulled\u0026rsquo; into locally defined custom images.\nCreate a new file called Dockerfile in the root folder of the libappK8 source-tree and open it in your editor. Copy the following content into the new Dockerfile. An effort has been made to briefly describe what each line of the Dockerfile is used for.\n# use the official docker hub alpine:latest base imageFROMalpine:latest# set the maintainer information for the new imageLABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34;# add the compiled application binary to the root folder of the new imageADD main ./# set permissions on mainRUN /bin/chmod 755 main# copy the configuration file to the root folder of the new imageCOPY .dev.config.json .# add the entrypoint.sh shell script to the root folder of the new imageADD docker-entrypoint.sh .# set widely exectuable permission on the shell-scriptRUN /bin/chmod 777 docker-entrypoint.sh# create a directory in the root folder of the new image to hold the jwt signing keysRUN mkdir jwtkeys# copy the jwtkeys folder content into the image\u0026#39;s /jwtkeys folderCOPY jwtkeys ./jwtkeys# set container environment variable $PORT to 8080ENV PORT 8080# container will listen on port tcp/8080EXPOSE8080# container will listen on port ws/4444EXPOSE4444# update local package listRUN apk update# add unix file commandRUN apk add file# add openssh-client for connectivity testingRUN apk add openssh-client# add the postgresql-client to test connectivity to the dbRUN apk add postgresql-clientENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;]CMD [\u0026#34;-dev\u0026#34;]\n\nCreate the Entrypoint Script In a previous step .dev.config.json was updated with xxx.xxx.xxx.xxx ipv4 address masks. In order to replace the masks with the container\u0026rsquo;s ipv4 address, docker run and docker start will execute the docker-entrypoint.sh when running a container instance based on the image definition. At the moment this is a problem however, as we have not written the script yet. Create a new file called docker-entrypoint.sh in the root folder of the libappK8 source-tree and open it in your editor. Copy the following content into the new docker-entrypoint.sh file:\n#!/bin/sh  # get the ipv4 address assigned to eth0 replace=$(ifconfig eth0 | grep \u0026#34;inet addr\u0026#34; | cut -d \u0026#39;:\u0026#39; -f 2 | cut -d \u0026#39; \u0026#39; -f 1) # set a variable with the value we are planning to replace search=\u0026#34;xxx.xxx.xxx.xxx\u0026#34; # check that variable replace has something in it if [ -z \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;Did not get an address value for eth0\u0026#34; elif [ -n \u0026#34;$replace\u0026#34; ]; then echo \u0026#34;${replace}found\u0026#34; # replace all instances of \u0026#39;xxx.xxx.xxx.xxx\u0026#39; in .dev.config.json # with the ipv4 address in the ${replace} variable sed -i \u0026#34;s/${search}/${replace}/g\u0026#34; .dev.config.json exec /main \u0026#34;$@\u0026#34; fi  Note that the docker-entrypoint.sh script assumes the ipv4 address should be read from the eth0 interface. This may not be the case in more complex deployments.\n \n\nBuild the Image Assuming the previous steps have been successful, it is now time to build the new Docker image. Execute the following command from the libappk8 root folder:\ndocker build -t libappk8 . Running docker build as shown instructs Docker to construct an image called libappk8 using the Dockerfile in the current working directory. You should see output similar to:\nAardvark:libappk8 stevem$ docker build -t libappk8 . Sending build context to Docker daemon 14.4MB Step 1/18 : FROM alpine:3.7 ---\u0026gt; 3fd9065eaf02 Step 2/18 : LABEL maintainer=\u0026#34;\u0026lt;stevem@1414c.io\u0026gt;\u0026#34; ---\u0026gt; Using cache ---\u0026gt; a89002eee29a Step 3/18 : ADD main ./ ---\u0026gt; Using cache ---\u0026gt; 8b9bc986eeaf Step 4/18 : RUN /bin/chmod 755 main ---\u0026gt; Using cache ---\u0026gt; 28d71ce7dab5 Step 5/18 : COPY .dev.config.json . ---\u0026gt; 8e328fa89f48 Step 6/18 : ADD docker-entrypoint.sh . ---\u0026gt; 03cdb6d936c9 Step 7/18 : RUN /bin/chmod 777 docker-entrypoint.sh ---\u0026gt; Running in 531609e3a043 Removing intermediate container 531609e3a043 ---\u0026gt; 8ec421877ec1 Step 8/18 : RUN mkdir jwtkeys ---\u0026gt; Running in b27591bd3191 Removing intermediate container b27591bd3191 ---\u0026gt; 4e55e01097c9 Step 9/18 : COPY jwtkeys ./jwtkeys ---\u0026gt; e211c1e1ccee Step 10/18 : ENV PORT 8080 ---\u0026gt; Running in fa89a88ebcf4 Removing intermediate container fa89a88ebcf4 ---\u0026gt; 416f504d58e1 Step 11/18 : EXPOSE 8080 ---\u0026gt; Running in 66c2aef3a443 Removing intermediate container 66c2aef3a443 ---\u0026gt; 6f3157466a72 Step 12/18 : EXPOSE 4444 ---\u0026gt; Running in 673d4bbef1f1 Removing intermediate container 673d4bbef1f1 ---\u0026gt; ac7734dd11c3 Step 13/18 : RUN apk update ---\u0026gt; Running in 7e3b73167c88 fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz v3.7.0-215-g16971064c0 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main] v3.7.0-207-gac61833f9b [http://dl-cdn.alpinelinux.org/alpine/v3.7/community] OK: 9054 distinct packages available Removing intermediate container 7e3b73167c88 ---\u0026gt; 367ea4588fb7 Step 14/18 : RUN apk add file ---\u0026gt; Running in 785efc041757 (1/2) Installing libmagic (5.32-r0) (2/2) Installing file (5.32-r0) Executing busybox-1.27.2-r7.trigger OK: 9 MiB in 13 packages Removing intermediate container 785efc041757 ---\u0026gt; fdd43aa7687f Step 15/18 : RUN apk add openssh-client ---\u0026gt; Running in 324ae2c9b8c3 (1/2) Installing openssh-keygen (7.5_p1-r8) (2/2) Installing openssh-client (7.5_p1-r8) Executing busybox-1.27.2-r7.trigger OK: 12 MiB in 15 packages Removing intermediate container 324ae2c9b8c3 ---\u0026gt; 583336db3bff Step 16/18 : RUN apk add postgresql-client ---\u0026gt; Running in 5c16c83775fc (1/9) Installing ncurses-terminfo-base (6.0_p20171125-r0) (2/9) Installing ncurses-terminfo (6.0_p20171125-r0) (3/9) Installing ncurses-libs (6.0_p20171125-r0) (4/9) Installing libedit (20170329.3.1-r3) (5/9) Installing db (5.3.28-r0) (6/9) Installing libsasl (2.1.26-r11) (7/9) Installing libldap (2.4.45-r3) (8/9) Installing libpq (10.4-r0) (9/9) Installing postgresql-client (10.4-r0) Executing busybox-1.27.2-r7.trigger OK: 24 MiB in 24 packages Removing intermediate container 5c16c83775fc ---\u0026gt; 73960ab81e46 Step 17/18 : ENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;] ---\u0026gt; Running in 90236136ec8c Removing intermediate container 90236136ec8c ---\u0026gt; 960766571b87 Step 18/18 : CMD [\u0026#34;-dev\u0026#34;] ---\u0026gt; Running in 60e5203ffd61 Removing intermediate container 60e5203ffd61 ---\u0026gt; c952825021e9 Successfully built c952825021e9 Successfully tagged libappk8:latest Aardvark:libappK8 stevem$ View the Image You can run the docker image command as shown below to view some basic data regarding the new image:\ndocker image ls libappk8 You should see output similar to:\nREPOSITORY TAG IMAGE ID CREATED SIZE libappk8 latest c952825021e9 Less than a second ago 48.8MB Use the Image Once the image has been created, the next step is to use it to create a container. This can be done in a single step where Docker creates the container and then starts it. Run the following command to create and start a new container from the libappk8 image:\ndocker run --rm --name libappk8 -p 8080:8080 -d libappk8 Calling docker run with the \u0026ndash;rm flag instructs Docker to delete the container when it is stopped. Jiffy application containers should be considered throwaway under normal operating conditions. Execution of docker run should create, start and detach the libappk8 container.\nIf all went well, docker created a container from the libappk8 image and then started it. The flags provided with the docker run command do the following:\n \u0026ndash;rm - remove (delete) the container after it is stopped \u0026ndash;name - the image to create the container from -p - used to bind the host\u0026rsquo;s tcp/8080 port to container port tcp/8080 -d - detach the container from the starting session  Check the Container Status Container status can be checked via the docker ps command:\ndocker ps -a Resulting in output similar to:\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7d99554e46dd libappk8 \u0026#34;/docker-entrypoint.\u0026#34; Less than a second ago Up 2 minutes 4444/tcp, 0.0.0.0:8080-\u0026gt;8080/tcp libappk8 The output of the command shows that the libappk8 container was started with entrypoint \u0026lsquo;/docker-entrypoint.sh -dev\u0026rsquo; and that container port :8080 is mapped to host port :8080.\nSSH into the Container We can ssh into the running container to see what is going on using the command shown in the following terminal session. The command logs in as root using the specified interactive shell (in this case /bin/sh). Check that \u0026lsquo;main -dev\u0026rsquo; is running as expected using the Linux ps command.\ndocker exec -it libappk8 /bin/sh ps -ef shows that \u0026lsquo;main -dev\u0026rsquo; is running:\n/ # ps -ef PID USER TIME COMMAND 1 root 0:00 /main -dev 22 root 0:00 /bin/sh 30 root 0:00 ps -ef / # Take a look around the in the container environment and verify that the content of .dev.config.json has been updated with the correct ip-address using the ifconfig/cat commands. Remember that in this use-case the docker container is created with a static ipv4 address assigned to the eth0 interface. Verify that the eth0 ipv4 address has been added to the \u0026lsquo;external_address\u0026rsquo; and \u0026lsquo;internal_address\u0026rsquo; keys in .dev.config.json.\n/ # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1173 errors:0 dropped:0 overruns:0 frame:0 TX packets:887 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:117699 (114.9 KiB) TX bytes:65147 (63.6 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:8058 errors:0 dropped:0 overruns:0 frame:0 TX packets:8058 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:1409323 (1.3 MiB) TX bytes:1409323 (1.3 MiB) / # cat .dev.config.json { \u0026#34;external_address\u0026#34;: \u0026#34;172.17.0.2:8080\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;172.17.0.2:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, ... ... ... \u0026#34;service_name\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] }/ # \n\nUse the psql Client to Connect to Postgres We installed the Postgres client package into the libappk8 image by including it in our Dockerfile. Make sure that the libappk8 container is running and that you have logged in via the docker exec -it libappk8 /bin/sh command. Try to connect to your Postgres database as follows:\n/ # psql -h 192.168.1.65 -d postgres -U postgres Password for user postgres: ******************* psql (10.4, server 9.5.3) Type \u0026#34;help\u0026#34; for help. postgres=# Connecting to the database using psql is just for demonstration purposes. If the database was not reachable the container would not have started. For a discussion of what to do if the container entrypoint fails, see the Troubleshooting section of this document. \nLogin to the Application Launch Postman or your favorite RESTful service testing tool and specify a target URL of: http://172.17.0.2:8080/usr/login making sure to select the http POST method. Maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a Jiffy application is an email address, but an exception is made for the default administration user definition.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.  If all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single \u0026lsquo;token\u0026rsquo; tag containing a jumble of letters and numbers. This is the JWT that will be used to validate the \u0026lsquo;admin\u0026rsquo; user\u0026rsquo;s authorization to access the \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity service end-points. If you want to read more about JWT\u0026rsquo;s, jwt.io is a good place to start, or you can refer to the Access Control section of this document set. \nCreate a Library We will create a new \u0026lsquo;Library\u0026rsquo; entity. Configure your test-tool to POST to the \u0026lsquo;library\u0026rsquo; service as shown in the following image:\nCopy the JWT from the login session and paste it into the new POST request\u0026rsquo;s Authorization header field as shown below and then submit the request to the application.\nFollowing submission, a new \u0026lsquo;Library\u0026rsquo; entity should have been created:\n\n\nStop the Docker Container Now that we have verified that the containerized application runs in the Docker environment, stop the container as follows:\ndocker stop libappk8 \n\nInstall Minikube Kubernetes offers a preconfigured single node cluster called Minikube which is designed to allow developers to test deployments. Minikube is lightweight and will easily run on a workstation or laptop. Install Minikube and kubectl following the instructions at install-minikube. Minikube and kubectl are required in order to follow along with the tutorial.\n\n\nVerify Minikube Installation Once you have installed minikube and kubectl the cluster must be started and kubectl needs to be told to use the minikube context. From the command-prompt run the following commands:\nminikube start kubectl config use-context minikube kubectl cluster-info If there are any errors, go back to the install-minikube instructions and work through the issues before continuing. If all went well, you should see output similar to:\nKubernetes master is running at https://192.168.64.2:8443 KubeDNS is running at https://192.168.64.2:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;. \n\nOpen the Kubernetes Dashboard Use of the Kubernetes dashboard is not required, but it does make things easier to understand. The tutorial will make use of and refer the dashboard from this point forward. Run the following command to open the Kubernetes dashboard in your default browser:\nnminikube dashboard The dashboard should open in your default browser as shown below. Note that it can take some time for the dashboard to become available. If your browser opens but is not able to connect to the dashboard, wait a bit and then refresh the browser session. The dashboard will should become available after a short delay.\n\n\nDeploy the Application in Kubernetes Now that the minikube cluster is running and the Kubernetes dashboard has been launched, it is time to deploy the libappk8 application. We will create a single instance deployment of the application using the kubectl command. Kubernetes expects to pull images from an image repository, however in this example we will be working with a local image instead. kubectl requires that locally pulled images conform to a `image_name:image_version\u0026rsquo; where the version is not equal to \u0026lsquo;latest\u0026rsquo;. For this reason, we will build a new image with version :v1.\nRemove the existing libappk8 image via the docker image rm command, then use eval to tell Docker to build a new image in the Minikube environment. Finally run docker build to create a new image (libappk8:v1) for deployment:\nSee this link for a discussion of using local Docker images with Minikube.\ndocker image rm libappk8* eval $(minikube docker-env) docker build -t libappk8:v1 . Once the new Docker image has been created, run the following kubectl command to create a new single instance deployment called libappk8:\nkubectl run libappk8 --image=libappk8:v1 --replicas=1 --port=8080 Execution of the kubectl run command should result in the following:\nAardvark:libappk8 stevem$ kubectl run libappk8 --image=libappk8:v1 --replicas=1 --port=8080 deployment.apps \u0026#34;libappk8\u0026#34; created Aardvark:libappk8 stevem$ Go to the dashboard session running in the browser and click on \u0026lsquo;Overview\u0026rsquo; in the menubar located on the left-side of the screen. You should see that a new Deployment called \u0026lsquo;libappk8\u0026rsquo; has been created from image libappk8:v1. The Deployment should be running a single Pod (application instance) and everything should be green.\n\n\nCheck the Pod Logs Now that the application has been deployed into the the minikube cluster and appears to be running we can use the dashboard to check the application logs being emitted from the container\u0026rsquo;s stdout/stderr. Jiffy runs in a verbose manner at the moment, so a quick check of the log output will provide a good indication of the application\u0026rsquo;s real health.\nClick on the \u0026lsquo;Pods\u0026rsquo; menu-item under the \u0026lsquo;Workloads\u0026rsquo; heading in the menubar on left-side of the dashboard screen. As we have only deployed with a single-instance (replica) of the libappk8 application, we should see a single Pod. Click on the logs icon as shown below to view the Pod/container stdout/stderr output:\nUpon clicking the logs icon, the dashboard will show a snapshot of the current stdout/stderr output from the Pod. Enable the log auto-refresh by clicking the refresh icon as shown below and verify that the application appears to be in good health.\n\n\nScale the Application Up We deployed a single instance (replica) of the application into the minikube cluster resulting the creation of a Deployment containing a single Pod. We can add application instances to the Deployment with a few clicks in the dashboard \u0026lsquo;Deployments\u0026rsquo; view. Click on \u0026lsquo;Deployments\u0026rsquo; in the menubar located on the left-side of the Kubernetes dashboard screen to see the current libappk8 deployment. Select \u0026lsquo;Scale\u0026rsquo; from the \u0026lsquo;Action\u0026rsquo; drop-down on the right-hand-side of the libappk8 deployment row:\nIncrease the number of desired Pods from 1 to 4. Each Pod will run a distinct instance of the containerized jiffy application.\nNotice that the number of Pods in the libappk8 Deployment row has increased as requested and the number of running Pods climbs to 4/4 in a few seconds. Click on \u0026lsquo;Pods\u0026rsquo; in the menubar located on the left-side of the dashboard to view the list of Pods:\nExamine the log of each Pod and ensure that the application instances running in the Pods can see each other. This is important from a cache management perspective. Remember that each jiffy application instance caches authorization related information to mitigate the need for database round-trips or network calls while processing a service request.\nIn order for each application instance\u0026rsquo;s cache to remain current, any application instance that processes a successful update of authorization/access information must propagate the change to the other application instances in the group. When viewing the Pod logs, you should see something like this:\nThe \u0026lsquo;UpdFromPing()\u0026rsquo; lines contain information regarding the Ping source-Pod\u0026rsquo;s view of the group. Generally speaking, you can expect to see a \u0026lsquo;UpdFromPing()\u0026rsquo; line for each Pod in the Deployment and a set of \u0026lsquo;UpdFromPing()\u0026rsquo; records from each Pod in the Deployment. ALIVE statuses are good, SUSPECT and FAILED statuses are not so good.\n\n\nExpose the Deployment via a Kubernetes Service So far we have created and scaled a Deployment of the libappk8 application, but we have yet to access any of the application services. Before accessing the libappk8 services, we need to expose the Deployment through the creation of a Kubernetes Service. In order to expose the libappk8 Deployment via a Kubernetes Service we will fall back to the command-line.\n\n\nGet Deployments First we will show how to examine the libappk8 Pods and Deployment from the command-line:\nkubectl get deployments Results in output similar to:\nNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE libappk8 4 4 4 4 50m \n\nGet Pods Next we will show how examine the list of Pods in the libappk8 Deployment from the command-line:\nkubectl get pods Results in output similar to:\nNAME READY STATUS RESTARTS AGE libappk8-687c7484cb-5nwxq 1/1 Running 0 53m libappk8-687c7484cb-8hmtw 1/1 Running 0 42m libappk8-687c7484cb-hnksv 1/1 Running 0 42m libappk8-687c7484cb-pbntc 1/1 Running 0 42m \n\nGet Kubernetes Services Next we will show how to examine the list of Kubernetes Services running on the minikube cluster. Remember that we told kubectl which Kubernetes cluster to connect to in an earlier step (link).\nkubectl get services Results in a list of Kubernetes Services:\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 36d As you can see, the libappk8 Deployment is not yet available as a service.\n\n\nCreate a Service for the libappk8 Deployment We will now create a Kubernetes Service for the libappk8 Deployment. Creation of the service will allow us to expose the application end-points via the load-balance built into the Kubernetes stack. There are several options for the type of service that will be exposed, but for single Node testing with minikube the \u0026lsquo;LoadBalancer\u0026rsquo; type works well. Create a new service from the libappk8 Deployment as follows:\nkubectl expose deployment libappk8 --type=LoadBalancer Creation of the service should result in output similar to:\nservice \u0026#34;libappk8\u0026#34; exposed Check that the service has been created and is running:\nkubectl get services You should see a new line in the Services table with the correct name and TYPE. In a productive scenario, configuration would have been done to allocate an EXTERNAL-IP to the new Service. Minikube does not allocate an external address for exposed Kubernetes Services, but exposes them via a port on the Cluster\u0026rsquo;s server address.\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 36d libappk8 LoadBalancer 10.103.54.235 \u0026lt;pending\u0026gt; 8080:32700/TCP 1m \n\nGet the Base URL for the Kubernetes Service There are a few ways to get the base-address of our new libappk8 Kubernetes Service.\n From the command-prompt using the \u0026ndash;url flag. From the command-prompt using the Cluster config and Service port mapping information. From the Kubernetes dashboard using the Node configuration and Service port mapping information.  \n\nGet the Service Base URL from the Command-Prompt minikube service libappk8 --url This command will return the base URL of the libappk8 service:\nhttp://192.168.64.2:32700 \n\nGet the Service Base URL from the Cluster Config / Service Port Mapping Another way to determine the base URL of the libappk8 service is to inspect the Service -\u0026gt; Node port mapping as well as the Cluster configuration. If we look at the result from the kubectl get services command we can see that Service port tcp:8080 is mapped to Node port tcp:32700:\n libappk8 LoadBalancer 10.103.54.235  8080:32700/TCP 1m\n All we need now is the ipv4 address that the LoadBalancer is using. We retrieve this value by running the following command to review the cluster\u0026rsquo;s configuration:\nkubectl config view The result of which will be similar to:\napiVersion: v1 clusters: - cluster: certificate-authority: /Users/stevem/.minikube/ca.crt server: https://192.168.64.2:8443 name: minikube contexts: - context: cluster: minikube user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate: /Users/stevem/.minikube/client.crt client-key: /Users/stevem/.minikube/client.key Take note of the \u0026lsquo;server:\u0026rsquo; key. This tells us the InternalIP of the minikube Node (192.168.64.2). The base address of our exposed Kubernetes Service is therefore 192.168.64.2:32700.\n\n\nGet the Service Base URL from the Kubernetes Dashboard It is also possible to get this information via the Kubernetes dashboard. Open the dashboard and click on \u0026lsquo;Nodes\u0026rsquo; in the menubar on the left-side of the dashboard screen. Take note of the \u0026lsquo;InternalIP\u0026rsquo; value in the \u0026lsquo;Addresses:\u0026rsquo; key as shown below:\nNext, click on the \u0026lsquo;Services\u0026rsquo; in the menubar on the left-side of the dashboard screen and select the libappk8 Kubernetes Service. Take note of the \u0026lsquo;Internal endpoints\u0026rsquo;. The LoadBalancer-type Service is mapped from tcp/8080 to Node port tcp/32700. The base URL of the exposed libappk8 Kubernetes Service is https://192.168.64.2:32700.\n\n\nLogin to the Load Balanced Kubernetes Service Launch Postman or your favorite RESTful service testing tool and specify a target URL of: http://192.168.64.2:32700/usr/login making sure to select the http POST method. Maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a Jiffy application is an email address, but an exception is made for the default administration user definition.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman session (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.  If all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single 'token' tag containing a jumble of letters and numbers. This is the JWT that will be used to validate the 'admin' user's authorization to access the 'Library' and 'Book' entity service end-points. If you want to read more about JWT's, [jwt.io](https://jwt.io) is a good place to start, or you can refer to the [Access Control](/jiffy/accesscontrol/index.html) section of this document set. ![k8login2](/jiffy/tutorials/images/k8login2.png)  Create a Library We will create a new \u0026lsquo;Library\u0026rsquo; entity. Configure your test-tool to POST to the \u0026lsquo;library\u0026rsquo; service as shown in the following image:\nCopy the JWT from the login session and paste it into the new POST request\u0026rsquo;s Authorization header field as shown below and then submit the request to the application.\nFollowing submission, a new \u0026lsquo;Library\u0026rsquo; entity should have been created:\n\n\nLogin to a Pod It is possible for more than one container to be running in a Pod, but jiffy application containers are typically are deployed in their own Pod as shown in the preceding example. It is possible to login to a jiffy container running in a Pod using the kubectl exec command.\nFirst, identify the Pod of interest. We will select a Pod at random from the list provided by kubectl get pods:\nNAME READY STATUS RESTARTS AGE libappk8-687c7484cb-5nwxq 1/1 Running 0 1d libappk8-687c7484cb-8hmtw 1/1 Running 0 1d libappk8-687c7484cb-hnksv 1/1 Running 0 1d libappk8-687c7484cb-pbntc 1/1 Running 0 1d Select the first jiffy Pod in your list and run the following command to login to the Pod with a /bin/sh session:\nkubectl exec -it libappk8-687c7484cb-5nwxq -- /bin/sh You should be logged into the Pod (container) as root. Run a few commands to verify that the jiffy application is running etc:\n/ # uname -a Linux libappk8-687c7484cb-5nwxq 4.9.64 #1 SMP Fri Mar 30 21:27:22 UTC 2018 x86_64 Linux / # / # / # ps -a PID USER TIME COMMAND 1 root 11:23 /main -dev 20 root 0:00 /bin/sh 33 root 0:00 ps -a / # / # / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:04 inet addr:172.17.0.4 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:4388710 errors:0 dropped:0 overruns:0 frame:0 TX packets:4388283 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:851735396 (812.2 MiB) TX bytes:852858453 (813.3 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:1433477 errors:0 dropped:0 overruns:0 frame:0 TX packets:1433477 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:263340481 (251.1 MiB) TX bytes:263340481 (251.1 MiB) / # Create another \u0026lsquo;Library\u0026rsquo; entity using the \u0026lsquo;Create a Library\u0026rsquo; steps and then request a list of Library entities using the GET ../librarys end-point:\nCreate a Book Next, we will create a \u0026lsquo;Book\u0026rsquo; entity and allocate it to \u0026lsquo;Library\u0026rsquo; 1. Configure your test-tool to POST to the \u0026lsquo;book\u0026rsquo; service as shown in the following image:\nFollowing the submission, a new \u0026lsquo;Book\u0026rsquo; entity should have been created:\nCreate a few more \u0026lsquo;Book\u0026rsquo; entities using the \u0026lsquo;Create a Book\u0026rsquo; steps and allocate them to your \u0026lsquo;Library\u0026rsquo; entities. When you have finished, request a list of \u0026lsquo;Book\u0026rsquo; entities using the GET ../books end-point:\nLibrary toBooks Based on the \u0026lsquo;hasMany\u0026rsquo; relationship between the \u0026lsquo;Library\u0026rsquo; and \u0026lsquo;Book\u0026rsquo; entity\u0026rsquo;s, we can get the number of \u0026lsquo;Book\u0026rsquo; entities belonging to \u0026lsquo;Library\u0026rsquo; 1 as follows:\nRemove the $count suffix from the URL to get the complete list of Book entities belonging to \u0026lsquo;Library\u0026rsquo; 1:\nBook toLibrary A reciprocal \u0026lsquo;belongsTo\u0026rsquo; relationship exists between the \u0026lsquo;Book\u0026rsquo; and \u0026lsquo;Library\u0026rsquo; entity definitions. Select a \u0026lsquo;Book\u0026rsquo; entity and verify that the \u0026lsquo;belongsTo\u0026rsquo; relationship works as expected:\nCheck the list of filters and commands along with the Library and Book models to see what can be appended to the the service end-points. Try some things out.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/overview/ov-content-d/",
	"title": "Jiffy Application Architecture",
	"tags": [],
	"description": "",
	"content": "Jiffy Application Architecture Jiffy approaches the API from a services perspective. Each entity has a corresponding service that can be started when the application initializes. The Usr, UsrGroup, Auth and GroupAuth services are always generated by default when creating a Jiffy application. Additional services are generated based on the content of your project\u0026rsquo;s model files.\nGenerated application services can be broken down into five high-level areas: \n graph TD; subgraph A(End-Points)--B(Middleware) B--C(Controllers) C--D(Models) D--E(Database) end  \n End-Points expose the service APIs to the consumer, such as a web-app or another server. End-points may be customized by way of the application model files. Middleware provides user authentication / authorization services and is tightly-coupled to the end-point definitions. The middleware offers comprehensive services such as authorization via JWT claim inspection, as well as some caching of user and group authorization details. This is an area of active development. Controllers are the entry point into the application proper, and are called after a request has been granted access to the end-point by the middleware. It is here that the body of the request is unmarshalled and mapped into the correct go model structure. Extension-points conforming to standard Jiffy interfaces are provided in the controllers for post-generation enhancements. Models are where the entity data from the request is checked, normalized and prepared for submission to the database. Extension-points conforming to standard Jiffy interfaces are provided in the models for post-generation enhancements. Database refers to the backend DBMS that is used to house the entity data. Jiffy generated applications can connect to PostgreSQL, MariaDB/MySQL, MSSQL, SAP HanaDB or SQLite. It is easy to extend the database support to other relational platforms provided that there is an existing go sql driver for the database in question. It is possible to override the generated Jiffy call to the database and \u0026lsquo;roll-your-own\u0026rsquo; should the need arise.  "
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/gs-content-c/",
	"title": "Let&#39;s Build Something",
	"tags": [],
	"description": "",
	"content": "Now that Jiffy is installed, we will build a simple service to test it out.\nJiffys source tree comes with a number of sample model files that you can be used to get the hang of things. We are going to use a simple model file that contains an entity named \u0026lsquo;Person\u0026rsquo;. The model file can be found in the Jiffy source tree, or pulled directly from the Jiffy github repository.\n $GOPATH/src/github.com/1414C/jiffy/support/testing_models/simpleSingleEntityModel.json jiffy repository model: simpleSingleEntityModel.json  For now we are not going to worry about the content of the model file, but we will look at the structure of our new \u0026lsquo;Person\u0026rsquo; entity briefly.\n// Person structure  type Person struct { ID uint64 `json:\u0026#34;id\u0026#34; sqac:\u0026#34;primary_key:inc;start:10000000\u0026#34;` Href string `json:\u0026#34;href\u0026#34; sqac:\u0026#34;-\u0026#34;` Name *string `json:\u0026#34;name,omitempty\u0026#34; sqac:\u0026#34;nullable:true;index:non-unique\u0026#34;` Age *uint `json:\u0026#34;age,omitempty\u0026#34; sqac:\u0026#34;nullable:true\u0026#34;` Weight *float64 `json:\u0026#34;weight,omitempty\u0026#34; sqac:\u0026#34;nullable:true\u0026#34;` ValidLicense *bool `json:\u0026#34;valid_license,omitempty\u0026#34; sqac:\u0026#34;nullable:true;index:non-unique\u0026#34;` } We can see that Jiffy will create a \u0026lsquo;Person\u0026rsquo; model with a small set of fields, each with a number of attributes. For the moment, we will concern ourselves only with the field names and types, as we will need to use this information to construct some test data for the new service.\n\u0026lsquo;sqac\u0026rsquo; tags are used to pass information to Jiffys ORM layer.\n  Create a new target directory for the project under $GOPATH/src.\ncd $GOPATH/src mkdir jiffy_tests  Execute the jiffy binary, specifying the model file to use, as well as the target directory/project name.\njiffy -m $GOPATH/src/github.com/1414C/jiffy/support/testing_models/simpleSingleEntityModel.json -p /jiffy_tests/first_app -m tells jiffy which model file should be used to construct the new service.\n-p tells jiffy where to write the generated application code.\nNote that the location of the folder specified by the -p flag is deemed to be relative to $GOPATH/src.\n  If everything has gone according to plan, a new application has been generated and should be ready to run. Let\u0026rsquo;s take a look at what jiffy generated for us!\ncd $GOPATH/src/jiffy_tests/first_app ls -l This should result in a list of the files and folders comprising our new application.\ndrwxr-xr-x 12 stevem staff 384 5 Feb 21:44 . drwxr-xr-x 10 stevem staff 320 5 Feb 21:44 .. -rwxr-xr-x 1 stevem staff 588 5 Feb 21:44 .dev.config.json -rwxr-xr-x 1 stevem staff 611 5 Feb 21:44 .prd.config.json drwxr-xr-x 4 stevem staff 128 5 Feb 21:44 appobj drwxr-xr-x 10 stevem staff 320 5 Feb 21:44 controllers drwxr-xr-x 4 stevem staff 128 5 Feb 21:44 jwtkeys -rwxr-xr-x 1 stevem staff 839 5 Feb 21:44 main.go -rwxr-xr-x 1 stevem staff 18421 5 Feb 21:44 main_test.go drwxr-xr-x 3 stevem staff 96 5 Feb 21:44 middleware drwxr-xr-x 12 stevem staff 384 5 Feb 21:44 models drwxr-xr-x 3 stevem staff 96 5 Feb 21:44 util $ Jiffy generates two sample configuration files each time it is executed. We are going to run our application with development environment settings, so lets take a quick look at the .dev.config.json file to make sure there are no horrible surprises.\n{ \u0026#34;external_address\u0026#34;: \u0026#34;127.0.0.1:3000\u0026#34;, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;ping_cycle\u0026#34;: 1, \u0026#34;failure_threshold\u0026#34;: 5, \u0026#34;pepper\u0026#34;: \u0026#34;secret-pepper-key\u0026#34;, \u0026#34;hmac_Key\u0026#34;: \u0026#34;secret-hmac-key\u0026#34;, \u0026#34;database\u0026#34;: { \u0026#34;db_dialect\u0026#34;: \u0026#34;sqlite\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;port\u0026#34;: 0, \u0026#34;usr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testdb.db\u0026#34;, \u0026#34;ormLogActive\u0026#34;: true, \u0026#34;ormDebugTraceActive\u0026#34;: false }, \u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } }, \u0026#34;logging\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;callLocation\u0026#34;: true, \u0026#34;colorMsgTypes\u0026#34;: true, \u0026#34;infoMsgs\u0026#34;: false, \u0026#34;warningMsgs\u0026#34;: false, \u0026#34;errorMsgs\u0026#34;: true, \u0026#34;debugMsgs\u0026#34;: false, \u0026#34;traceMsgs\u0026#34;: false }, \u0026#34;cert_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa384_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;rsa512_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa256_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa384_priv_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.priv.pem\u0026#34;, \u0026#34;ecdsa384_pub_key_file\u0026#34;: \u0026#34;jwtkeys/ecdsa384/ec384.pub.pem\u0026#34;, \u0026#34;ecdsa521_priv_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecdsa521_pub_key_file\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;jwt_sign_method\u0026#34;: \u0026#34;ES384\u0026#34;, \u0026#34;jwt_lifetime\u0026#34;: 120, \u0026#34;service_activations\u0026#34;: [ { \u0026#34;service_name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;service_active\u0026#34;: true } ] } Jiffy decides by default to run against a sqlite database and generates what should be a suitable configuration file for most systems. Again, we are not going to worry too much about what is in the configuration file at this point, but know that database file \u0026lsquo;testdb.db\u0026rsquo; will be created in the generated application\u0026rsquo;s root folder. For more information regarding the content of the configuration files see the Application Configuration Overview section of this document.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-d/",
	"title": "Generated &#39;controllers&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;controllers\u0026rsquo; Folder FirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go  controllers   authc.go   controllerfuncs.go   groupauthc.go   person_relationsc.go   personc.go   usrc.go   usr_groupc.go   ext   extc_interfaces.go   personc_ext.go  group   ...    ... . . . . .  .dev.config.json  .prd.config.json  main_test.go  main.go A controller is created for each entity that has been declared in the model files, as well as a number of static controllers that are used to handle the application\u0026rsquo;s users and authorization objects.\nControllers act as a bridge between an entity\u0026rsquo;s routes and its model layer. Each entity mux route is assigned a method in their respective controller based on the intent of that route. For example, to create a new new \u0026lsquo;Library\u0026rsquo; entity the following POST could be made:\nhttps://servername:port/library {JSON body} + POST The route for this call is defined in appobj.go as follows, where \u0026lsquo;a\u0026rsquo; is the one-and-only instance of the AppObj:\na.router.HandleFunc(\u0026#34;/library\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Create)).Methods(\u0026#34;POST\u0026#34;) The \u0026lsquo;/library\u0026rsquo;-POST route is assigned a HandleFunc belonging to the instance of the LibraryController that has been created on the appobj. Controller method a.libraryC.Create is called for the \u0026lsquo;library\u0026rsquo; route when the http method equals \u0026lsquo;POST\u0026rsquo;. The route contains some additional code related to authentication and authorization of the requester but this can be ignored for now. The handler function for a mux.route must conform to the standard go http.Handler interface:\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } This interface facilitates the passing of the incoming request header and body to the controller method, as well as the passing of the formatted response back to the router. With this out of out the way, let\u0026rsquo;s look at generated Controller method LibraryController.Create:\n// Create facilitates the creation of a new Library. This method is bound  // to the gorilla.mux router in main.go.  //  // POST /library  func (lc *LibraryController) Create(w http.ResponseWriter, r *http.Request) { var l models.Library decoder := json.NewDecoder(r.Body) if err := decoder.Decode(\u0026amp;l); err != nil { log.Println(\u0026#34;Library Create:\u0026#34;, err) respondWithError(w, http.StatusBadRequest, \u0026#34;libraryc: Invalid request payload\u0026#34;) return } defer r.Body.Close() // fill the model  library := models.Library{ Name: l.Name, City: l.City, } // build a base urlString for the JSON Body self-referencing Href tag  urlString := buildHrefStringFromCRUDReq(r, true) // call the Create method on the library model  err := lc.ls.Create(\u0026amp;library) if err != nil { log.Println(\u0026#34;Library Create:\u0026#34;, err) respondWithError(w, http.StatusBadRequest, err.Error()) return } library.Href = urlString + strconv.FormatUint(uint64(library.ID), 10) respondWithJSON(w, http.StatusCreated, library) } The complete Library.Create(http.Handler) controller method is shown exactly as it has been generated.\nEach section of the method is broken down in the following subsets of commented code:\n// declare a local variable of struct type models.Library to hold the decoded  // JSON body provided in the request.Body.  var l models.Library // create a new JSON decoder passing in the request.Body  decoder := json.NewDecoder(r.Body) // call the Decoder.Decode(interface{}) method passing a reference to the  // locally declared models.Library struct \u0026#39;l\u0026#39;. if the decoder is able to  // decode the JSON contained in the request.Body, the member fields of \u0026#39;l\u0026#39;  // will be populated. if the decoder fails to parse and map the incoming  // JSON to the models.Library struct, it will return an error. The problem  // will be logged to stdout (for now) on the server-instance, and a response  // conforming to the http.Handler interface will be constructed and passed  // back to the router. if the JSON was parsed closed upon exit of the method.  if err := decoder.Decode(\u0026amp;l); err != nil { log.Println(\u0026#34;Library Create:\u0026#34;, err) respondWithError(w, http.StatusBadRequest, \u0026#34;libraryc: Invalid request payload\u0026#34;) return } defer r.Body.Close() // fill the model with the parsed content of the JSON body. this step looks  // redundant, but can be thought of as a way to separate the incoming data  // from the response. going forward from this point, \u0026#39;l\u0026#39; is ignored and  // all data transformation occurs on the \u0026#39;library\u0026#39; variable.  library := models.Library{ Name: l.Name, City: l.City, } // build a base urlString for the JSON Body self-referencing Href tag  urlString := buildHrefStringFromCRUDReq(r, true) // call the Create method on the library model. each controller contains an  // instance of the Service for it\u0026#39;s respective entity. the Create method on  // the service is called, passing a reference to the \u0026#39;library\u0026#39; data structure.  // recall that the Service for an entity provides the link to that entity\u0026#39;s  // model-layer by way of the entity\u0026#39;s validator. lc.ls.Create(\u0026amp;library) will  // result in a call the model Validator Create() method for the Library  // entity, and in-turn, call to the enitity\u0026#39;s model.Create() method where  // the data will be passed to the ORM-layer. if the Create() call returns  // an error, the problem will be logged to stdout (for now) on the server-  // instance, and a response conforming to the http.Handler interface will be  // constructed and passed back to the router.  err := lc.ls.Create(\u0026amp;library) if err != nil { log.Println(\u0026#34;Library Create:\u0026#34;, err) respondWithError(w, http.StatusBadRequest, err.Error()) return } // if the call to the model-layer was successful, it indicates that a new  // Library entity was created in the DBMS. the \u0026#39;library\u0026#39; reference passsed  // to the Create() method(s) in the model-layer will now contiain the new  // Library\u0026#39;s information. first, the ID for the new Library will be added  // to the urlString and assigned to the library struct\u0026#39;s Href member field.  // Href is another injected field in the entity and fullfills the purpose  // of providing a direct URI for the returned entity. finally the populated  // \u0026#39;library\u0026#39; struct is formatted as a JSON response and passed back to the  // router along with an http status-code indicating success.  library.Href = urlString + strconv.FormatUint(uint64(library.ID), 10) respondWithJSON(w, http.StatusCreated, library) } The controllers folder also contains an \u0026lsquo;ext\u0026rsquo; sub-directory which is used to hold the interface definitions for controller extension-points as well as the associated empty implementation for each entity. See the Controller Extension Points section of this document for more details.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/models/mo-content-d/",
	"title": "Entity Relations",
	"tags": [],
	"description": "",
	"content": "Modeling Entity Relationships Relationships between entities can be declared in the application model file via the addition of a \u0026lsquo;relations\u0026rsquo; block inside an entity\u0026rsquo;s declaration. Relationships are based on resource id\u0026rsquo;s by default, although it is possible to specify non-default key fields in the configuration, or implement complex joins directly by maintaining the entity\u0026rsquo;s controller and model. \u0026lsquo;relations\u0026rsquo; blocks look as follows:\n\u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToOwner\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasOne\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Owner\u0026#34; } } ] The sample relations block illustrates the declaration of a \u0026lsquo;hasOne\u0026rsquo; relationship between \u0026lsquo;Car\u0026rsquo; and \u0026lsquo;Owner\u0026rsquo; making use of default-keys (ID).\nhasOne Relationship \u0026lsquo;hasOne\u0026rsquo; relationships establish a one-to-one relationship between two modeled entities. As an example, let\u0026rsquo;s posit that a car can have one owner. If the car and owner were modeled as entities, we could declare a \u0026lsquo;hasOne\u0026rsquo; (1:1) relationship between them. The relation would be added to the \u0026lsquo;relations\u0026rsquo; block inside the \u0026lsquo;Car\u0026rsquo; entity definition (as shown above).\nA break-down of the relations block fields is as follows:\n{ \u0026#34;relations\u0026#34;: [ // The \u0026#39;entities\u0026#39; block contains an array of relations belonging to the containing  // entity definition. Each relation is defined from the perspective of the  // containing entity having a relationship of the specified type (in this case  // hasOne), with the entity referenced in the declaration. A \u0026#39;Car\u0026#39; has one \u0026#39;Owner\u0026#39;  // - in our example at least.  { \u0026#34;relName\u0026#34;: \u0026#34;Owner\u0026#34; // Field \u0026#39;relName\u0026#39; refers to the name the relationship will be known by inside  // the application and in the mux route end-point definition. It must be  // capitalized and written in CamelCase. Any name may be chosen for this  // field, but keep in mind the name will be exposed to the service consumer via  // the URI, so something respecting the relationship enities and cardinality is  // best. For the example, we have chosen a relName of \u0026#39;ToOwner\u0026#39; to demonstrate  // the difference between the toEntity and relName fields.  // \u0026#39;relName\u0026#39; is a mandatory field in a relations declaration.  \u0026#34;properties\u0026#34;: { // The \u0026#39;properties\u0026#39; block contains the details of the relationship.  \u0026#34;relType\u0026#34;: // Field \u0026#39;relType\u0026#39; is used to indicate what sort of relationship is being  // declared between the containing (from) entity and the toEntity.  // Valid values are {hasOne, hasMany and belongsTo}.  // This is a mandatory field.  \u0026#34;toEntity\u0026#34;: // Field \u0026#39;toEntity\u0026#39; is used to specify the target entity in the  // relationship. The toEnity must be capitalized and provided in CamelCase  // that matches that used in the toEntity\u0026#39;s declaration. The toEntity need  // not appear prior to the containing entity in the model file or files.  // This is a mandatory field.  } } ] } A complete example of a model file containing \u0026lsquo;Car\u0026rsquo; and \u0026lsquo;Owner\u0026rsquo; entity definitions along with the \u0026lsquo;hasOne\u0026rsquo; relationship is shown below. Notice that the \u0026lsquo;Car\u0026rsquo; entity has been declared with an \u0026lsquo;OwnerID\u0026rsquo; field. As our \u0026lsquo;Car\u0026rsquo; model specifies that a \u0026lsquo;Car\u0026rsquo; may have one \u0026lsquo;Owner\u0026rsquo;, it makes sense for the key-relationship to go from \u0026lsquo;Car\u0026rsquo; back to the \u0026lsquo;Owner\u0026rsquo;.\nBy default jiffy looks for a targetEntity + ID field when attempting to generate the constraint on the database system. Although it is possible to override this behavior, it is recommended to use the jiffy standard. It is incumbent on the model designer to include the correct foreign-key fields in the model.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Owner\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;RegistrationNumber\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;City\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; } }, \u0026#34;compositeIndexes\u0026#34;: [ {\u0026#34;index\u0026#34;: \u0026#34;name, city\u0026#34;} ], \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToCar\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasOne\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Car\u0026#34; } } ], \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } }, { \u0026#34;typeName\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Model\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Make\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;OwnerID\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: hasOne.json.\nhasMany Relationship \u0026lsquo;hasMany\u0026rsquo; relationships establish a one-to-many relationship between two modeled entities. As an example, let\u0026rsquo;s posit that a library can have many books. If library and book were modeled as entities, we could declare a \u0026lsquo;hasMany\u0026rsquo; (1:N) relationship between them. The relation would be added to the \u0026lsquo;relations\u0026rsquo; block inside the \u0026lsquo;Library\u0026rsquo; entity definition. Notice that the \u0026lsquo;Book\u0026rsquo; entity has been declared with an \u0026lsquo;LibraryID\u0026rsquo; field. As our \u0026lsquo;Library\u0026rsquo; model specifies that a \u0026lsquo;Library\u0026rsquo; may have many \u0026lsquo;Book\u0026rsquo; entities, it makes sense for the key-relationship to go from \u0026lsquo;Book\u0026rsquo; back to the \u0026lsquo;Library\u0026rsquo;.\nBy default jiffy looks for a targetEntity + ID field when attempting to generate the constraint on the database system. Although it is possible to override this behavior, it is recommended to use the jiffy standard. It is incumbent on the model designer to include the correct foreign-key fields in the model.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;City\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true }, \u0026#34;compositeIndexes\u0026#34;: [ {\u0026#34;index\u0026#34;: \u0026#34;name, city\u0026#34;} ], \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;Books\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasMany\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Book\u0026#34; } } ] }, { \u0026#34;typeName\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Hardcover\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,ne\u0026#34; }, \u0026#34;Copies\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;LibraryID\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; } }, \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: hasManyDefaultKeys.json.\nAgain, it seems that this model does not capture the entire story, as each book belongs to its respective library. This brings us to the \u0026lsquo;belongsTo\u0026rsquo; relationship type.\nbelongsTo Relationship \u0026lsquo;belongsTo\u0026rsquo; relationships are used to form the inverse of the \u0026lsquo;hasOne\u0026rsquo; and \u0026lsquo;hasMany\u0026rsquo; relations. Consider the library \u0026lsquo;hasMany\u0026rsquo; books example; A library has many books, but we can also posit that a book belongs to a library; this is an example of a \u0026lsquo;belongsTo\u0026rsquo; relationship. The JSON below extends the \u0026lsquo;Library\u0026rsquo; -\u0026gt; \u0026lsquo;Book\u0026rsquo; example by adding the \u0026lsquo;belongsTo\u0026rsquo; relationship to the \u0026lsquo;Book\u0026rsquo; entity definition:\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;City\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt,like\u0026#34; } }, \u0026#34;compositeIndexes\u0026#34;: [ {\u0026#34;index\u0026#34;: \u0026#34;name, city\u0026#34;} ], \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToBooks\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasMany\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Book\u0026#34; } } ], \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } }, { \u0026#34;typeName\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;default\u0026#34;: \u0026#34;unknown title\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Author\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;degault\u0026#34;: \u0026#34;unknown author\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Hardcover\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,ne\u0026#34; }, \u0026#34;Copies\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;LibraryID\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; } }, \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToLibrary\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;belongsTo\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Library\u0026#34; } } ], \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } The sample model file can be downloaded from the following location: hasManyBelongsTo.json.\nBy relying on the default key determinations for the \u0026lsquo;belongsTo\u0026rsquo; relationship, the generator determines that the Book.LibraryID field should be matched against field Library.ID. If alternate keys are desired, they can be specified in the \u0026lsquo;refKey\u0026rsquo; and \u0026lsquo;foreignKey\u0026rsquo; property fields in the \u0026lsquo;belongsTo\u0026rsquo; relation declaration.\nWhat if more complex relationships are required? At the moment the generator only supports \u0026lsquo;hasOne\u0026rsquo;, \u0026lsquo;hasMany\u0026rsquo; and \u0026lsquo;belongsTo\u0026rsquo; relations, as in practice these seem to be the most widely used. The generated code can be extended to accommodate additional relationships and joins if need be. There is a tentative plan to support more complex relations in the generator in the future. Most of the supporting code is in place, but the controller_rel templates would need to be enhanced to support it. In the meantime, a combination of foreign-keys and static filters or hand-coded SQL can be employed as an alternative to formally defined relationships in cases where the entity-id model is not sufficient. See the Custom Join Tutorial for an example of coding a custom-join between two entities.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/models/mo-content-e/",
	"title": "Accessing Entity Relations",
	"tags": [],
	"description": "",
	"content": "Entity Relationship URL\u0026rsquo;s In the previous section we saw how model files can be used to define relationships between declared entities. We will now look at how to access and test the relationships via Postman tests.\nThis section uses the hasManyBelongsTo.json model from the jiffy repository. Rather than generate a new application from the model, you may choose to pull a pre-generated jiffy application source tree based on the model. To do so, switch to a sub-directory under your $GOPATH/src folder and run the following command in a terminal window.\ngo get -u github.com/1414C/libraryapp This will have the effect of pulling the application source code into a folder (libraryapp). Follow the instructions at the following link to start the application on your test machine.\nTo recap, our model contains two entities - Library and Book. A Library may have 0:n Books, and a Book must belong to one and only one Library.\n{ \u0026#34;entities\u0026#34;: [ { \u0026#34;typeName\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;City\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;unique\u0026#34;: false, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt,like\u0026#34; } }, \u0026#34;compositeIndexes\u0026#34;: [ {\u0026#34;index\u0026#34;: \u0026#34;name, city\u0026#34;} ], \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToBooks\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasMany\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Book\u0026#34; } } ], \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } }, { \u0026#34;typeName\u0026#34;: \u0026#34;Book\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;default\u0026#34;: \u0026#34;unknown title\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Author\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: false, \u0026#34;degault\u0026#34;: \u0026#34;unknown author\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; }, \u0026#34;Hardcover\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,ne\u0026#34; }, \u0026#34;Copies\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,lt,gt\u0026#34; }, \u0026#34;LibraryID\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;uint64\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;nonUnique\u0026#34;, \u0026#34;selectable\u0026#34;: \u0026#34;eq,like\u0026#34; } }, \u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToLibrary\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;belongsTo\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Library\u0026#34; } } ], \u0026#34;ext_points\u0026#34;: { \u0026#34;gen_controller\u0026#34;: true, \u0026#34;gen_model\u0026#34;: true } } ] } Start the application.\ngo run main.go -dev -rs # use -rs the first time you start the app \nLogin Launch Postman and create a new test specifying a target URL of: http://\u0026lt;your-ip-address:8080/usr/login making sure to select the http POST method. Maintain the request header as shown below to add the correct Content-Type.\nNext, maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a Jiffy application is an email address, but we make an exception for the default administration user.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.\nIf all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single \u0026lsquo;token\u0026rsquo; tag containing a jumble of letters and numbers. This is the JSON Web Token (JWT) that will be used to validate your authorization to access the Person entity\u0026rsquo;s service end-points. If you want to read more about JWTs, jwt.io is a good place to start, or you can refer to the Access Control section of this document set.\nCreate a Library Now that you have successfully logged into the application and received your first JWT, it is time to create a new \u0026lsquo;Person\u0026rsquo; entity. Start by copying the content of the \u0026lsquo;token\u0026rsquo; tag from the login response body to the clipboard. This JWT must henceforth be included in the http header of every subsequent request.\nCreate a new tab in Postman and specify a target URL of http://your-ip-address:8080/library with the http POST method. Next, add the following key-value pairs to the http header:\n Content-Type : application\\json Authorization : Bearer *paste-your-JWT-here*  When you have finished maintaining the http header-values, click on \u0026lsquo;Body\u0026rsquo; and maintain it using the \u0026lsquo;raw\u0026rsquo; setting. This will allow you to paste the following JSON code snippet into the request\u0026rsquo;s body:\n{ \u0026#34;name\u0026#34;: \u0026#34;Bill the Cat Public Libary\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Denver\u0026#34; } When you have finished, the test session should look as follows and it is time to create your first \u0026lsquo;Library\u0026rsquo; entity. Click \u0026lsquo;Send\u0026rsquo; to post the new entity to the application.\nCongratulations! You have created your first \u0026lsquo;Library\u0026rsquo; entity!\nWhat Just Happened? The router matched the request URL to a route (service end-point), the middleware layer in the matched route examined the JWT, verified it was okay to proceed and then passed the raw JSON from the request body to the \u0026lsquo;Library\u0026rsquo; entity\u0026rsquo;s controller. The controller unmarshalled the JSON into a \u0026lsquo;Library\u0026rsquo; struct and then passed the result to the Create method in the model/validation layer. Validation of the \u0026lsquo;Library\u0026rsquo; struct\u0026rsquo;s content occurred, and then a call was made to the underlying sqac ORM to create the entity on the database.\nThe sqac ORM-layer returned the new entity to the application\u0026rsquo;s model-layer, where it was checked and passed back to the controller layer, whereupon it was marshaled (struct content becomes JSON) and written to the the response-writer.\nThis is a high-level view of what transpired, but the general flow of things is accurate.\nNotice that the entity passed back to us seems to have a couple of extra fields? All entities created via a Jiffy model file are injected with a primary-key of \u0026lsquo;id\u0026rsquo; as well as a non-persistent \u0026lsquo;href\u0026rsquo; field. In this example, our entity\u0026rsquo;s \u0026lsquo;id\u0026rsquo; field was specified in the model file to be auto-incrementing with no starting value. \u0026lsquo;href\u0026rsquo; is included in each entity\u0026rsquo;s GET responses, and acts as a self-reference providing the entity\u0026rsquo;s direct access URI to the consumer.\nSee the Annotated Simple Single Entity Model in the Model Maintenance section for details regarding key options.\nCreate a Second Library Following the same steps as above, adjust the Body of the Library POST request to create another \u0026lsquo;Library\u0026rsquo; entity as follows:\n{ \u0026#34;name\u0026#34;: \u0026#34;Opus the Penguin Public Library\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Denver\u0026#34; } Submission of the request should result in the creation of a new \u0026lsquo;Library\u0026rsquo; entity:\n\nCreate a Book for Library 1 At the moment, your libraries don\u0026rsquo;t have any books but that is about to change. Create a new POST request in Postman, making sure to maintain the header as follows:\n Content-Type : application\\json Authorization : Bearer *paste-your-JWT-here*  When you have finished maintaining the http header-values, click on \u0026lsquo;Body\u0026rsquo; and maintain it using the \u0026lsquo;raw\u0026rsquo; setting. This will allow you to paste the following JSON code snippet into the request\u0026rsquo;s body:\n{ \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Turtle\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: true, \u0026#34;copies\u0026#34;: 3, \u0026#34;library_id\u0026#34;: 1 } When you have finished, the test session should look as follows and it is time to create your first \u0026lsquo;Book\u0026rsquo; entity. Click \u0026lsquo;Send\u0026rsquo; to post the new entity to the application.\nIf all went well, you will see something like this in the response:\nNotice that we have allocated the new \u0026lsquo;Book\u0026rsquo; entity to \u0026lsquo;Library\u0026rsquo; entity 1. \nCreate More Books for Library 1 Following the same steps as above, adjust the Body of the Book POST request to create another \u0026lsquo;Book\u0026rsquo; entity as follows:\n{ \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Fox\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: false, \u0026#34;copies\u0026#34;: 4, \u0026#34;library_id\u0026#34;: 1 } Submission of the request should result in the creation of another new \u0026lsquo;Library\u0026rsquo; entity:\nUse the following JSON snippets to create a few more books for librarys 1 \u0026amp; 2:\nCreate Books for Library 1 { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Wolf\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: false, \u0026#34;copies\u0026#34;: 2, \u0026#34;library_id\u0026#34;: 1 } { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Turtle\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: true, \u0026#34;copies\u0026#34;: 2, \u0026#34;library_id\u0026#34;: 1 } { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Turtle\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: false, \u0026#34;copies\u0026#34;: 5, \u0026#34;library_id\u0026#34;: 1 } { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: true, \u0026#34;copies\u0026#34;: 2, \u0026#34;library_id\u0026#34;: 1 }  Create Books for Library 2 { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit tricks Mr. Turtle\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: false, \u0026#34;copies\u0026#34;: 2, \u0026#34;library_id\u0026#34;: 2 } { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: true, \u0026#34;copies\u0026#34;: 1, \u0026#34;library_id\u0026#34;: 2 } { \u0026#34;title\u0026#34;: \u0026#34;Peter Rabbit Tricks Mr. Owl\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Beatrix Potter\u0026#34;, \u0026#34;hardcover\u0026#34;: false, \u0026#34;copies\u0026#34;: 4, \u0026#34;library_id\u0026#34;: 2 }  Get All of the Books For All Librarys Create a new GET request in Postman specifying a target URL of http://your-ip-address:8080/books, making sure to maintain the header as follows:\n Authorization : Bearer *paste-your-JWT-here*  When you have finished, the request should look as follows:\nWhen you submit the request, the application should send a response containing all of the Book entities for both Libraries:\n\nGet All of the Books for Library 1 Create a new GET request in Postman specifying a target URL of http://your-ip-address:8080/library/1/toBooks, making sure to maintain the header as follows:\n Authorization : Bearer *paste-your-JWT-here*  When you have finished, the request should look as follows:\nWhen you submit the request, the application should send a response containing all of the Book entities that are owned by Library 1. As Libraries tend to have more than one title to lend, the tobooks relationship has been defined as a hasMany relationship (1:n). The end-point handler for the ./library/1/tobooks URI knows that there is a relationship between the Library and Book entities, and is therefore able to process the request.\n\u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToBooks\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;hasMany\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Book\u0026#34; } } ], The relations array in the Library block of the model file instructed jiffy to generate the end-point, end-point handler as well as database constraints to formally implement the relationship.\nTry the same test to retrieve a list of all of the Book entities belonging to Library 2. \nGet a Count of All Books Rather than read potentially thousands of Books via a GET request, you may wish to simply get a count of how many Books exist. Use the following URI to create a new GET request to return the number of Books.\nhttp://your-ip-address:8080/books/$count\nThe response should look similar to:\nJiffy applications return the result of a $count command in the response body rather than in the response header. In this case, the response body contains the number \u0026lsquo;9\u0026rsquo; indicating that there are 9 Books in total. \nGet a Count of Books Belonging to Library 1 Use the following URI to create a new GET request to return the number of Books that belong to Library 1.\nhttp://your-ip-address:8080/library/1/tobooks/$count\nThe response should look similar to:\n\nGet a Count of Books Belonging to Library 2 Use the following URI to create a new GET request to return the number of Books that belong to Library 2.\nhttp://your-ip-address:8080/library/2/tobooks/$count\nThe response should look similar to:\nLibrary 1 has 6 Books, while Library 2 has 3 giving a total of 9 Books.\n\nFinding A Book\u0026rsquo;s Library If the application has read a Book and needs details regarding that Book\u0026rsquo;s Library, the hasOne relationship can be leveraged to read the Library details. In the following example, a Book with an ID of 2 has been read from the database. The response body indicates that the Book belongsTo Library 1. The inverse of the hasMany relationship is the belongsTo relationship, which was defined in the model file that the application was generated from:\n\u0026#34;relations\u0026#34;: [ { \u0026#34;relName\u0026#34;: \u0026#34;ToLibrary\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;relType\u0026#34;: \u0026#34;belongsTo\u0026#34;, \u0026#34;toEntity\u0026#34;: \u0026#34;Library\u0026#34; } } ], Use the following URI to create a new GET request to read a Book\u0026rsquo;s Library details from the database:\nhttp://your-ip-address:8080/book/2/tolibrary\nThe response should look similar to:\nWhat Else? There are a number of suffixes that can be applied to the GET URI in order to influence what is returned to the caller. Refer to the CRUD Access, Filters and Relationships and Commands section in the Jiffy Application Overview section of the documentation for details.\nAs an example, a call to GET Books from Library 1 could be constructed with the following parameters:\nhttps://your-ip-address:8080/library/1/tobooks/\\$limit=3\\$offset=2\\$orderby=name$asc\n return no more than 3 Books ($limit=3) do not return the first 2 Books ($offset=2) sort the returned list by name in ascending order  Offset and limit are common operations when you wish to return pages of results.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tutorials/using-docker/dr-content-g/",
	"title": "Troubleshooting",
	"tags": [],
	"description": "",
	"content": "Overview If a container crashes when executing the entrypoint, there are a few things that can be done to help figure out what is going on.\nStart the Container in Interactive Mode Docker allows containers to be started with flags that direct the console output to the starter\u0026rsquo;s session. For example, to start a containerized jiffy application in this manner use the following command/flags:\nAardvark:pgelibraryapp stevem$ docker start pgelibraryapp -ia When Docker starts the container, the ENTRYPOINT specified in the image\u0026rsquo;s Dockerfile will be executed. Due to the removal of the -d flag and the addition of the -ia flags in the docker start command, anything written to the container\u0026rsquo;s stdout/stderr will be output in the starter\u0026rsquo;s terminal session. The -i flag allows the starter to supply input if user-input is required (probably unusual in the jiffy-application case).\nconsole output: 2018/06/23 00:09:41 package sqac init is running 2018/06/23 00:09:41 successfully loaded the config file... 2018/06/23 00:09:41 config: {172.17.0.2:8080 172.17.0.2:4444 dev 1 5 secret-pepper-key {postgres 192.168.1.65 5432 godev gogogo123 glrestgen} jwtkeys/ecdsa384/ec384.priv.pem jwtkeys/ecdsa384/ec384.pub.pem ES384 120 [{Library true} {Book true}]} 2018/06/23 00:09:41 ECDSA256PrivKeyFile: 2018/06/23 00:09:41 ECDSA256PubKeyFile: 2018/06/23 00:09:41 ECDSA384PrivKeyFile: jwtkeys/ecdsa384/ec384.priv.pem 2018/06/23 00:09:41 ECDSA384PubKeyFile: jwtkeys/ecdsa384/ec384.pub.pem 2018/06/23 00:09:41 ECDSA521PrivKeyFile: 2018/06/23 00:09:41 ECDSA521PubKeyFile: 2018/06/23 00:09:41 RSA256PrivKeyFile: 2018/06/23 00:09:41 RSA256PubKeyFile: 2018/06/23 00:09:41 RSA384PrivKeyFile: 2018/06/23 00:09:41 RSA384PubKeyFile: 2018/06/23 00:09:41 RSA512PrivKeyFile: 2018/06/23 00:09:41 RSA512PubKeyFile: 2018/06/23 00:09:41 Login() signing jwt's with ES384 Development settings selected... Starting http server on: 172.17.0.2:8080 2018/06/23 00:09:41 listening for ws traffic on 172.17.0.2:4444 2018/06/23 00:09:43 gm.count: 1 2018/06/23 00:09:43 gm.count: 2 2018/06/23 00:09:44 gm.count: 3 2018/06/23 00:09:45 gm.count: 4 2018/06/23 00:09:45 JOIN: no leader detected - setting myID = 1 as leader 2018/06/23 00:09:45 gm.count: 5 2018/06/23 00:09:45 db and local leader set to 1, 172.17.0.2:4444 2018/06/23 00:09:45 initialization complete... 2018/06/23 00:09:45 leader info is: {1 172.17.0.2:4444} 2018/06/23 00:09:46 PING CYCLE: starting ping cycle... 2018/06/23 00:09:46 gm.count: 6 2018/06/23 00:09:46 sendPing assembled index slice: [0] 2018/06/23 00:09:46 sending PING: {PING 1 172.17.0.2:4444 1 0 1 172.17.0.2:4444 1 /ping ALIVE 1 0 true 0xc4205d2f30 false false []} 2018/06/23 00:09:46 EncodeGMMessage \u0026amp;m.MemberMap: 0xc42005ece0 2018/06/23 00:09:46 websocket.Dial: ws://172.17.0.2:4444/ping 2018/06/23 00:09:46 websocket.Dial: ws://172.17.0.2:4444/ping complete 2018/06/23 00:09:46 gm.count: 7 ... ... \n\nThe Container Crashes During Startup Containers can crash during startup if something prevents the ENTRYPOINT from executing successfully. In the context of a jiffy application a common cause of failure during startup is failure to connect to the database (for example). When a container crashes on startup, the first thing to do is attempt to restart the container using the -ia flags as described above. It is possible that a corrective action can be determined and implemented by reviewing the stdout/stderr during the container startup.\nIf you are unable to correct the startup issue after reviewing the stdout/stderr output a good next step is logging into the container to investigate the issue. How can we do this if the container is not running?\nWithout going overboard on repeating the Docker online docs, it is helpful in these circumstances to remember that Docker images are constructed of so-called \u0026lsquo;layers\u0026rsquo;. Thinking back to the output of the docker build command, we see some numbers that look suspiciously like docker image id\u0026rsquo;s in each step of the image build output:\n... ... Step 13/18 : RUN apk add file ---\u0026gt; Running in 51acae660d55 (1/2) Installing libmagic (5.32-r0) (2/2) Installing file (5.32-r0) Executing busybox-1.27.2-r7.trigger OK: 9 MiB in 13 packages Removing intermediate container 51acae660d55 ---\u0026gt; 566a1ee53ff0 \u0026lt;---- this is interesting Step 14/18 : RUN apk add busybox-extras ... ... The Docker online docs tell us the following about image construction:\n Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.\n This is important, because it informs us that Docker sees images as accretions of layers corresponding to the build-steps in the Dockerfile used to define the image. The next interesting point is that each layer corresponds to an intermediate image that inherits all of the intermediate images related to the previous docker build steps in the original Dockerfile. We can get a list of the image-layers for our container by running the docker history command:\ndocker history pgelibraryapp Running the command for the pgelibraryapp image results in output similar to:\nIMAGE CREATED CREATED BY SIZE 2f8b3df80aea About an hour ago /bin/sh -c #(nop) ENTRYPOINT [\u0026quot;/main\u0026quot;] 0B 7c6e201e86d2 About an hour ago /bin/sh -c #(nop) CMD [\u0026quot;-dev\u0026quot;] 0B 0ccad193e938 About an hour ago /bin/sh -c apk add postgresql-client 7.31MB 9e0557830716 About an hour ago /bin/sh -c apk add openssh-client 3.09MB 1adf3e8bbaf2 About an hour ago /bin/sh -c apk add busybox-extras 119kB 566a1ee53ff0 About an hour ago /bin/sh -c apk add file 5.12MB e365a84b6aec About an hour ago /bin/sh -c apk update 1.22MB 2963aa3091b8 About an hour ago /bin/sh -c #(nop) EXPOSE 8080 0B 8f359a48314a About an hour ago /bin/sh -c #(nop) ENV PORT=8080 0B f8563aec3763 About an hour ago /bin/sh -c #(nop) COPY dir:93ede63eb2fbf590a 7.92kB 17afeeae80b5 About an hour ago /bin/sh -c mkdir jwtkeys 0B 1e9f1d632409 About an hour ago /bin/sh -c sh setaddress.sh 1.21kB 2381bd9d01b2 About an hour ago /bin/sh -c /bin/chmod 755 setaddress.sh 352B 9996d0cbf44c About an hour ago /bin/sh -c #(nop) ADD file:b4cc3b29b753aaa7a 352B d2764e99b3f5 About an hour ago /bin/sh -c #(nop) COPY file:1331fb51eea27513 1.22kB deec414c95e4 About an hour ago /bin/sh -c #(nop) ADD file:5604ab9e3793fff27 14MB 7bd0bd5537d4 2 days ago /bin/sh -c #(nop) LABEL maintainer=\u0026lt;stevem@ 0B 3fd9065eaf02 5 months ago /bin/sh -c #(nop) CMD [\u0026quot;/bin/sh\u0026quot;] 0B \u0026lt;missing\u0026gt; 5 months ago /bin/sh -c #(nop) ADD file:093f0723fa46f6cdb 4.15MB Starting from the bottom of the list and going up, we can see that each image builds on the images before it, all the way up to the image corresponding to the named pgelibraryapp image. This can be easily corroborated by running the docker image command with the pgelibraryapp image name as the command\u0026rsquo;s ls criteria:\ndocker image ls pgelib* Resulting in output similar to:\nREPOSITORY TAG IMAGE ID CREATED SIZE pgelibraryapp latest 2f8b3df80aea About an hour ago 35MB Compare the IMAGE ID of the pgelibraryapp image with the top-level image reported by the docker history pgelibraryapp command. They are the same. We can infer from this that if an image is an image is an image, we should be able to start any image in the history list.\nAssuming that the container is crashing when attempting to execute the ENTRYPOINT, it may be useful to create and start a container using a source image that does everything but run the ENTRYPOINT step. We can do this by selecting the intermediate image that we would like to run as a container and running the following command:\ndocker run -it 0ccad193e938 /bin/sh A check of the docker history output above tells us that intermediate image 0ccad193e938 contains everything that should be in our image with the exception of the ENTRYPOINT and CMD(flags) steps. Starting the intermediate image as shown tells Docker to create a container from the intermediate image, run it in the foreground starting an interactive session running /bin/sh:\ndocker run -it 0ccad193e938 /bin/sh Resulting in a root login to the container created from image 0ccad193e938:\n/ # set HISTFILE=\u0026#39;/root/.ash_history\u0026#39; HOME=\u0026#39;/root\u0026#39; HOSTNAME=\u0026#39;1aac17789e87\u0026#39; IFS=\u0026#39; \u0026#39; OPTIND=\u0026#39;1\u0026#39; PATH=\u0026#39;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#39; PORT=\u0026#39;8080\u0026#39; PPID=\u0026#39;0\u0026#39; PS1=\u0026#39;\\w \\$ \u0026#39; PS2=\u0026#39;\u0026gt; \u0026#39; PS4=\u0026#39;+ \u0026#39; PWD=\u0026#39;/\u0026#39; SHLVL=\u0026#39;1\u0026#39; TERM=\u0026#39;xterm\u0026#39; / # From here we can try to figure out what the problem is by attempting to start the application directly, inspecting the Alpine Linux setup, adding and configuring missing packages, adjusting network setup (careful) etc. When the problem has been solved and the application can be started by running the docker-entrypoint.sh script in the container session the source Dockerfile/scripts can be updated to reflect the required changes.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-e/",
	"title": "Application Server Flags",
	"tags": [],
	"description": "",
	"content": "Application Server Flags Flags are generally not used, as the configuration files (models.json) are easier to deal with. There are however, a few flags that can be used when starting the server:\n -dr  The -dr switch is used to perform a destructive reset of the application\u0026rsquo;s data tables. This flag causes the application tables to be dropped and recreated, but does not affect the user, user-group, or authorization tables.    go run main.go -dev -dr  -rs  The -rs switch is used to add new auths detected in the route and add them to the Super user-group. It is a good idea to run with this flag in changing environments.    go run main.go -dev -rs  "
},
{
	"uri": "https://1414c.github.io/jiffy/overview/ov-content-e/",
	"title": "Jiffy Development Steps",
	"tags": [],
	"description": "",
	"content": "Jiffy Pre-Generation Workflow Jiffy is intended to generate a clean, straight-forward and secure application services platform just like the one you would write by hand. Jiffy originally started as a few Go templates used to generate boiler-plate code that seemed onerous to type. Generation is a lot nicer than cut-and-paste. There are places in the generated code where things could be more elegant, but the code is intended to be easy to work on even if one is not familiar with it. File and folder names are somewhat subjective; an attempt has been made to be descriptive and organized.\nDesign Steps   You are building a back-end of some sort where you need to reliably read and write data. Before you start building the \u0026lsquo;real\u0026rsquo; Jiffy model of your application, try some of the demo models to get a feel for what Jiffy is and what it isn\u0026rsquo;t. It is a lot easier to design if you know what the platform provides and what it does not.\n  Start messing around with entity ideas. What is the best way to represent your data? Transferring your ideas into a few rough diagrams often changes your understanding of what you are modeling.\n  Consider the relationships you would like to have between your entities. Does your model still hold up?\n  Add some detail to your proposed entities in terms of fields. Remember that Jiffy will insert a primary-key (id), as well as a self-referencing entity href into the model for you. This is important when you are considering relationships, as Jiffy applications have some expectations regarding the name of the referencing field. See the Entity Relations section of this documentation set for details.\n  Once you are comfortable with the entities and the fields that they will contain, it is time to create the model in the Jiffy model file format.\n  Jiffy model files are simple JSON and at the moment need to be coded up by hand. Taking a copy of one of the sample model-files is the best way to start. Short of creating a graphical model file generator, maintaining the models via direct file maintenance is the most direct and transparent way to edit them. Remember that you do not have to put your entire model in one file. Jiffy is quite happy to accept any number of model files for your project with the entities defined in any order. The generator will sort it all out.\n  Check your model files as best as possible before feeding them into Jiffy. If you get an error, don\u0026rsquo;t worry; look at the error message, then check the model-file for problems. If you can\u0026rsquo;t see anything wrong, log an issue along with an example of the model-file that is causing the problem. Usual suspects for errors are missing double-quotes on field-names or string-values, missing closing parentheses on a list, missing brace on struct or sub-struct, putting quotes on a bool value, putting quotes on an int or dec value etc.\n  Again, don\u0026rsquo;t worry too much about formal inter-entity rules in the beginning. The idea is to get something up and running quickly so you can try out the services. You can generate your application many times over without touching anything but the model-file / model-files. Generation is fast.\n  Generate a version of your application and start it up. Try it out with a tool like Postman. See the Quickstart for an overview of application generation through to application testing, or go to the formal section dealing with each of the application creation steps.\n  It is not (typically) necessary to do early development testing via https. If this is not the case for you, see the Testing with TLS section in this document set. Step-by-step instructions are given to create and install self-signed certificates that will permit you to test locally with https.\n  As you test your application, you will probably see some fields missing, some fields that you don\u0026rsquo;t care for, and maybe the need for an additional entity. Update your model files and generate the application again. Try it out. Repeat.\n  As your model becomes more refined, consider formally adding relationships. Generate, test, repeat.\n  Consider foreign-keys. Generate, test, repeat.\n  Consider start-values for id. Not everybody is okay to start at 1, particularly if you are planning on migrating existing data into your application. Generate and test.\n  Consider static-queries and add the selection options to each field that can be queried. Generate, test, repeat. See the static query section for details.\n  Consider indices and add indexes to the model definitions where needed. Generate, test, repeat.\n  Access restrictions can be assigned at the end-point-level, and this is built into the generated application. Don\u0026rsquo;t worry about testing authorization and authentication for now.\n  Development   When you are satisfied with your model, generate a version of the application and place it under source-code control.\n  Implement extension-points in the controller and model go source as per your requirements. Implemented extension-points will not be over-written should you need to regenerate the application. Test often.\n  Implement normalization and validation at the field-level in the generated entity model go source file. This part is slightly contentious, as field normalization and validation is performed directly in the generated code, rather than off to the side in extension-points. We suggest that if you are worried about over-writing your normalization and validation code with an accidental regeneration, you create a model_normalization package for each model and implement field-level normalizations and checks there. Of course, you are free to ignore the provided field-level normalization and validation methods and perform all checks in one of the model extension-points. Its up to you, and it will make more sense once you take a look through one of the generated files.\n  When you are happy with the way things are working, think about user access. Sketch out user-groups and assign end-points to them until you have something that you like. Use Postman to create UserGroups and assign Auths to them, then create new users and allocate the relevant UserGroups to their ID. That is all you need to do; the Jiffy middleware will take care of the rest. See the Access Control section for a detailed discussion of how users are authenticated and authorized.\n  Deployment Jiffy generated applications can be deployed in any number of ways. For example:\n On your laptop On a server under your desk On a blade running the os of your choice. This is not entirely true anymore, as a bash shell is now required to build the Jiffy binary. On a VM (xen etc.) Docker image / Droplet / Cloud Foundry etc. In a Kubernetes cluster Across a collection of the above  At the software level, the Jiffy generated application can be deployed as:\n A single environment hosting the DBMS and application A single application instance talking to a database Multiple application instances talking to a database  Considerations for deployment  SSL certificates - you will need them Is there a need to support JWTs from JWT-capable Identity Providers in the existing deployment landscape? If so, their public-keys must be added to the production configuration file. JWT expiration policy has been set correctly in the production configuration file? You have tested your user-access revocation? Jiffy makes provisions for the revocation of user-access based on the user master. If a user is deleted or marked as inactive, even a valid JWT for that user will not permit access. Data migration; have you run real test migrations with the key relationships etc. in place? If you disabled certain database features for migration, have you turned them back on again? Looking at you foreign-keys\u0026hellip; User access; users have been assigned to Groups and the create/update/delete end-points have been secured in accordance with the known use-cases? Is a reverse-proxy required and / or is there a need to route traffic based on expected load? Service activations; is there a need to route traffic to specific application instances based on expected load? Is there a documented strategy for scaling horizontally or vertically if required? Backup and recovery strategy is in place and has been tested?  "
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/gs-content-d/",
	"title": "Let&#39;s Run Something",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s execute our first application!\ncd $GOPATH/src/jiffy_tests/first_app go run main.go -dev -rs Executing with the -dev and -rs flags instructs our new application to initialize itself using the development configuration file, and forces a rebuild of the \u0026lsquo;Super\u0026rsquo; authorization-group. Consequently, some warning and info messages will scroll up the screen which is expected.\n2018/02/05 22:29:26 package sqac init is running 2018/02/05 22:29:26 successfully loaded the config file... 2018/02/05 22:29:26 JWTPrivKeyFile: jwtkeys/private.pem 2018/02/05 22:29:26 JWTPubKeyFile: jwtkeys/public.pem 2018/02/05 22:29:26 warning: auth usr.GET_SET not found in the db Auth master data 2018/02/05 22:29:26 warning: auth usr.CREATE not found in the db Auth master data 2018/02/05 22:29:26 warning: auth usr.GET_ID not found in the db Auth master data ... ... 2018/02/05 22:29:26 info: creating auth usr.GET_SET in the db Auth master data 2018/02/05 22:29:26 warning: new auth usr.GET_SET must be added to at least one group 2018/02/05 22:29:26 info: creating auth usr.CREATE in the db Auth master data 2018/02/05 22:29:26 warning: new auth usr.CREATE must be added to at least one group ... ... 2018/02/05 22:29:26 warning: new auth person.STATICFLTR_ByValidLicense must be added to at least one group 2018/02/05 22:29:26 info: creating auth person.STATICFLTR_CMD_ByValidLicense in the db Auth master data 2018/02/05 22:29:26 warning: new auth person.STATICFLTR_CMD_ByValidLicense must be added to at least one group 2018/02/05 22:29:26 The Super UsrGroup has been initialized with 42 Auth objects. 2018/02/05 22:29:26 re-initializing local middleware to accomodate Super group changes. 2018/02/05 22:29:27 admin user created with ID: 1 and initial password of initpass Development settings selected... Starting http server on port... 8080 If all goes well, a message indicating that the application is running will be displayed. During the startup, the application executed a number of steps:\n Loaded the development configuration file. Initialized a handle to the underlying sqac ORM. Checked for and loaded the public and private keys for JWT support. Checked for and created the user, auth, and usrgroup tables in the database. Checked for and created the person table in the database based on the \u0026lsquo;Person\u0026rsquo; model. Checked for and created authorizations in the database for each service end-point. Checked for and created the Super user-group in the database. Assigned all authorizations to the Super user-group. Created the \u0026lsquo;admin\u0026rsquo; user and assigned it to the \u0026lsquo;Super\u0026rsquo; user-group. Initialized the authorization, user, user-group and auth-groups caches in the router. Started the router. Looked at the leader-persistence store to determine the group-leader (running in standalone mode). Became the defacto group-leader, set own process-id (usually to 1 in this case). Updated the leader-persistence store with the new group-leader information. Started the inter-process failure-detector.  Congratulations! Your first application is now open for business at http://127.0.0.1:8080\nNote that subsequent starts of the application should be done without the use of the -rs flag.\ncd $GOPATH/src/jiffy_tests/first_app go run main.go -dev "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-e/",
	"title": "Generated &#39;models&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;models\u0026rsquo; Folder FirstApp  appobj   appconf.go   appobj.go |  lead_set_get.go . . .  models   authm.go   errors.go   group_authm.go   modelfuncs.go   personm_ext.go   personm.go   servicesm.go   usr_groupm.go   usrm.go   ext   model_ext_interfaces.go  util   strings.go  .dev.config.json  .prd.config.json  main_test.go  main.go A model is created for each entity that has been modeled in the my_model.json files, as well as well as the static models used to support users and authorizations.\nModels define an entity\u0026rsquo;s structure and member field characteristics such as type, required/not-required, db-type etc. Each model has a corresponding controller that examines the request, parses the incoming JSON data into the model structure, and then calls the appropriate method in the entity-model based on the end-point / http method. The model provides a validator, which can be used to perform detailed checks and normalizations on the entity data prior to making the call to the sqac ORM.\nEmpty model validations are generated for each entity field, and are designed to be extended by the application developer. Validation methods are generated for each entity field and added to the model\u0026rsquo;s entity validator. For example, the model source file for entity \u0026lsquo;Library\u0026rsquo; (./models/librarym.go), contains a \u0026lsquo;libraryValidator\u0026rsquo; type. Validation methods for each of the library entity\u0026rsquo;s fields are attached to this type.\nThe validator type also contains methods matching the public interface (LibraryDB) of the model\u0026rsquo;s service definition. The model\u0026rsquo;s service declaration includes a validator member, and due to the manner of the declaration, it is the validator that is passed back to the caller (controller) when model access is needed.\n// newLibraryValidator returns a new libraryValidator  func newLibraryValidator(ldb LibraryDB) *libraryValidator { return \u0026amp;libraryValidator{ LibraryDB: ldb, } } // NewLibraryService declaration  func NewLibraryService(handle sqac.PublicDB) LibraryService { ls := \u0026amp;librarySqac{handle} lv := newLibraryValidator(ls) // *db  return \u0026amp;libraryService{ LibraryDB: lv, } } In the NewLibraryService function, see that two members are declared:\n ls contains an implementation of the generated LibraryDB interface which is used to call the ORM layer following successful execution of the model\u0026rsquo;s validations lv contains an implementation of the generated LibraryDB interface, as well as the set of empty generated field validation methods  Using the creation of a new \u0026lsquo;Library\u0026rsquo; entity as an example, the controller will parse the JSON body of the incoming request into a \u0026lsquo;Library\u0026rsquo; entity struct. The controller will then call the entity\u0026rsquo;s model.Create method. The \u0026lsquo;libraryValidator.Create\u0026rsquo; method (on lv) will execute the implemented field validations, then call the service\u0026rsquo;s model.Create() method (on ls)which will in-turn make the required call to the ORM.\n// Create validates and normalizes data used in the library creation.  // Create then calls the creation code contained in LibraryService.  func (lv *libraryValidator) Create(library *Library) error { // perform normalization and validation -- comment out checks that are not  // required note that the check calls are generated as a straight enumeration  // of the entity structure. It may be neccessary to adjust the calling order  // depending on the relationships between the fields in the entity structure.  err := runLibraryValFuncs(library, lv.normvalName, lv.normvalCity, ) if err != nil { return err } // use method-chaining to call the library service Create method  return lv.LibraryDB.Create(library) } The last line of the method is the most interesting, as it demonstrates something known as method-chaining which allows the call to implicitly access the \u0026lsquo;ls\u0026rsquo; methods. Look carefully at the code in this area so you understand what is happening, and perhaps lookup \u0026lsquo;method-chaining\u0026rsquo; as it pertains to golang.\nNote that at the moment, validations are intended to be coded directly in the body of the generated model code even though model extension points are available. This is in contrast with the extension-point technique implemented in the controller and at the sqacService level in the model file (see Extension Points). The reasons for this are as follows:\n It is expected that no validations will be coded until the model has been stabilized. It is generally desirable to get an application working (or mostly working), then start worrying about validations. Extension points exist as a convenience in the case where data needs pre/post processing. For most entities, some sort of validation will be required on the majority of fields. We treat the validations as first-class citizens in the application rather than extension-points. By treating validations as first-class citizens we do not need to use type assertion and reflection in the validation layer when performing the checks. This is in contrast to the model extension-point interfaces. If there is a concern regarding the over-writing of coded validations due to application regeneration, it is simple for an application developer to implement their own sub-package with methods or functions containing the check code. Jiffy application generation will not overwrite files that it is not responsible for during a regeneration of an application.  By default, a CRUD interface is generated for each entity. Using the \u0026lsquo;Library\u0026rsquo; example, the generated code for the CRUD end-points look as follows:\n// ====================== Library protected routes for standard CRUD access ====================== a.router.HandleFunc(\u0026#34;/librarys\u0026#34;, requireUserMw.ApplyFn(a.libraryC.GetLibrarys)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.GET_SET\u0026#34;) a.router.HandleFunc(\u0026#34;/library\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Create)).Methods(\u0026#34;POST\u0026#34;).Name(\u0026#34;library.CREATE\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Get)).Methods(\u0026#34;GET\u0026#34;).Name(\u0026#34;library.GET_ID\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Update)).Methods(\u0026#34;PUT\u0026#34;).Name(\u0026#34;library.UPDATE\u0026#34;) a.router.HandleFunc(\u0026#34;/library/{id:[0-9]+}\u0026#34;, requireUserMw.ApplyFn(a.libraryC.Delete)).Methods(\u0026#34;DELETE\u0026#34;).Name(\u0026#34;library.DELETE\u0026#34;) The generated go struct for the \u0026lsquo;Library\u0026rsquo; model looks as follows:\n// Library structure  type Library struct { ID uint64 `json:\u0026#34;id\u0026#34; db:\u0026#34;id\u0026#34; sqac:\u0026#34;primary_key:inc\u0026#34;` Href string `json:\u0026#34;href\u0026#34; db:\u0026#34;href\u0026#34; sqac:\u0026#34;-\u0026#34;` Name string `json:\u0026#34;name\u0026#34; db:\u0026#34;name\u0026#34; sqac:\u0026#34;nullable:false;index:non-unique;index:idx_library_name_city\u0026#34;` City string `json:\u0026#34;city\u0026#34; db:\u0026#34;city\u0026#34; sqac:\u0026#34;nullable:false;index:idx_library_name_city\u0026#34;` } The model structure and tags are explained:\n   Field Name Description     ID This is the injected key for the entity. The sqac tag \u0026ldquo;primary_key:inc\u0026rdquo; instructs the ORM that this field is to be created as an auto-incrementing column in the backend DBMS.   Href Each entity has an Href field injected into its structure when the application is generated. The Href value provides a direct link to read, update or delete the represented entity. This can be useful if the entity was returned as part of a list, or via a relation-based request. Changes to entities must be carried out via the direct links rather than through relation-type requests. Enforcement of this precludes the requirement of coding / executing additional checks during updates to make sure that the relationship path is valid. Authorization for end-point access is also simplified via this model. Sqac tag \u0026ldquo;-\u0026rdquo; indicates that this field is not persisted on the database and is not included in the table schema.   Name Name is a field from the model file, and has the following attributes in the backend DBMS based on the sqac tag-values: Not nullable, has a non-unique btree index, is part of a composite (non-unique) index consisting of the \u0026lsquo;name\u0026rsquo; and \u0026lsquo;city\u0026rsquo; table columns.   City City is a field from the model file, and has the following attributes in the backend DBMS based on the sqac tag-values: Not nullable, is part of a composite (non-unique) index consisting of the \u0026lsquo;name\u0026rsquo; and \u0026lsquo;city\u0026rsquo; table columns.    For a more complete explanation of the Sqac ORM tags and operation, see the examples contained in README.md of the sqac library at: https://github.com/1414C/sqac or the sqac ORM documentation.\nThe models folder also contains an \u0026lsquo;ext\u0026rsquo; sub-directory which is used to hold the interface definitions for model extension-points if you wish to use them. See the Extension Points section of this document for more details.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-f/",
	"title": "Testing with TLS",
	"tags": [],
	"description": "",
	"content": "Generate Self-Signed Certs for https Testing If you wish to perform local https-based testing, it is possible to do so through the use of self-signed certificates. Self-signed certificates can be easily created through the use of the openssl tool on *nix systems. \nVerify the OpenSSL Installation Open a terminal session and verify that openssl is available:\nwhich -a openssl /usr/bin/openssl If openssl is not shown in the \u0026lsquo;which\u0026rsquo; command output, check your path to ensure you have access to /usr/bin or /usr/local/bin. If you have access to the ./bin directories, but still cannot find the openssl tool, it can be downloaded from https://www.openssl.org/source/ . Follow the directions on the site to correctly download and install the tool. \nGenerate a Private Certificate Authority (CA) Certificate Key Open a terminal session and execute the openssl command as shown:\nopenssl genrsa -out \u0026#34;myCA.key\u0026#34; \u0026#34;2048\u0026#34; Generating RSA private key, 2048 bit long modulus ...................................+++ ..........................................................................................+++ e is 65537 (0x10001) Verify that a file called \u0026ldquo;myCA.key\u0026rdquo; has been created. \nGenerate a Private Certificate Authority (CA) Certificate Open a terminal session and execute the openssl command as shown:\nopenssl req -x509 -new -days 365 -key \u0026#34;myCA.key\u0026#34; -out \u0026#34;myCA.cer\u0026#34; -subj \u0026#34;/CN=\\\u0026#34;\u0026#34;MyCompanyName\u0026#34;\\\u0026#34;\u0026#34; There is no output to this command, so verify that a file called \u0026ldquo;myCA.cer\u0026rdquo; has been created. \nGenerate a Private Server Key Open a terminal session and execute the openssl command as shown:\nopenssl genrsa -out \u0026#34;srvcert.key\u0026#34; \u0026#34;2048\u0026#34; Generating RSA private key, 2048 bit long modulus ..............................................................................................+++ .....+++ e is 65537 (0x10001) Verify that a file called \u0026ldquo;srvcert.key\u0026rdquo; has been created. \nCreate a Private Server Certificate Signing Request This generates an intermediate certificate signing request file (.csr) based on the Private Server Key created in the previous step. The creation of the CSR is an interrogative process, but for self-signed testing, most of the inputs can safely be ignored. Follow the prompts as per the example shown below:\nopenssl req -new -key srvcert.key -out srvcert.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]:CA State or Province Name (full name) [Some-State]:AB Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgets Ltd]:MyCompany Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []: Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Verify that a file called \u0026ldquo;srvcert.crt\u0026rdquo; has been created. \nCreate a Private Server Certificate This is the final step in getting the required certificate and key files to support local https testing. In this step, the CA certificate and private key files will be used in conjunction with the private server key and private server signing-request to generate a private server certificate. Execute the following command in your terminal session:\nopenssl x509 -req -in srvcert.csr -out srvcert.cer -CAkey myCA.key -CA myCA.cer -days 365 -CAcreateserial -CAserial 123456 Signature ok subject=/C=CA/ST=AB/O=MyCompany Getting CA Private Key Verify that a file called \u0026ldquo;srvcert.cer\u0026rdquo; has been created. \nEnsure myCA.cer is Trusted Locally Ensure that myCA.cer is fully-trusted in your local certificate store. The process to do this will differ per operating system, so look online for instructions regarding \u0026lsquo;trusting a self-signed CA certificate\u0026rsquo;. You may also need to adjust the settings in test tools like Postman in order for them to accept self-signed certs.\nAdd Certificates to the Configuration File In order to publish the generated services over https, add the \u0026ldquo;srvcert.cer\u0026rdquo; and \u0026ldquo;svrcert.key\u0026rdquo; files to the \u0026lsquo;cert_file\u0026rsquo; and \u0026lsquo;key_file\u0026rsquo; keys respectively in the appropriate configuration file. Additionally, the myCA.key file must be placed in the same directory as the \u0026ldquo;srvcert.*\u0026rdquo; files in order for go\u0026rsquo;s https (TLS) server to operate correctly.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/",
	"title": "Let&#39;s Test Something",
	"tags": [],
	"description": "",
	"content": "We have a running application, but what can we do with it? Clicking on the http://127.0.0.1:8080 link at the end of the preceding section, did not yield a good looking response\u0026hellip;\nJiffy services are best tested using an API test utility. If you have a tool that works for you, use that to follow along. If you don\u0026rsquo;t have a test utility, Google\u0026rsquo;s Postman is a great choice and that is what we are going to use for the rest of the quick-start.\nLet\u0026rsquo;s make a quick list of things that we are going to do in order to test our new Person service.\n Login Create a new \u0026lsquo;Person\u0026rsquo; entity Create another new \u0026lsquo;Person\u0026rsquo; entity Read each \u0026lsquo;Person\u0026rsquo; by their key (id) Read a list of \u0026lsquo;Person\u0026rsquo; entities Update a \u0026lsquo;Person\u0026rsquo; entity Create yet another new \u0026lsquo;Person\u0026rsquo; entity See what options we can add to an entity request Delete an entity  "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-f/",
	"title": "Generated &#39;middleware&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;middleware\u0026rsquo; Folder FirstApp  appobj   ...   ... |  ... . . .  middleware   requireuser.go . . .  .dev.config.json  .prd.config.json  main_test.go  main.go The middleware folder contains all of the code related to the Authentication and Authorization concepts discussed in the Access Control Overview and Authorizations sections of this document.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-g/",
	"title": "Automated Application Testing",
	"tags": [],
	"description": "",
	"content": "Automated Testing When jiffy generates the application, a set of automated tests are also generated for the application\u0026rsquo;s end-points. The tests make use of the standard go test tooling. Tests can be conducted using http or https, and run against the address:port that the application is presently serving on. Remember, the application must be running prior to executing the test.\nThe generated tests check the availability of the end-points and attempt to perform CRUD activities using representative data for the field-types. If customization has occurred in the model normalization and validation enhancement points, the field values used in the generated main_test.go file should be updated accordingly. The generated CRUD tests are provided as a starting point for your own testing.\nThe generated simple selector tests check the availability of the end-points, and attempt to perform a GET for each of the selection operators specified in the Entity-\u0026gt;selectable field in the models.json file. It is not necessary to have values populated in the database in order for the simple selector tests to run.\nAt the moment, relationships are not included in the generated tests, and the test case generator needs to be updated to consider foreign-key relationships. For this reason, it is recommended to perform baseline model testing without foreign-keys in the model-files.\nRun go test With https In order to conduct automated testing via a TLS connection, follow the instructions in the Testing with TLS section of this documentation to generate and install self-signed certificates. Next, open a terminal window and run go test as shown below:\ngo test -v -https -address \u0026#34;192.168.1.66:8080\u0026#34; 2018/06/05 17:50:17 package sqac init is running using usr: {\u0026#34;email\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;initpass\u0026#34;} === RUN TestCreatePerson --- PASS: TestCreatePerson (0.03s) === RUN TestGetPersons --- PASS: TestGetPersons (0.03s) === RUN TestGetPerson --- PASS: TestGetPerson (0.01s) === RUN TestUpdatePerson --- PASS: TestUpdatePerson (0.04s) === RUN TestDeletePerson --- PASS: TestDeletePerson (0.01s) === RUN TestGetPersonsByName --- PASS: TestGetPersonsByName (0.05s) === RUN TestGetPersonsByAge --- PASS: TestGetPersonsByAge (0.09s) === RUN TestGetPersonsByWeight --- PASS: TestGetPersonsByWeight (0.11s) === RUN TestGetPersonsByValidLicense --- PASS: TestGetPersonsByValidLicense (0.10s) PASS ok exp/csrest4 1.495s Run go test Without https go test -v -address \u0026#34;192.168.1.66:8080\u0026#34; 2018/06/05 17:50:17 package sqac init is running using usr: {\u0026#34;email\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;initpass\u0026#34;} === RUN TestCreatePerson --- PASS: TestCreatePerson (0.03s) === RUN TestGetPersons --- PASS: TestGetPersons (0.03s) === RUN TestGetPerson --- PASS: TestGetPerson (0.01s) === RUN TestUpdatePerson --- PASS: TestUpdatePerson (0.04s) === RUN TestDeletePerson --- PASS: TestDeletePerson (0.01s) === RUN TestGetPersonsByName --- PASS: TestGetPersonsByName (0.05s) === RUN TestGetPersonsByAge --- PASS: TestGetPersonsByAge (0.09s) === RUN TestGetPersonsByWeight --- PASS: TestGetPersonsByWeight (0.11s) === RUN TestGetPersonsByValidLicense --- PASS: TestGetPersonsByValidLicense (0.10s) PASS ok exp/csrest4 1.495s "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-g/",
	"title": "Generated &#39;jwtkeys&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;jwtkeys\u0026rsquo; Folder FirstApp  appobj   ...   ...   ... . . .  jwtkeys   ecdsa256    ecdsa.priv.pem    ecdsa.pub.pem   ecdsa384    ecdsa384.prive.pem    ecdsa384.pub.pem   ecdsa521    ecdsa521.priv.pem    ecdsa521.pub.pem   rsa256    rsa.priv.pem    rsa.pub.pem   rsa384    rsa384.prive.pem    rsa384.pub.pem   rsa512   rsa512.priv.pem   rsa512.pub.pem . . .  .dev.config.json  .prd.config.json  main_test.go  main.go The jwtkeys folder contains the public and private keys that are generated in order to support the use of JWT tokens. Jiffy generates public/private keys for all supported JWT signing algorithms. It would probably be okay to place the keys into a common location, as they are only read once by each application instance during its initialization. JWT\u0026rsquo;s and key usage are discussed in greater detail in the \u0026lsquo;Authorizations \u0026amp; End-Point Security\u0026rsquo; section of this documentation.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/us-content-h/",
	"title": "Key Value Store Support",
	"tags": [],
	"description": "",
	"content": "Overview A KVS is required in order to persist the current group-leader information in multi-instance jiffy-application deployments. This is discussed in the Joining Overview section of the Interprocess Communication documentation. Although we refer to the persistent store as a KVS, anything that manages access and allows read/write operations can be used.\nJiffy applications support the use of Redis, Memcached, Stand-Alone/Local or Sluggo KVS systems out of the box. The active group-leadership KVS can be configured in the .xxx.config.json file by making appropriate settings in the \u0026ldquo;group_leader_kvs\u0026rdquo; key. As shown in the json excerpt below, the default config.json files are generated with the \u0026lsquo;local_standalone\u0026rsquo; group-leader KVS active. In this mode, a single instance of the application may be tested without worrying about the group-leadership setup.\n\u0026#34;group_leader_kvs\u0026#34;: { \u0026#34;local_standalone\u0026#34;: { \u0026#34;active\u0026#34;: true, \u0026#34;internal_address\u0026#34;: \u0026#34;127.0.0.1:4444\u0026#34; }, \u0026#34;redis\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;max_idle\u0026#34;: 80, \u0026#34;max_active\u0026#34;: 12000, \u0026#34;redis_protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;redis_address\u0026#34;: \u0026#34;127.0.0.1:6379\u0026#34; }, \u0026#34;memcached\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;memcached_addresses\u0026#34;: [ \u0026#34;192.168.112.50:11211\u0026#34; ] }, \u0026#34;sluggo\u0026#34;: { \u0026#34;active\u0026#34;: false, \u0026#34;sluggo_address\u0026#34;: \u0026#34;127.0.0.1:7070\u0026#34; } } If you wish to test a multi-application server deployment but do not want to install redis or memcached, the application supports a simple KVS called sluggo that was written as a lightweight-non-productive KVS testing solution. For now, the docs will refer to sluggo when discussing the KVS, but it recommended to use something more robust for real deployments.\nSluggo may be installed in your environment the following go get command:\ngo get -u github.com/1414C/sluggo Sluggo may be run from a terminal session via the following command:\ngo run main.go -a 192.168.1.40:7070 If none of the supported KVS solutions are appealing, support can be added for the desired KVS via the implementation of interface gmcom.GMSetterGetter{} in appobj/lead_set_get.go.\nExample gmcom.GetterSetter Implementation Interface gmcom.GMGetterSetter Interface gmcom.GMGetterSetter contains methods to facilitate read/write access to the persisted leader record in any key-value-store. Applications implementing the interface may choose to store the persisted current leader in any number of mediums; flat-file, db table record, redis, memcached etc.\n Interface gmcom.GMGetterSetter   GetDBLeader() (*GMLeader, error) GetDBLeader is provided in order to allow the implementer to retrieve the current group-leader information from the persistent store. The implementation of this method is intended to be self-contained. For example, if the implementation calls for the current leader information to be persisted in redis, the implementer should code a self-contained method to connect to redis, retrieve the leader information and return it in the GMLeader pointer. Failure to read a current leader from the persistent store should result in the return of a nil in place of the *GMLeader pointer and a non-nil error value.    SetDBLeader(l GMLeader) error SetDBLeader is provided in order to allow the implementer to persist a newly elected leader's information in the persistent store. The implementation of this method is intended to be self-contained. For example, if the implementation calls for the current leader information to be persisted in redis, the implementer should code a self-contained method to connect to redis and store the leader information provided by input parameter *l*. Failure to persist the provided leader information should result in the implementer returning a non-nil value in the *error* return parameter.    Cleanup() error Cleanup is provided in order to allow the implementer to cleanup connection pools, open and/or busy connections before the hosting application shuts down in response to a SIGKILL, os.Interrupt or SIGINT event. If the implementation does not require any cleanup, this method can be implemented to simply return nil.    Interface gmcom.GMSetterGetter Sample Implementation // LeadSetGet provides a sample implementation of the GMLeaderSetterGetter // interface in order to support persistence of the current group-leader // information. re-implement these methods as you see fit to facilitate // storage and retrieval of the leader information to and from the persistent // storage. This example uses a quick and dirty web-socket-based cache to // handle the persistence. It works well enough for testing, but you should // use something more robust like a database, redis etc. The methods in the // GMLeaderSetterGetter interface are called when a new process is attempting // to join the group and also when a new leader is selected via the coordinator // process. // // To test with the delivered interface implementation, install and run sluggo: // go get -u github.com/1414C/sluggo // // Execute sluggo from the command-line as follows: // go run main.go -a \u0026lt;ipaddress:port\u0026gt; // For example: // $ go run main.go -a 192.168.1.40:7070 // type LeadSetGet struct { gmcom.GMLeaderSetterGetter } // GetDBLeader retrieves the current leader information from // the persistence layer. func (sg *LeadSetGet) GetDBLeader() (*gmcom.GMLeader, error) { // access the database here to read the current leader  l := \u0026amp;gmcom.GMLeader{} wscl.GetCacheEntry(\u0026#34;LEADER\u0026#34;, l, \u0026#34;192.168.1.40:7070\u0026#34;) return l, nil } // SetDBLeader stores the current leader information in the // persistence layer. func (sg *LeadSetGet) SetDBLeader(l gmcom.GMLeader) error { // access the database here to set a new current leader  wscl.AddUpdCacheEntry(\u0026#34;LEADER\u0026#34;, \u0026amp;l, \u0026#34;192.168.1.40:7070\u0026#34;) return nil } // Cleanup closes connections to group-leadership KVS when // prior to application shutdown. func (sg *LeadSetGet) Cleanup() error { // perform cleanup(s)  return nil } "
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-h/",
	"title": "Generated &#39;docker&#39; Folder",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;docker\u0026rsquo; Folder FirstApp  appobj   ...   ...   ... . . .  docker   .dev.config.json   .dev.config.json   .dev.config.json   Dockerfile . . .  .dev.config.json  .prd.config.json  main_test.go  main.go The docker folder contains files that can be used as a starting point for containerizing generated jiffy applications. The Using Docker with Jiffy Applications tutorials make use of these files. The files in the docker folder are provided as a learning aid, not as an example of how to deploy applications with Docker.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/deployment/",
	"title": "Deployment Overview",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://1414c.github.io/jiffy/generation/gn-content-j/",
	"title": "Other Generated Folders",
	"tags": [],
	"description": "",
	"content": "The \u0026lsquo;ext\u0026rsquo; Folders \u0026lsquo;ext\u0026rsquo; folders contain Jiffy application interface definitions and empty implementations of the same for controller and model extension-points. See the Extension Points section of this documentation.\nThe group/gmcl Folder The group/gmcl folder contains the source files for the usr, auth, usrgroup and groupauth cache clients. This package is for internal use only. See the Group Membership Overview and Failure Detector sections of this documentation.\nThe group/gmcom Folder The group/gmcom folder contains source files holding artifacts that are needed by the groups/\u0026hellip; packages and those of the generated jiffy application. This package is for internal use only. See the Group Membership Overview and Failure Detector sections of this documentation.\nThe group/gmsrv Folder The group/gmsrv folder contains the source files for the group-membership service, the failure detector and the leader-election mechanism. This package is for internal use only. See the Group Membership Overview and Failure Detector sections of this documentation.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/deployment/us-content-i/",
	"title": "Deployment Requirements",
	"tags": [],
	"description": "",
	"content": "Overview Jiffy was written with the idea of generating sidecar-free backend service applications. While this is a nice goal, the current version of Jiffy relies on the presence of some external processes and/or services depending on the target environment.\nDatabase System The generated application will need to connect to a database system from the supported list. It is easiest to use sqlite3 for initial testing if you do not want to install a full DBMS in the development environment. Connectivity to the database can be checked by running the test suite in the github.com/1414C/sqac repository. The sqac repository will be pulled into the Go environment when the Jiffy source code is installed via go get -u. See the README.md file in the sqac repository for instructions.\nKey Value Store A KVS is required in order to persist the current group-leader information. This is discussed in the Key Value Store Support section of this documentation. Deployment-specific considerations are outlined for each of the deployment scenarios.\nLoad Balancer Jiffy applications are designed to scale horizontally by starting more application server instances (processes). The applications do not handle load balancing however, and in a bare metal or VM-type deployment it is recommended to use something like NGinx to direct traffic.\nSample Deployment Scenarios This section of the documentation contains sample high-level deployment scenarios for a jiffy-generated application. The examples should be considered as general guidance rather than production-deployment-cookbooks. Infrastructure security is not discussed in any depth, but the usual precautions apply when deploying a Jiffy-application productively.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-a/",
	"title": "Login",
	"tags": [],
	"description": "",
	"content": "Launch Postman and specify a target URL of: http://127.0.0.1:8080/usr/login making sure to select the http POST method. Maintain the request body to provide a user-id and password as shown in the following JSON snippet. Typically the user-id for a Jiffy application is an email address, but we make an exception for the default administration user.\n{ \u0026#34;email\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;initpass\u0026#34; }  When you have finished and your Postman (or other test utility) looks like the following image, click the \u0026lsquo;Send\u0026rsquo; button to post your login request to the running application.  If all goes well, you will get a http response code of 200 (status ok), and a block of JSON with a single \u0026lsquo;token\u0026rsquo; tag containing a jumble of letters and numbers. This is the JSON Web Token (JWT) that will be used to validate our authorization to access the Person entity\u0026rsquo;s service end-points. If you want to read more about JWTs, jwt.io is a good place to start, or you can refer to the Access Control section of this document set. "
},
{
	"uri": "https://1414c.github.io/jiffy/usage/deployment/us-content-j/",
	"title": "Deployment on Bare Metal / VM&#39;s",
	"tags": [],
	"description": "",
	"content": "\n\nDeployment Overview See the Deployment Overview chapter for a brief outline of jiffy-application deployment artifacts \nAll-In-One Deployment In a development or test setting it may make sense to deploy everything in one system. In this context \u0026lsquo;system\u0026rsquo; refers to a laptop, bare-metal server or a VM of some sort. To deploy an all-in-one type setup, the following artifacts are required:\n Database Jiffy application Set the \u0026lsquo;local_standalone\u0026rsquo; KVS to Active in the config.json file  The All-In-One Deployment diagram shows a jiffy-application instance running on a system with an ip-address of 192.168.1.5. The application instance is accepting http client connections on port :8080 and using port :7070 to listen for failure-detector \u0026amp; cache synchronization messages. The failure detector \u0026lsquo;bus\u0026rsquo; is used for group-leadership and inter-process cache messages, even when the application is run standalone (single process).\nIt is not necessary to run an external KVS if the jiffy-application will be run as a standalone process. The KVS is used to hold the current group-leader information when jiffy applications are deployed with more than one instance. When running without a KVS, set the \u0026lsquo;local_standalone\u0026rsquo; KVS to active in the xxx.config.json file. The application instance will assign itself a PID of 1 and assert leadership inside it\u0026rsquo;s own process. The short version is: don\u0026rsquo;t worry about the KVS if you want to run a single instance of your jiffy application.\nIf you do choose to run an All-In-One / single application instance with a KVS, using sluggo / setting the \u0026lsquo;sluggo\u0026rsquo; KVS to active in the xxx.config.json file is the easiest way to get started. You may also choose to use Redis, Memcached or create your own implementation of the gmcom.GetterSetter interface to support another KVS.\nThe application communicates with the KVS using whatever protocol/transport is required. Remember that the selection of KVS is arbitrary and an interface is provided to allow the implementer to write their own code to communicate with any KVS.\nThe application is also shown to be accessing the locally installed database over a tcp connection. In this example we show PostgreSQL accepting connections on it\u0026rsquo;s default port (tcp/5432), but any of the supported databases can be used. \nSingle-Instance Deployment Single instance deployments contain one jiffy-application instance, an optional KVS and a database. In this scenario the database is running on a separate system and is available over the local network. Ip-addresses are shown for illustrative purposes only.\n Database running on a separate host Jiffy application Optional Key-Value-Store  The Single-Instance Deployment diagram shows a jiffy-application instance running on a system with an ip-address of 192.168.1.5. The application instance is accepting http client connections on port :8080, using port :7070 to listen for failure-detector \u0026amp; cache synchronization messages. The failure detector \u0026lsquo;bus\u0026rsquo; is used for group-leadership and inter-process cache messages, even when the application is run standalone (single process).\nIt is not necessary to run an external KVS if the jiffy-application will be run as a standalone process. The KVS is used to hold the current group-leader information when jiffy applications are deployed with more than one instance. When running without a KVS, set the \u0026lsquo;local_standalone\u0026rsquo; KVS to active in the xxx.config.json file. The application instance will assign itself a PID of 1 and assert leadership inside it\u0026rsquo;s own process. The short version is: don\u0026rsquo;t worry about the KVS if you want to run a single instance of your jiffy application.\nIf you do choose to run an All-In-One / single application instance with a KVS, using sluggo / setting the \u0026lsquo;sluggo\u0026rsquo; KVS to active in the xxx.config.json file is the easiest way to get started. You may also choose to use Redis, Memcached or create your own implementation of the gmcom.GetterSetter interface to support another KVS.\nThe application communicates with the KVS using whatever protocol/transport is required. Remember that the selection of KVS is arbitrary and an interface is provided to allow the implementer to write their own code to communicate with any KVS.\nThe application is also shown to be accessing a Postgres database via tcp @192.168.1.31:5432. In this example we show PostgreSQL accepting connections on it\u0026rsquo;s default port (tcp/5432), but any of the supported databases can be used. \nMulti-Instance Deployment Multi-instance deployments contain more than one jiffy-application instance, a KVS and a database. In this scenario the database is running on a separate system and is available over the local network and jiffy-application instances are running in parallel on multiple hosts. In this arrangement the KVS is not optional, as the group-leadership sub-system requires it in order to persist the group-leader information.\n Database running on a separate host Jiffy application instances running on separate hosts/VM\u0026rsquo;s Key-Value-Store  The Multi-Instance Deployment diagram shows a number of jiffy-application instances running on individual hosts. Each application instance is accepting http client connections on port :8080 and using port :7070 to listen for failure-detector \u0026amp; cache synchronization messages. The failure detector \u0026lsquo;bus\u0026rsquo; is used for group-leadership and inter-process cache messages. Each application instance is shown making a web-socket connection to its peers on ws:7070.\nThe KVS is used to hold the current group-leader information when jiffy applications are deployed with more than one instance. See the Interprocess Communication section for details regarding the use of the KVS with group-membership and group-leader election.\nRunning sluggo and making use of the default gmcom.GetterSetter implementation is the easiest way to get started. You may also choose to use Redis, Memcached or create your own implementation of the gmcom.GetterSetter interface to support another KVS.\nThe application communicates with the KVS using whatever protocol/transport is required. Remember that the selection of KVS is arbitrary and an interface is provided to allow the implementer to write their own code to communicate with any KVS.\nApplication instances are shown to be accessing a Postgres database via tcp @192.168.1.31:5432. In this example we show PostgreSQL accepting connections on it\u0026rsquo;s default port (tcp/5432), but any of the supported databases can be used.\nWhen running multiple jiffy-application instances a load-balancer of some sort should be used to route traffic based on end-point, system-load or other locally important criteria.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-b/",
	"title": "Create a Person",
	"tags": [],
	"description": "",
	"content": "Now that we have successfully logged into the application and received our first JWT, it is time to create a new \u0026lsquo;Person\u0026rsquo; entity. Start by copying the content of the \u0026lsquo;token\u0026rsquo; tag from the login response body to the clipboard. This JWT must henceforth be included in the http header of every subsequent request.\nCreate a new tab in Postman and specify a target URL of http://127.0.0.1:8080/person with the http POST method. Next, add the following key-value pairs to the http header:\n Content-Type : application\\json Authorization : Bearer *paste-your-JWT-here*  When you have finished maintaining the http header-values, click on \u0026lsquo;Body\u0026rsquo; and maintain it using the \u0026lsquo;raw\u0026rsquo; setting. This will allow you to paste the following JSON code snippet into the request\u0026rsquo;s body:\n{ \u0026#34;name\u0026#34;: \u0026#34;Steve Dallas\u0026#34;, \u0026#34;age\u0026#34;: 46, \u0026#34;weight\u0026#34;: 185, \u0026#34;valid_license\u0026#34;: true, \u0026#34;license_class\u0026#34;: \u0026#34;A\u0026#34; }  When you have finished, the test session should look as follows and it is time to create our first \u0026lsquo;Person\u0026rsquo; entity. Click \u0026lsquo;Send\u0026rsquo; to post the new entity to the application.\n\nCongratulations! You have created your first \u0026lsquo;Person\u0026rsquo; entity!\nWhat Just Happened? The router matched the request URL to a route (service end-point), the middleware layer in the matched route examined the JWT, verified it was okay to proceed and then passed the raw JSON from the request body to the \u0026lsquo;Person\u0026rsquo; entity\u0026rsquo;s controller. The controller unmarshalled the JSON into a \u0026lsquo;Person\u0026rsquo; struct and then passed the result to the Create method in the model/validation layer. Validation of the \u0026lsquo;Person\u0026rsquo; struct\u0026rsquo;s content occurred, and then a call was made to the underlying sqac ORM to create the entity on the database.\nThe sqac ORM-layer returned the new entity to the application\u0026rsquo;s model-layer, where it was checked and passed back to the controller layer, whereupon it was marshaled (struct content becomes JSON) and written to the the response-writer.\nThis is a high-level view of what transpired, but the general flow of things is accurate.\nNotice that the entity passed back to us seems to have a couple of extra fields? All entities created via a Jiffy model file are injected with a primary-key of \u0026lsquo;id\u0026rsquo; as well as a non-persistent \u0026lsquo;href\u0026rsquo; field. In this example, our entity\u0026rsquo;s \u0026lsquo;id\u0026rsquo; field was specified in the model file to be auto-incrementing with a starting value of 10000000. \u0026lsquo;href\u0026rsquo; is included in each entity\u0026rsquo;s GET responses, and acts as a self-reference providing the entity\u0026rsquo;s direct access URI to the consumer.\nSee the Annotated Simple Single Entity Model in the Model Maintenance section for details regarding key options.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/deployment/us-content-k/",
	"title": "Deployment with Containers",
	"tags": [],
	"description": "",
	"content": "\n\nDeployment Overview See the Deployment Overview chapter for a brief outline of jiffy-application deployment artifacts \nAll-In-One Deployment with Docker In a development or test setting it may make sense to deploy everything in one container. SQLite is a good choice for this type of container deployment, as it is a file-based database and therefore does not need to be started as a service. Containers typically offer single services and their configuration is geared to this usage pattern. While it is possible to run Postgres, a KVS and a jiffy-application in the same container, it is an atypical scenario and a little cumbersome to setup. By using SQLite and dispensing with the KVS we only need to run the jiffy-application in the container.\nThe docker build command can be used in conjunction with a Dockerfile to generate a new Docker image complete with the application, SQLite library and sparse Alpine Linux install. docker build also assigns an ipv4 address to the container image by default. This ip-address needs to be added to the application\u0026rsquo;s configuration file via the execution of a custom script during the image build.\nSee the Jiffy with Docker and SQLite tutorial for an example of an end-to-end all-in-one Jiffy application deployment with Docker and SQLite.\nThe new Docker image can then be used to create a container which the Docker daemon will then manage and run.\nSee the sample tutorial referenced above for the Dockerfile, application configuration file and scripting required to support this type of deployment.\n\n\nSingle-Instance Deployment with Docker Single instance deployments contain one jiffy-application instance, an optional KVS and a database. In this example scenario the jiffy application is deployed in a Docker container, the database is running on a separate host and the stand-alone/local KVS is used. Ip-addresses are shown for illustrative purposes only and it is implied that Docker\u0026rsquo;s default bridge network is used. See the All-In-One Deployment with Docker section for a brief overview of the Docker containerization of a jiffy application.\nThe docker build command can be used in conjunction with a Dockerfile to generate a new Docker image containing the application and a sparse Alpine Linux install. docker build also assigns a static ipv4 address to the container image by default. This ip-address needs to be added to the application\u0026rsquo;s configuration file via the execution of a custom script during the image build.\nSee the Jiffy with Docker and External PostgreSQL tutorial for an example of an end-to-end deployment of a single jiffy application container talking to a PostgreSQL database on the host\u0026rsquo;s network.\nThe Single-Instance Deployment diagram shows a jiffy-application instance running in a container with an ipv4 address of 172.17.0.2. The container is using docker\u0026rsquo;s default bridge network, as evidenced by the first two numbers of the ip-address. The application instance is accepting http client connections on port :8080 and using port :7070 to listen for failure-detector \u0026amp; cache synchronization messages. The failure detector \u0026lsquo;bus\u0026rsquo; is used for group-leadership and inter-process cache messages, even when the application is run standalone (single process).\nIt is not necessary to run an external KVS if only one container/jiffy-application instance will be run. When running without a KVS, set the \u0026lsquo;local_standalone\u0026rsquo; KVS to active in the xxx.config.json file. The application instance will assign itself a PID of 1 and assert leadership inside it\u0026rsquo;s own process. The short version is: don\u0026rsquo;t worry about the KVS if you want to run a single instance of your jiffy application.\nIf you do choose to run an All-In-One / single application instance with a KVS, using sluggo / setting the \u0026lsquo;sluggo\u0026rsquo; KVS to active in the xxx.config.json file is the easiest way to get started. You may also choose to use Redis, Memcached or create your own implementation of the gmcom.GetterSetter interface to support another KVS.\nThe application communicates with the KVS using whatever protocol/transport is required. Remember that the selection of KVS is arbitrary and an interface is provided to allow the implementer to write their own code to communicate with any KVS.\nThe application is also shown to be accessing a Postgres database on the host\u0026rsquo;s network via tcp @192.168.1.31:5432. In this example we show PostgreSQL accepting connections on it\u0026rsquo;s default port (tcp/5432), but any of the supported databases can be used. \nMulti-Instance Deployment with Docker Multi-instance deployments refer to non-swarm Docker deployments of \u0026gt;1 jiffy-application containers, a KVS and a database. In this scenario the database and KVS are running on separate systems on the host network. When deploying more than one instance of a jiffy-application the KVS is not optional, as the group-leadership sub-system requires it in order to globally persist the group-leader information. It would be possible to run the KVS and the database in Docker containers as well, but we will start by only running instances of the containerized jiffy-application in Docker.\nThe Multi-Instance Deployment diagram shows two instances of a containerized jiffy application running in Docker. Each application instance is accepting http client connections on port :8080 and using port :7070 to listen for failure-detector \u0026amp; cache synchronization messages. The failure detector \u0026lsquo;bus\u0026rsquo; is used for group-leadership and inter-process cache messages.\nThe KVS is used to hold the current group-leader information when jiffy applications are deployed with more than one instance. See the Interprocess Communication section for details regarding the use of the KVS with group-membership and group-leader election.\nRunning sluggo is the easiest way to get started with a KVS for jiffy. You may also choose to use an existing Redis or Memcached system or cluster.\nThe application communicates with the KVS using whatever protocol/transport is required. The diagram shows a web-socket connection from the containerized jiffy application to the KVS on port :4444, as this is how sluggo communicates. Remember that the selection of KVS is arbitrary and an interface is provided to allow the implementer to write their own code to communicate with any KVS.\nApplication instances are shown to be accessing a Postgres database on the host network via tcp @192.168.1.59:5432. In this example we show PostgreSQL accepting connections on it\u0026rsquo;s default port (tcp/5432), but any of the supported databases can be used.\nWhen running multiple jiffy-application instances a load-balancer of some sort should be used to route traffic based on end-point, system-load or other locally important criteria.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-c/",
	"title": "Create Another Person",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s change a few things in our request-body and create another \u0026lsquo;Person\u0026rsquo; entity. Edit the JSON body in the request section of your Postman session and click \u0026lsquo;Send\u0026rsquo; when you are ready.\n\nAnother \u0026lsquo;Person\u0026rsquo; entity has been created.\n\nCreate one more \u0026lsquo;Person\u0026rsquo; entity so we have three (or more) in total.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/usage/deployment/us-content-l/",
	"title": "Deployment on Kubernetes",
	"tags": [],
	"description": "",
	"content": "\n\nDeployment Overview See the Deployment Overview chapter for a brief outline of jiffy-application deployment artifacts. \nDeployment on Kubernetes Jiffy applications are designed to run on Kubernetes and fully support the idea of disposable application containers and automated scale-up / scale-down. The best way to learn about deploying Jiffy applications in a Kubernetes cluster is to read through the Jiffy with Kubernetes tutorial.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-d/",
	"title": "Get Some Persons",
	"tags": [],
	"description": "",
	"content": "So far we have created a few \u0026lsquo;Person\u0026rsquo; entities. We have observed that upon successful creation of an entity, a JSON representation of that entity is passed back to us via the response-writer. Let\u0026rsquo;s now look at how we can get a list of all of our \u0026lsquo;Person\u0026rsquo; entities.\nCreate a new tab in Postman and specify a target URL of http://127.0.0.1:8080/persons making sure to select the http GET method. Next, add the following key-value pair to the http header:\n Authorization : Bearer *paste-your-JWT-here*  When you have finished, the test session should look as follows and it is time to read some \u0026lsquo;Person\u0026rsquo; entities from the database. Click \u0026lsquo;Send\u0026rsquo; to issue the read request to the application.\n\nWe just read the complete list of \u0026lsquo;Person\u0026rsquo; entities. Adding an \u0026lsquo;s\u0026rsquo; to the entity name and issuing the request with a GET http verb tells a jiffy application to read all of the \u0026lsquo;Person\u0026rsquo; entities. In some cases (like this one), the pluralization of the entity name via the addition of an \u0026lsquo;s\u0026rsquo; looks odd, but it makes it quite easy to consume the services. Notice that the \u0026lsquo;href\u0026rsquo; field of each \u0026lsquo;Person\u0026rsquo; entity provides a direct link to the entity that it is a part of.\n\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-e/",
	"title": "Get a Person",
	"tags": [],
	"description": "",
	"content": "What if we need to read a single \u0026lsquo;Person\u0026rsquo;, or isolate a \u0026lsquo;Person\u0026rsquo; entity from a list of entities? Let\u0026rsquo;s try reading a \u0026lsquo;Person\u0026rsquo; entity using its \u0026lsquo;id\u0026rsquo; key.\nCreate a new tab in Postman and specify a target URL of http://127.0.0.1:8080/person/10000001 making sure to select the http GET method. Next, add the following key-value pair to the http header:\n Authorization : Bearer *paste-your-JWT-here*  When you have finished, the test session should look as follows and it is time to read \u0026lsquo;Person\u0026rsquo; 10000001 from the database. Click \u0026lsquo;Send\u0026rsquo; to issue our read request to the application.\n\nWe just read the \u0026lsquo;Person\u0026rsquo; entity with \u0026lsquo;id\u0026rsquo; key 10000001. While this is not a very human-friendly way to search for a person, it is a simple way to programmatically isolate and reference an entity for reading, updating or deletion. Fortunately there are better ways for a human to search for a Person of interest - as we will see later.\n\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-f/",
	"title": "Update a Person",
	"tags": [],
	"description": "",
	"content": "If you have been following along, we have created \u0026lsquo;Person\u0026rsquo; entities, read \u0026lsquo;Person\u0026rsquo; entities both in bulk and by \u0026lsquo;id\u0026rsquo; key. We are now going to take a look at updating an existing \u0026lsquo;Person\u0026rsquo; entity.\nRead \u0026lsquo;Person\u0026rsquo; entity 10000001 from the database as shown in the Get a Person example.\nOnce you have successfully read \u0026lsquo;Person\u0026rsquo; entity 10000001 into your Postman session, copy the content of the response body to your clipboard. Next, create a new tab in Postman and paste the content of the GET response into the new request\u0026rsquo;s body. Set the new request\u0026rsquo;s target URL to http://127.0.0.1:8080/person/10000001 and ensure that the http verb is set to PUT. Next, add the following key-value pair to the http header:\n Content-Type : application\\json  Now edit the new request\u0026rsquo;s JSON body so that Opus\u0026rsquo;s full name is given along with an accurate weight and driving ability. Strictly speaking, you do not need to include the \u0026lsquo;id\u0026rsquo; or \u0026lsquo;href\u0026rsquo; fields in an update, but it does not hurt to do so as the application runtime will ignore them in the case of an update operation. Remember that the key (id) of the \u0026lsquo;Person\u0026rsquo; entity we are updating is specified in the update request\u0026rsquo;s URL.\n{ \u0026#34;id\u0026#34;: 10000001, \u0026#34;href\u0026#34;: \u0026#34;http://127.0.0.1:8080/person/10000001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Opus the Penguin\u0026#34;, \u0026#34;age\u0026#34;: 8, \u0026#34;weight\u0026#34;: 385, \u0026#34;valid_license\u0026#34;: false } When you have finished, you should have something that looks as follows. Click \u0026lsquo;Send\u0026rsquo; to issue the PUT request to the application. The PUT request should update the entity using the \u0026lsquo;id\u0026rsquo; key as its update criteria, and then return a JSON representation of the updated entity. This is a little different than standard PUT/MERGE approaches, where the result of an update is measured simply by the http response code. If you don\u0026rsquo;t like the way the application handles update operations, it is very easy to update the generated source code to omit the response body following a PUT.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-g/",
	"title": "Get Persons With Restrictions",
	"tags": [],
	"description": "",
	"content": "We have seen how to Create, Get, and Update a \u0026lsquo;Person\u0026rsquo; entity, but before we get around to the Delete operation, let\u0026rsquo;s take a quick look at some other simple things we can do with Get entity lists.\nEach of the following bullet points can be expanded to show various ways that entities can be read, sorted and counted via a standardized set of URL suffixes. Remember to include the JWT and correct http verb in your requests when testing these operations in your test environment.\n  Get a count of \u0026#39;Person\u0026#39; entities in the database   http://127.0.0.1:8080/persons/$count .\n    Get all \u0026#39;Person\u0026#39; entities in the database ordered-by age   http://127.0.0.1:8080/persons$orderby=age .\n    Get all \u0026#39;Person\u0026#39; entities in the database ordered-by age descending   http://127.0.0.1:8080/persons$orderby=age$desc .\n    Get all \u0026#39;Person\u0026#39; entities in the database ordered-by age descending with a selection offset of 1   http://127.0.0.1:8080/persons/$orderby=age$desc$offset=1 .\n    Get all \u0026#39;Person\u0026#39; entities in the database ordered-by age descending with a limit of 2   http://127.0.0.1:8080/persons/$orderby=age$desc$limit=2 .\n    Get all \u0026#39;Person\u0026#39; entities in the database with name like %qui%   http://127.0.0.1:8080/persons/name(LIKE 'qui') .\n    Get all \u0026#39;Person\u0026#39; entities in the database with age equal to 46   http://127.0.0.1:8080/persons/$age(EQ 46) .\n  "
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-h/",
	"title": "Delete a Person",
	"tags": [],
	"description": "",
	"content": "Next we will delete one of our \u0026lsquo;Person\u0026rsquo; entities. Create a new tab in Postman and specify a target URL of http://127.0.0.1:8080/person/10000000 with the http DELETE verb. As usual, add the following key-value pairs to the http header:\n Content-Type : application\\json Authorization : Bearer *paste-your-JWT-here*  When you have something that looks as follows, click the \u0026lsquo;Send\u0026rsquo; button to issue the delete request to the application.\nIf the delete request was successful, you will see a http response-code of 202 (Accepted). Try to read the entity by converting your delete request into a get request and verify that \u0026lsquo;Person\u0026rsquo; entity 10000000 has truly been deleted.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/getting-started/level-two/l2-content-i/",
	"title": "Next Steps",
	"tags": [],
	"description": "",
	"content": "That is a quick overview of the sort of things that can be done with an application generated by Jiffy. There is a lot more to see however!\nGood places to start would be in the Jiffy Overview and the Model Maintenance section.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Jiffy Services Generator Jiffy is a model-based RESTful application services generator written in Go. Jiffy processes model files to generate Go source code for a complete backend services application. Jiffys goal is to generate a robust services application that implements all (most?) of the gritty parts, thereby allowing the developer to focus on their application\u0026rsquo;s model and functionality.\nJiffy and the underlying sqac ORM were written as part of my effort to learn more about Go, jwt, consensus protocols, inter-nodal traffic / distributed | replicated cache, containerization and ORM design.\nThe idea of writing a services generator came to me while I was wishing for an alternative avenue for native SAP Hana application development and wrestling with some interesting OData related problems. While the result is probably not for everybody, it does reduce the mental cost of entry and allows deployment of a web-based application on SAP Hana with virtually no prior Hana knowledge. Jiffy also works nicely with other databases.\nJiffy was written in the go 1.9 / 1.10 time-frame, but has been minimally updated to use go modules and now requires a minimum Go version of 1.13.5.\nA list of some of Jiffys features can be found in the following What is Jiffy? section.\nJiffy makes use of a number of external packages provided by some really talented people. These are listed in the CREDITS section.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://1414c.github.io/jiffy/credits/",
	"title": "Credits",
	"tags": [],
	"description": "",
	"content": "Packages and libraries  sqlx jwt-go go-sql-driver/mysql lib/pq go-sqlite3 go-mssqldb go-hdb redigo memcache pkger  Tooling  Hugo Hugo Learn Theme  "
},
{
	"uri": "https://1414c.github.io/jiffy/showcase/",
	"title": "Showcases",
	"tags": [],
	"description": "",
	"content": "Simple Single Entity Application This repository contains a Jiffy application that has been generated from the simpleSingleEntityModel.json model file located in the Jiffy repository.\nThis model is the same one used in the Jiffy Getting Started tutorial in the documentation set.\n Ensure that the latest release of go is installed on your local system. Clone the repository to your local system and follow the Getting Started tutorial link above.  Ready-to-Run Dockerized Application The libraryapp repository contains a Jiffy application that has been generated from the hasManyBelongsTo.json model file located in the Jiffy repository.\nThis model contains a Library entity and a Book entity and declares relationships between them. The relationships allow for nice modes of access where we can do things like read all of the Book entities belonging to a Library, or ask a Book which Library it belongs to. See the Entity Relations section in the Jiffy documentation for details regarding relationships.\nThis repository contains a runnable docker image which makes use of Alpine linux and a sqlite database to expose an application supporting the Library and Book services @ localhost:8080.\nGetting the Docker Image Installed  Make sure port 8080 is not being held by another process on the host system. Ensure that Docker is installed and running on the host machine. Clone the libraryapp repository to the host system, or minimally download the libraryapp.tar file from the libraryapp repository. Use docker load to load the image. Start the libraryapp image and run some tests with Postman.  Docker Load The docker load command can be used to extract the libraryapp image from the libraryapp.tar file and load it as a docker image.\nAardvark:libraryapp stevem$ docker load --input libraryapp.tar 01d7fe70da5c: Loading layer [==================================================\u0026gt;] 15.43MB/15.43MB c12245161295: Loading layer [==================================================\u0026gt;] 4.096kB/4.096kB f210cee51b6f: Loading layer [==================================================\u0026gt;] 2.56kB/2.56kB 06867f677dc6: Loading layer [==================================================\u0026gt;] 2.56kB/2.56kB 90571e324a88: Loading layer [==================================================\u0026gt;] 2.048kB/2.048kB b8fb7e4542f7: Loading layer [==================================================\u0026gt;] 24.58kB/24.58kB fd23e9cd4bef: Loading layer [==================================================\u0026gt;] 1.428MB/1.428MB 0f2acd65de52: Loading layer [==================================================\u0026gt;] 5.811MB/5.811MB 6bb5b02469f6: Loading layer [==================================================\u0026gt;] 4.67MB/4.67MB Loaded image: libraryapp:latest Aardvark:libraryapp stevem$ Check that the image has been loaded correctly.\nAardvark:libraryapp stevem$ docker image ls libraryapp REPOSITORY TAG IMAGE ID CREATED SIZE libraryapp latest 1c2810de379f 3 hours ago 48.2MB Aardvark:libraryapp stevem$ Once you have reached this point, the image is ready to be used and you may pick up at the View the Image Section of the Jiffy with Docker and SQLite tutorial.\n"
},
{
	"uri": "https://1414c.github.io/jiffy/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]